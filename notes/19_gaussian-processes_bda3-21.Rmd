---
title: "18. Notes on 'Ch 21. Gaussian process models'"
date: "2022-01-13"
output: distill::distill_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dpi = 300, comment = "#>")

library(glue)
library(ggtext)
library(tidyverse)

theme_set(
  theme_bw() +
    theme(axis.ticks = element_blank())
)
```


> These are just notes on a single chapter of *BDA3* that were not part of the course.

## Chapter 21. Gaussian process models

- *Gaussian process* (GP): "flexible class of models for which any finite-dimensional marginal distribution is Gaussian" (pg. 501)
  - "can be viewed as a potentially infinite-dimensional generalization of Gaussian distribution" (pg. 501)

### 21.1 Gaussian process regression

- realizations from a GP correspond to random functions
  - good prior for an unknown regression function $\mu(x)$
- $\mu \sim \text{GP}(m,k)$
  - $m$: mean function
  - $k$: covariance function
- $\mu$ is a random function ("stochastic process") where the values at any $n$ pooints $x_1, \dots, x_n$ are drawn from the $n-dimensional$ normal distribution
  - with mean $m$ and covariance $K$:

$$
\mu(x_1), \dots, \mu(x_n) \sim \text{N}((m(x_1), \dots, m(x_n)), K(x_1, \dots, x_n))
$$

- the GP $\mu \sim \text{GP}(m,k)$ is nonparametric with infinitely many parameters
  - the mean function $m$ represents an inital guess at the regression function
  - the covariance function $k$ represents the covariance between the process at any two points
    - controls the smoothness of realizations from the GP and degree of shrinkage towards the mean
- below is an example of realizations from a GP with mean function 0 and the *squared exponential* (a.k.a. exponentiated quadratic, Gaussian) covariance function with different parameters

$$
k(x, x^\prime) = \tau^2 \exp(-\frac{|x-x^\prime|^2}{2l^2})
$$

```{r}
squared_exponential_cov <- function(x, tau, l) {
  n <- length(x)
  k <- matrix(0, nrow = n, ncol = n)
  denom <- 2 * (l^2)
  for (i in 1:n) {
    for (j in 1:n) {
      a <- x[i]
      b <- x[j]
      k[i, j] <- tau^2 * exp(-(abs(a - b)^2) / (denom))
    }
  }
  return(k)
}

my_gaussian_process <- function(x, tau, l, n = 3) {
  m <- rep(0, length(x))
  k <- squared_exponential_cov(x = x, tau = tau, l = l)
  gp_samples <- mvtnorm::rmvnorm(n = n, mean = m, sigma = k)
  return(gp_samples)
}

set.seed(0)
x <- seq(0, 10, by = 0.1)
gp_samples <- my_gaussian_process(x, tau = 0.5, l = 2)

# TODO: scale to use multiple values for tau and l and then plot all together,
#       faceting by these parameters

as.data.frame(gp_samples) %>%
  as_tibble() %>%
  set_names(x) %>%
  mutate(sample_idx = as.character(1:n())) %>%
  pivot_longer(-sample_idx, names_to = "x", values_to = "y") %>%
  mutate(x = as.numeric(x)) %>%
  ggplot(aes(x = x, y = y)) +
  geom_line(aes(color = sample_idx)) +
  scale_x_continuous(expand = expansion(c(0, 0))) +
  scale_y_continuous(expand = expansion(c(0.02, 0.02))) +
  theme(legend.position = "none", axis.text.y = element_markdown()) +
  labs(x = "x", y = "\u03BC(x)")
```



#### Covariance functions



#### Inference



#### Covariance function approximations



#### Marginal likelihood and posterior
