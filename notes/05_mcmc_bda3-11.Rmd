---
title: "05. Markov chain Monte Carlo"
date: "2021-09-26"
output: distill::distill_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dpi = 300, comment = "#>")
```

## Resources

- BDA3 chapter 11 and [reading instructions](../reading-instructions/BDA3_ch11_reading-instructions.pdf)
- lectures:
  - ['5.1. Markov chain Monte Carlo, Gibbs sampling, Metropolis algorithm'](https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=098dfdb4-f3b8-46aa-b988-aadf00bd3177)
  - ['5.2. Warm-up, convergence diagnostics, R-hat, and effective sample size'](https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=9f657178-d8cf-4cb8-af62-aadf00cd9423)
- [slides](../slides/slides_ch11.pdf)
- [Assignment 5](assignments/assignment-05.pdf)

## Notes

### Reading instructions

- Outline of the chapter 11
  - Markov chain simulation: before section 11.1, pages 275-276
  - 11.1 Gibbs sampler (an example of simple MCMC method)
  - 11.2 Metropolis and Metropolis-Hastings (an example of simple MCMC method) â€¢ 11.3 Using Gibbs and Metropolis as building blocks (can be skipped)
  - 11.4 Inference and assessing convergence (important)
  - 11.5 Effective number of simulation draws (important)
  - 11.6 Example: hierarchical normal model (skip this)
- Animations
  - Nice animations with discussion: http://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/
  - And just the animations with more options to experiment: https://chi-feng.github.io/mcmc-demo/
- Convergence
  - theoretical convergence in an infinite time is different than practical convergence in a finite time
  - no exact moment when chain has converged
    - convergence diagnostics can help to find out if the chain is unlikely to be representative of the target distribution
- $\hat{R}$ effective sample size (ESS, previously $n_\text{eff}$)
  - there are many versions of $\hat{R}$ and effective sample size
    - some software packages compute these using old inferior approaches
    - updated version in [*Rank-normalization, folding, and localization: An improved $\hat{R} for assessing convergence of MCMC*](https://projecteuclid.org/euclid.ba/1593828229)

### Chapter 11. Basics of Markov chain simulation

#### Introduction

- **MCMC**: general method based on drawing values of $\theta$ from approximate distribtuions and then correcting those draws to better approximate the target posterior distribution $p(\theta, y)$
  - **Markov chain**: a sequence of random variables $\theta^1, \theta^2, \dots$ for wihch, for any $t$, the distribtuion of $\theta^t$ given all previous $\theta$'s depends only on the previous value $\theta^{t-1}$
- general process:
  1. create several independent sequences
  2. each sequence $\theta^1, \theta^2, \dots$ starts from some point $\theta^0$
  3. for each $t$, draws $\theta^t$ from the *transition distribution $T_t (\theta^t | \theta^{t-1})$
- essential to check convergence of chains
- this chapter introduces the *Gibbs sampler* and *Metropolic-Hastings algorithm*

#### 11.1 Gibbs sampler

- algorithm:
  1. separate the parameter vector $\theta$ into $d$ components (also called subvectors) $\theta = (\theta_1, \dots, \theta_d)$
  2. for each iteration $t$, each compoent is cycled through (thus, there are $d$ steps for each iteration)
  3. for each iteration $t$, for each $j$ component of $\theta$, each $\theta_j^t$ is sampled from the conditional distribution given all the other current values of $\theta$: $p(\theta_j | \theta_{-j}^{t-1})$
    - where $\theta_{-j}^{t-1} = (\theta_1^t, \dots, \theta_{j-1}^t, \theta_{j+1}^{t-1}, \dots, \theta_d^{t-1})$
    - is just all of the current values of $\theta$ where some have yet to be update in iteration $t$
- ex: bivariate normal distribution
  - a bivariate normally distribution population with mean $\theta = (\theta_1, \theta_2)$ (so $d = 2$ for this example) and covariance matrix $\begin{pmatrix} 1 & \rho \\ \rho  & 1 \\ \end{pmatrix}$
  - given single observation $(y_1, y_2)$
  - uniform prior on $\theta$
  - posterior distribution defined in \@ref(eq:gibbs-posterior)
  - need conditional posterior distribution for each $\theta_j$ on the other components of $\theta$
    - here, use equations A.1 from appendix A (pg. 582): \@ref(eq:gibbs-conditional-posterior)
  - Gibbs sampler just alternatively samples from these two conditional distributions

\begin{equation}
  \begin{pmatrix}
    \theta_1 \\ \theta_2 \end{pmatrix} | y
    \sim \text{N}
    \begin{pmatrix}
    \begin{pmatrix} y_1 \\ y_2 \end{pmatrix},
    \begin{pmatrix} 1 & \rho \\ \rho  & 1 \\ \end{pmatrix}
  \end{pmatrix}
  (\#eq:gibbs-posterior)
\end{equation}

\begin{align}
  \begin{split}
  \theta_1 | \theta_2, y &\sim \text{N}(y_1 + \rho (\theta_2 - y_2), 1 - \rho^2) \\
  \theta_2 | \theta_1, y &\sim \text{N}(y_2 + \rho (\theta_1 - y_1), 1 - \rho^2)
  \end{split}
  (\#eq:gibbs-conditional-posterior)
\end{align}

**TODO**: replicate example from book in code

### Lecture notes
