---
title: "08. Model checking & Cross-validation"
date: "2021-10-31"
output: distill::distill_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dpi = 300, comment = "#>")
```

## Resources
- reading:
  - BDA3 ch. 6 "Model checking" and [ch. 6 reading instructions](../reading-instructions/BDA3_ch06_reading-instructions.pdf)
  - BDA3 ch. 7 "Evaluating, comparing, and expanding models" and [ch. 7 reading instructions](../reading-instructions/BDA3_ch07_reading-instructions.pdf)
  - read *Visualization in Bayesian workflow* ([pdf](additional-reading/Visualization-in-Bayesian-workflow.pdf), [link](https://doi.org/10.1111/rssa.12378))
  - read *Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC* ([pdf](additional-reading/Practical-Bayesian-model-evaluation-using-leave-one-out-cross-validation-and-WAIC.pdf), [link](https://arxiv.org/abs/1507.04544))
  - additional reading material:
    - [Model assesment, selection and inference after selection](https://avehtari.github.io/modelselection/)
    - [Cross-validation FAQ](https://avehtari.github.io/modelselection/CV-FAQ.html)
- lectures:
  - ['Model Checking'](https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7047e366-0df6-453c-867f-aafb00ca2d78)
  - ['Cross-Validation (part 1)'](https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=d7849131-0afd-4ae6-ad64-aafb00da36f4)
- slides:
  - [ch 6 slides](../slides/slides_ch6.pdf)
  - [ch 7 slides](../slides/slides_ch7.pdf)
  - [ch 7b slides](../slides/slides_ch7b.pdf)

## Notes

### Chapter 6 reading instructions

- Replicates vs. future observation
  - predictive $\tilde{y}$: the next yet unobserved possible observation
  - $y^\text{rep}$: replicating the whole experiment (with same values of $x$) and obtaining as many replicated observations as in the original data
- Posterior predictive *p*-values
  - **do not recommend *p*-values any more** especially in a form of hypothesis testing
- Prior predictive checking
  - using just the prior predictive distributions for assessing the sensibility of the model and priors before observing any data

### Chapter 6. Model checking

#### 6.1 The place of model checking in applied Bayesian statistics

- must assess the fit of a model to the data and to our substantive domain knowledge

##### Sensitivity analysis and model improvement

- *sensitivity analysis*: "how much do posterior inference change when other reasonable probability models are used in place of the present model?" (pg. 141)

##### Judging model flaws by their practical implications

- not interested in if the model is true or false - will likely always be false
- more interested in the question: "Do the model's deficiencies have a noticeable effect on the substantive inferences?" (pg. 142)
  - keep focus on the more important parts of the model, too

#### 6.2 Do the inferences from the model make sense?

- there will be knowledge that is not included in the model
  - if the additional information suggests that posterior inferences are false, this suggests an option for improving the model's accuracy

##### External validation

- *external validation*: "using the model to make predictions about future data, and then collecting those data and comparing to their predictions" (pg. 142)

#### 6.3 Posterior predictive checking

- if the model fits, then generated replicate data should look like the observed data
  - "the observed data should look plausible under the posterior predictive distribution" (pg. 143)
  - is a *self-consistency check*
- important to choose test quantities that are of interest of the goals of the model
  - may be inaccurate in some regards, but the relevance should be taken into account
- need not worry about adjusting for multiple comparisons:
  - "We are not concerned with 'Type I error' rate... because we use the checks not to accept or reject a model but rather to understand the limits of its applicability in realistic replications." (pg. 150)

#### 6.4 Graphical posterior predictive checks







### Chapter 7 reading instructions

- notes from the reading insturctions

### Chapter 7. Evaluating, comparing, and expanding models

- notes from the book

### Lecture notes
