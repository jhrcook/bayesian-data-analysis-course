---
title: "08. Model checking & Cross-validation"
date: "2021-10-31"
output: distill::distill_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dpi = 300, comment = "#>")
```

## Resources

- reading:
  - BDA3 ch. 6 "Model checking" and [ch. 6 reading instructions](../reading-instructions/BDA3_ch06_reading-instructions.pdf)
  - BDA3 ch. 7 "Evaluating, comparing, and expanding models" and [ch. 7 reading instructions](../reading-instructions/BDA3_ch07_reading-instructions.pdf)
  - read *Visualization in Bayesian workflow* ([pdf](additional-reading/Visualization-in-Bayesian-workflow.pdf), [link](https://doi.org/10.1111/rssa.12378))
  - read *Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC* ([pdf](additional-reading/Practical-Bayesian-model-evaluation-using-leave-one-out-cross-validation-and-WAIC.pdf), [link](https://arxiv.org/abs/1507.04544))
  - additional reading material:
    - [Model assesment, selection and inference after selection](https://avehtari.github.io/modelselection/)
    - [Cross-validation FAQ](https://avehtari.github.io/modelselection/CV-FAQ.html)
- lectures:
  - ['Lecture 8.1. Model Checking'](https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7047e366-0df6-453c-867f-aafb00ca2d78)
  - ['Lecture 8.2. Cross-Validation (part 1)'](https://aalto.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=d7849131-0afd-4ae6-ad64-aafb00da36f4)
- slides:
  - [ch 6 slides](../slides/slides_ch6.pdf)
  - [ch 7 slides](../slides/slides_ch7.pdf)
  - [ch 7b slides](../slides/slides_ch7b.pdf)

## Notes

### Chapter 6 reading instructions

- Replicates vs. future observation
  - predictive $\tilde{y}$: the next yet unobserved possible observation
  - $y^\text{rep}$: replicating the whole experiment (with same values of $x$) and obtaining as many replicated observations as in the original data
- Posterior predictive *p*-values
  - **do not recommend *p*-values any more** especially in a form of hypothesis testing
- Prior predictive checking
  - using just the prior predictive distributions for assessing the sensibility of the model and priors before observing any data

### Chapter 6. Model checking

#### 6.1 The place of model checking in applied Bayesian statistics

- must assess the fit of a model to the data and to our substantive domain knowledge

##### Sensitivity analysis and model improvement

- *sensitivity analysis*: "how much do posterior inference change when other reasonable probability models are used in place of the present model?" (pg. 141)

##### Judging model flaws by their practical implications

- not interested in if the model is true or false - will likely always be false
- more interested in the question: "Do the model's deficiencies have a noticeable effect on the substantive inferences?" (pg. 142)
  - keep focus on the more important parts of the model, too

#### 6.2 Do the inferences from the model make sense?

- there will be knowledge that is not included in the model
  - if the additional information suggests that posterior inferences are false, this suggests an option for improving the model's accuracy

##### External validation

- *external validation*: "using the model to make predictions about future data, and then collecting those data and comparing to their predictions" (pg. 142)

#### 6.3 Posterior predictive checking

- if the model fits, then generated replicate data should look like the observed data
  - "the observed data should look plausible under the posterior predictive distribution" (pg. 143)
  - is a *self-consistency check*
- important to choose test quantities that are of interest of the goals of the model
  - may be inaccurate in some regards, but the relevance should be taken into account
- need not worry about adjusting for multiple comparisons:
  - "We are not concerned with 'Type I error' rate... because we use the checks not to accept or reject a model but rather to understand the limits of its applicability in realistic replications." (pg. 150)

#### 6.4 Graphical posterior predictive checks

- three types of graphical display to start a posterior predictive check:
  1. direct display of all the data
    - may need to get clever with how to do this effectively
  2. display of data summaries or parameter inferences
    - useful when dataset is very large or want to focus on a particular part of the model
  3. graphs of residuals or other measures of discrepancy between the model and data
    - description of how to do this effectively for discrete data

#### 6.5 Model checking for the educational testing example

- check that posterior parameter values and predictions are reasonable
- compare summary statistics of real data and predictive distributions
  - min. and max. values, averages, skewness
- sensitivity analysis can assuage concerns that the outcome was not determined by specific choices of priors

### Chapter 6. Lecture notes

#### Lecture 8.1. Model Checking

- model checking overview:
  - Sensibility with respect to additional information not used in modeling
    - e.g., if posterior would claim that hazardous chemical decreases probability of death
  - External validation
    - compare predictions to completely new observations
    - compare to theorectical values
      - e.g., relativity theory predictions on the speed of light (not based on model optimized to data)
  - Internal validation
    - posterior predictive checking
    - cross-validation predictive checking
- example of posterior checks with air quality model
- examples with binary data and logistic regression
- get posterior predictive distribution in Stan:

```
data {
  int<lower=1> N;
  int<lower=0> y[N];
}
parameters {
  real<lower=0> lambda;
}
model {
  lambda ~ exponential(0.2);
  y ~ poisson(lambda);
}
generated_quantities {
  real log_lik[N];
  int y_rep[N];
  for (n in 1:N) {
    y_rep[n] = poisson_rng(lambda);
    log_lik[n] = poisson_lpmf(y[n] | lambda);
  }
}
```

---

### Chapter 7 reading instructions

- notes from the reading instructions

### Chapter 7. Evaluating, comparing, and expanding models

- notes from the book


### Chapter 7. Lecture notes
