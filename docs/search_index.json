[["index.html", "Bayesian Data Analysis course 0.1 Resources 0.2 How to study 0.3 Course sections 0.4 Additional notes 0.5 Assignments and exercises 0.6 Stan models", " Bayesian Data Analysis course TODO: go through each page and update styling DONE: citations: https://bookdown.org/yihui/bookdown/citations.html#citations footnotes: remove number from foot note so they appear at the bottom of the current page (https://bookdown.org/yihui/bookdown/markdown-syntax.html#inline-formatting) figure out where to put Stan models (script to put them all in an Rmd with good code highlighting) update About page update this page to act as more of an introduction and explain the structure of the book update each section’s Introduction page update links in notes to go to github (have these dynamically inserted using Rmd magic) This book serves as a collection of my notes and exercises completed for the Bayesian Data Analysis course taught by Aki Vehtari. It is normally taught as CS-E5710 at Aalto University, but the lectures and assignments have been made freely available online. The source code for my course work is available on GitHub: jhrcook/bayesian-data-analysis-course. If you see any problems (big or small), please let me know by opening an Issue. All R Markdown files are self-contained an can be executed on their own (i.e. do not need to be run in a series or specific order). 0.1 Resources Course website 2021 Schedule GitHub repo (my fork) Bayesian Data Analysis (3e) (BDA3) (exercise solutions) Chapter Notes Video lectures or individually lists here Lecture slides 0.2 How to study The following are recommendations from the course creators on how to take the course. The recommended way to go through the material is: Read the reading instructions for a chapter in the chapter notes. Read the chapter in BDA3 and check that you find the terms listed in the reading instructions. Watch the corresponding video lecture to get explanations for most important parts. Read corresponding additional information in the chapter notes. Run the corresponding demos in R demos or Python demos. Read the exercise instructions and make the corresponding assignments. Demo codes in R demos and Python demos have a lot of useful examples for handling data and plotting figures. If you have problems, visit TA sessions or ask in course slack channel. If you want to learn more, make also self study exercises listed below. 0.3 Course sections Below are the main sections of the course where each section should take about a week to complete. Course Introduction Basics of Bayesian Inference Multidimensional Posterior Monte Carlo Markov chain Monte Carlo HMC, NUTS, and Stan Hierarchical models and exchangeability Model checking &amp; Cross-validation Model comparison and selection Decision analysis Normal approximation &amp; Frequency properties Extended topics 0.4 Additional notes I took additional notes on other chapters in the book. I appended these chapters after the primary course sections. Ch. 14 Introduction to regression models Ch. 15 Hierarchical linear models Ch. 19 Parametric nonlinear models Ch. 20 Basis function models Ch. 21 Gaussian process models Ch. 22 Finite mixture models Ch. 23 Dirichlet process models I plan to also read through and take notes on chapters 16 and 18 on “Generalized linear models” and “Models for missing data” in the future. 0.5 Assignments and exercises I completed the assignments that accompany the course and also did some of additional exercises from the book. These are available in their own sections of the book: Assignments and Exercises. 0.6 Stan models Below is a list of the models built during the course. The original code is available in the GitHub repo “models” directory and they are also copied in the Models section of this website. Drug bioassay model for Assignment 6 8 school SAT model Drownings for Assignment 7 Factory machine measurements for Assignments 7 &amp; 8: pooled separate hierarchical (also used in Assignment 9) serial dilution assay for chapter 19 exercises "],["notes-introduction.html", "Introduction", " Introduction This part of the book contains my notes from course lectures and book reading. Sections 1-12 are based on the course’s sessions whereas 13-21 are additional notes on chapters of BDA3 not included in the course. Note that some sections are missing in this latter group because I skipped them for now, but left space in case I return. Each section corresponding to a session of the course contains several parts. Each begins with a list of resources for the session including readings from BDA3 or external sources (e.g. papers), lecture recordings and slides, a reading guide/instructions, and a link to any assignment instructions. This is then followed by notes from the reading(s) and lecture. In contrast, the sections corresponding to my additional reading just contain notes on the book’s text. "],["section-1.-course-introduction-and-prerequisites.html", "1 Section 1. Course introduction and prerequisites 1.1 Resources 1.2 Notes", " 1 Section 1. Course introduction and prerequisites 2021-08-17 1.1 Resources BDA chapter 1 and reading instructions lectures: ‘Computational probabilistic modeling’ ‘Introduction to uncertainty and modelling’ video: ‘Introduction to the course contents’ slides Assignment 1 1.2 Notes 1.2.1 Reading instructions model vs. likelihood for \\(p(y|\\theta, M)\\) model when the function is in terms of \\(y\\) should be written as \\(p_y(y|\\theta, M)\\) used to describe uncertainty about \\(y\\) given values of \\(\\theta\\) and \\(M\\) likelihood when the function is in terms of \\(\\theta\\) should be written as \\(p_\\theta(y|\\theta, M)\\) the posterior distribution describes the probability for different values of \\(\\theta\\) given fixed values for \\(y\\) “The likelihood function is unnormalized probability distribution describing uncertainty related to \\(\\theta\\) (and that’s why Bayes rule has the normalization term to get the posterior distribution).” exchangeability independence is stronger condition than exchangeability independence implies exchangeability exchangeability does not imply independence exchangeability is related to what information is available instead of the properties of unknown underlying data generating mechanism 1.2.2 Lecture notes Introduction to uncertainty and modelling two types of uncertainty: aleatoric: due to randomness epistemic: due to lack of knowledge model vs. likelihood: model \\(p_y(y|\\theta, M)\\) a function of \\(y\\) given fixed values of \\(\\theta\\) describes aleatoric uncertainty likelihood \\(p_\\theta(y|\\theta, M)\\) function of \\(\\theta\\) given fixed values of \\(y\\) provides information about the epistemic uncertainty is not a probability distribution Bayes rule combines the likelihood with prior uncertainty to update the posterior uncertainty example with a bag containing red and yellow chips: probability of red = #red / #red + #yellow = \\(\\theta\\) \\(p(y = \\text{red} | \\theta)\\): aleatoric uncertainty predicting the probability of pulling a red chip has uncertainty due to randomness even if we new \\(\\theta\\) exactly \\(p(\\theta)\\): epistemic uncertainty we don’t know \\(\\theta\\) but could compute it exactly if we knew the contents of the bag Introduction to the course contents benefits of Bayesian approach integrate over uncertainties to focus on interesting parts use relevant prior information hierarchical models model checking and evaluation "],["section-2.-basics-of-bayesian-inferences.html", "2 Section 2. Basics of Bayesian inferences 2.1 Resources 2.2 Notes", " 2 Section 2. Basics of Bayesian inferences 2021-08-21 2.1 Resources BDA3 chapter 2 and reading instructions lectures: ‘2.1 Basics of Bayesian inference, observation model, likelihood, posterior and binomial model, predictive distribution and benefit of integration’ ‘2.2 Priors and prior information, and one parameter normal model’ ‘Extra explanations about likelihood, normalization term, density, and conditioning on model M’ (optional) ‘Summary 2.1. Observation model, likelihood, posterior and binomial model’ (optional) ‘Summary 2.2. Predictive distribution and benefit of integration’ (optional) ‘Summary 2.3. Priors and prior information’ (optional) slides and extra slides Assignment 2 2.2 Notes 2.2.1 Chapter instructions recommendations about weakly informative priors has changed a bit updated recommendations: Prior Choice Recommendations “5 levels of priors”: Flat prior (not usually recommended) Super-vague but proper prior: \\(N(0, 10^6)\\) (not usually recommended) Weakly informative prior: very weak; \\(N(0, 10)\\) Generic weakly informative prior: \\(N(0, 1)\\) Specific informative prior: \\(N(0.4, 0.2)\\) or whatever; can sometimes be expressed as a scaling followed by a generic prior: \\(\\theta = 0.4 + 0.2z; \\text{ } z \\sim N(0, 1)\\) “flat and super-vague priors are not usually recommended” even a seemingly weakly informative prior could be informative e.g. a prior of \\(N(0, 1)\\) could put weight on values too large if a large effect size would only be on the scale of 0.1 def. weakly informative: “if there’s a reasonably large amount of data, the likelihood will dominate, and the prior will not be important” section on General Principles; some stand-outs copied here: “Computational goal in Stan: reducing instability which can typically arise from bad geometry in the posterior” “Weakly informative prior should contain enough information to regularize: the idea is that the prior rules out unreasonable parameter values but is not so strong as to rule out values that might make sense” “When using informative priors, be explicit about every choice; write a sentence about each parameter in the model.” 2.2.2 Chapter 2. Single-parameter models I took notes in the book, so below are just some main points. 2.2 Posterior as compromise between data and prior information “general feature of Bayesian inference: the posterior distribution is centered at a point that represents a compromise between the prior information and the data” 2.3 Estimating a probability from binomial data a key benefit of Bayesian modeling is the flexibility of summarizing posterior probabilities can be used to answer the key research questions commonly used summary statistics centrality: mean, median, mode variation: standard deviation, interquartile range, highest posterior density 2.4 Informative prior distributions hyperparameter: parameter of a prior distribution conjugacy: “the property that the posterior distribution follows the same parameter form as the prior distribution” e.g. the beta prior is a conjugate family for the binomial likelihood e.g. the gamma prior is a conjugate family for the Poisson likelihood convenient because the posterior follows a known parametric family formal definition of conjugacy: \\[ p(\\theta | y) \\in \\mathcal{P} \\text{ for all } p(\\cdot | \\theta) \\in \\mathcal{F} \\text{ and } p(\\cdot) \\in \\mathcal{P} \\] 2.5 Normal distribution with known variance precision (when discussing normal distributions): the inverse of the variance \\(\\frac{1}{\\tau^2}\\) 2.6 Other standard single-parameter models Poisson model for count data data \\(y\\) is the number of positive events unknown rate of the events \\(\\theta\\) conjugate prior is the gamma distribution section 2.7 is a good example of a hierarchical Poisson model 2.8 Noninformative prior distributions See more information in the notes from the chapter instructions. rationale: let the data speak for themselves; inferences are unaffected by external information/bias problems: can cause the posterior to become improper computationally, makes it harder to sample from the posterior 2.9 Weakly informative prior distributions See more information in the notes from the chapter instructions. weakly informative: the prior is proper, but intentionally weaker than whatever actual prior knowledge is available “in general, any problem has some natural constraints that would allow a weakly informative model” small amount of real-world knowledge to ensure the posterior makes sense 2.2.3 Lecture notes 2.1 Basics of Bayesian inference, observation model, likelihood, posterior and binomial model, predictive distribution and benefit of integration predictive distribution “integrate over uncertainties” for the example of pulling red or yellow chips out of a bag: want a predictive distribution for some data point \\(\\tilde{y} = 1\\): if we know \\(\\theta\\) then it is easy: \\(p(\\tilde{y} = 1 | \\theta, y, n, M)\\) where \\(n\\) is number of draws, \\(y\\) is number of success (red chip), \\(M\\) is model we don’t know \\(\\theta\\), we weight the probability of the new data for a given \\(\\theta\\) by the posterior probability that \\(\\theta\\) is that value sum (integrate) over all possible values for \\(\\theta\\) (“integrate out the uncertainty of \\(\\theta\\)”) \\(p(\\tilde{y}=1|y, n, M) = \\int_0^1 p(\\tilde{y} = 1 | \\theta, y, n, M) p(\\theta | y, n, M) d\\theta\\) now the prediction is not conditioned on \\(\\theta\\), just on what was observed prior predictive: predictions before seeing any data \\(p(\\tilde{y}=1|M) = \\int_o^1 p(\\tilde{y}=1 | \\theta, y, n, M) p(\\theta|M)\\) 2.2 Priors and prior information, and one parameter normal model proper prior: \\(\\int p(\\theta) = 1\\) better to use proper priors improper prior density does not have a finite integral the posterior can sometimes still be proper, though uniform distributions to infinity are improper a weak prior is not non-informative could give a lot of a weight to very unlikely (or impossible) values make sure to check prior values against knowable values sufficient statistic: the quantity \\(t(y)\\) is a sufficient statistic for \\(\\theta\\) because the likelihood for \\(\\theta\\) depends on the data \\(y\\) only through the value of \\(t(y)\\) smaller dimensional data that fully summarizes the full data can define a Gaussian with just the mean and s.d. Extras: likelihood, normalization term, density, and conditioning on model M Predictive distribution and benefit of integration predictive dist. effect of integration predictive dist of new \\(\\hat{y}\\) (discrete) with model \\(M\\): if we know \\(\\theta\\): \\(p(\\hat{y} = 1| y, n, M) = p(\\hat{y} = 1 | \\theta, y, n, M)\\) if we don’t know \\(\\theta\\): \\(p(\\hat{y} = 1 | \\theta, y, n, M) p(\\theta| y, n, M)\\) weight by the probability of the value for \\(\\theta\\) integrate over all possible values of \\(\\theta\\): \\(p(\\hat{y} = 1|y, n, M) = \\int_0^1 p(\\hat{y}=1| \\theta, y, n, M) p(\\theta|y, n, M)d\\theta\\) “integrate out the uncertainty over \\(\\theta\\)” prior predictive for new data \\(\\hat{y}\\): \\(p(\\hat{y} =1|M) = int_0^1 p(\\hat{y}=1|\\theta,y,n,M)p(\\theta|M)\\) Priors and prior information conjugate priors do not result in any computational benefits in HMC or NUTS can be useful to analytically reduce the size of a model, beforehand, though "],["section-3.-multidimensional-posterior.html", "3 Section 3. Multidimensional Posterior 3.1 Resources 3.2 Notes", " 3 Section 3. Multidimensional Posterior 2021-09-02 3.1 Resources BDA3 chapter 3 and reading instructions lectures: ‘Lecture 3. Multiparameter models, joint, marginal and conditional distribution, normal model, bioassay example, grid sampling and grid evaluation’ slides Assignment 3 3.2 Notes 3.2.1 Reading instructions the trace of a square matrix \\(tr(A)\\) is the sum of the diagonals the following property is used in derivation of 3.11: \\(tr(ABC) = tr(CAB) = tr(BCA)\\) 3.2.2 Chapter 3. Introduction to multiparameter models Averaging over ‘nuisance parameters’ suppose the unknown variable \\(\\theta\\) is a vector of length two: \\(\\theta= (\\theta_1, \\theta_2)\\) may only care about one of the variables, but the other is still required for a good model example model: \\(y | \\mu, \\sigma^2 \\sim N(\\mu, \\sigma^2)\\) here, \\(\\theta\\) would be the unknown values \\(\\mu (=\\theta_1)\\) and \\(\\sigma (=\\theta_2)\\), but we really only care about \\(\\mu\\) we want \\(p(\\theta_1|y)\\) derive it from the joint posterior density: \\(p(\\theta_1, \\theta_2) \\propto p(y|\\theta_1, \\theta2) p(\\theta_1, \\theta_2)\\) by averaging over \\(\\theta_2\\): \\(p(\\theta_1|y) = \\int p(\\theta_1, \\theta_2| y) d\\theta_2\\) “integrate over the uncertainty in \\(\\theta_2\\)” Summary of elementary modeling and computation the following is an outline of a simple Bayesian analysis it will change when we get to more complex models whose posteriors are estimated by more complex sampling processes write the likelihood: \\(p(y|\\theta)\\) write the posterior density: \\(p(\\theta|y) \\propto p(\\theta) p(y|\\theta)\\)$ estimate the parameters \\(\\theta\\) (e.g. using MLE) draw simulations \\(\\theta^1, \\dots, \\theta^S\\) for the posterior distribution (using the results of 3 as a starting point); use the samples to compute any other functions of \\(\\theta\\) that are of interest if any predictive quantities \\(\\tilde{y}\\) are of interest, simulate \\(\\tilde{y}^1, \\dots, \\tilde{y}^S\\) from \\(p(\\tilde{y} | \\theta^s)\\) 3.2.3 Lecture notes (No extra notes were taken — some comments added directly to slides.) "],["section-4.-monte-carlo.html", "4 Section 4. Monte Carlo 4.1 Resources 4.2 Notes", " 4 Section 4. Monte Carlo 2021-09-10 4.1 Resources BDA3 chapter 10 and reading instructions lectures: ‘Numerical issues, Monte Carlo, how many simulation draws are needed, how many digits to report’ ‘Direct simulation, curse of dimensionality, rejection sampling, and importance sampling’ slides Assignment 1 4.2 Notes 4.2.1 Reading instructions Overview of chapter sections: 10.1 Numerical integration (overview) 10.2 Distributional approximations (overview, more in Chapter 4 and 13) 10.3 Direct simulation and rejection sampling (overview) 10.4 Importance sampling (used in PSIS-LOO discussed later) 10.5 How many simulation draws are needed? (Important! Ex 10.1 and 10.2) • 10.6 Software (can be skipped) 10.7 Debugging (can be skipped) Other comments: “Importance sampling is useful in importance sampling leave-one-out cross-validation (LOO-CV)” and Pareto smoothed importance sampling (PSIS-LOO). “BDA3 p. 266 recommends importance resampling without replacement. At the time of writing that in 2013, we had less experience with importance sampling and there were some reasonable papers showing reduced variance doing resampling without replacement. We don’t recommend this anymore as Pareto smoothed importance sampling works better and is also applicable when the resample sample size is equal to the original sample size.” 4.2.2 Chapter 10. Introduction to Bayesian computation Bayesian computation revolves around 2 steps: computing the posterior distribution \\(p(\\theta|y)\\) computing the posterior predictive distribution \\(p(\\tilde{y}|y)\\) this chapter summarizes statistical procedures for approximately evaluating integrals define two distributions: target distribution: distribution to be simulated \\(p(\\theta\\)|y) unnormalized density: distribution to be simulated \\(q(\\theta\\)|y) \\(q(\\theta|y)/p(\\theta|y)\\) is a constant only dependent on \\(y\\) thus, for Bayes theorem, use \\(p(\\theta)p(y|\\theta) \\propto p(\\theta|y)\\) when possible, use log posterior densities to avoid computational over/underflows 10.1 Numerical integration methods where the integral over a continuous function is evaluated by computing the value of the function at a finite number of points included simulation methods (such as Monte Carlo) and deterministic methods posterior expectation of a function \\(h(\\theta)\\): \\(\\text{E}(h(\\theta)|y) = \\int h(\\theta) p(\\theta|y) d\\theta\\) thus can express any integral over \\(\\theta\\) as a posterior expectation by properly defining \\(h(\\theta)\\) simulation methods obtain random samples of \\(\\theta^s\\) from the target dist. \\(p(\\theta)\\) and estimate the expectation of and function \\(h(\\theta)\\): \\[ \\text{E}(h(\\theta)|y) = int h(\\theta)p(\\theta|y) d\\theta \\approx \\frac{1}{S} \\sum_{s=1}^S h(\\theta^s) \\] Monte Carlo methods produce independent samples and are described in this chapter Markov chain Monte Carlo methods better adapt to higher-dimensional, complex distributions, but produce dependent samples (discussed in chapter 11 and 12) 10.2 Distributional approximations approx the posterior with a simpler parameter distribution can solve these integrals analytically or use them as starting points for simulation-based methods often useful to create a simpler model that can be solved analytically to get a approx for the original posterior 10.3 Direct simulation and rejection sampling can often draw directly from the posterior distribution for simpler models otherwise, often good to factor the distribution analytically and simulate it in parts grid approximation: compute the target density \\(p(\\theta|y)\\) at a set of evenly spaced values \\(\\theta_1, \\dots, \\theta_N\\) that cover the parameter space for \\(\\theta\\) then normalize the samples by dividing over the sum of all probs. difficult for high-dimensional \\(\\theta\\) rejection sampling require a positive function \\(g(\\theta)\\) defined for all \\(\\theta\\) where the posterior is positive \\(p(\\theta|y)&gt;0\\) and: we can draw from the probability density proportional to \\(g\\) and \\(g(\\theta)\\) has a finite integral there must be a known upper bound \\(M\\) on \\(\\frac{p(\\theta|y)}{g(\\theta)} \\le M \\text{ } \\forall \\text{ } \\theta\\) rejection sampling algorithm: sample \\(\\theta\\) from the probability density proportional to \\(g(\\theta)\\) accept \\(\\theta\\) as a draw from \\(p\\) with a probability \\(\\frac{p(\\theta|y)}{Mg(\\theta)}\\) (the importance ratio); if rejected, return to step 1 the distribution of accepted \\(\\theta\\) is \\(p(\\theta|y)\\) ideally \\(g \\propto p\\) else, the bound for \\(M\\) must be large to ensure the importance ratio in step 2 is \\(\\frac{p(\\theta|y)}{g(\\theta)} \\le M\\), causing a lot of rejections in step 2 of the algorithm the function \\(g(\\theta)\\) is implicitly dependent on \\(y\\), but that is not of interest so it is not reflected in the notation 10.4 Importance sampling importance sampling: used for computing expectations using a random sample drawn from an approx to the target dist \\(p(\\theta|y)\\) related to rejection sampling precursor to Metropolis algorithm in chapter 11 suppose we are interested in \\(\\text{E}(h(\\theta)|y)\\), but cannot generate random draws of \\(\\theta\\) from \\(p(\\theta|y)\\): \\[ \\begin{aligned} \\text{E}(h(\\theta)|y) &amp;= \\frac{\\int h(\\theta)p(\\theta|y) d \\theta}{\\int q(\\theta|y) d \\theta} \\\\ &amp;= \\frac{\\int [h(\\theta) q(\\theta|y) / g(\\theta)] g(\\theta) d \\theta}{\\int[q(\\theta|y)/g(\\theta)] g(\\theta) d \\theta} \\end{aligned} \\] which can be estimated using \\(S\\) draws \\(\\theta^1, \\dots \\theta^S\\) from \\(g(\\theta)\\) by: \\[ \\text{E}(h(\\theta)|y) \\approx \\frac{\\frac{1}{s} \\sum^S h(\\theta^s) w(\\theta^s)}{\\frac{1}{S} \\sum^S w(\\theta^s)} \\text{ where } w(\\theta^s) = \\frac{q(\\theta^s|y)}{g(\\theta^s)} \\] \\(w(\\theta^s)\\) is the importance ratio/weight can run into problem if some weights are much larger than others diagnose by looking at histogram of weights or calculating effective sample size \\(1 / \\sum^S (\\tilde{w}(\\theta^s))^s\\) where \\(\\tilde{w}\\) are normalized weights there is a variant called importance resampling that offers a fix to the problem of uneven weights, but it is no longer recommended (chapter notes) importance sampling in Bayesian computation: obtain a starting point for iterative simulations of the posterior useful for LOO-CV where the original posterior is used as an approximation to the modified posterior dist 10.5 How many simulation draws are needed? goal: “…enough draws \\(S\\) so that quantities of interest can be estimated with reasonable accuracy” for most examples, \\(S=100\\) independent draws are enough often convenient to have more draws for numerical stability of posterior summaries accuracy of estimates of \\(\\theta\\) as a normal distribution: for \\(\\mu_\\theta\\), accuracy: \\(\\sum_\\theta / \\sqrt{S}\\) for \\(\\sum_\\theta\\), accuracy: \\(\\sum_\\theta \\sqrt{1 + 1/S}\\) for \\(S=100\\), \\(\\sqrt{1 + 1/S} = 1.005\\) indicating that Monte Carlo error has little effect on the uncertainty for rare events: ex: probability of very large differences between parameter values; may be 0 posterior draws, but doesn’t mean there is 0 probability can make more draws to have a non-zero number of rare events semi-analytically use the draws to estimate the parameters of a \\(\\theta\\)’s posterior distribution ex: \\(\\mu_\\theta\\) and \\(\\sum_\\theta\\) is \\(\\theta\\) is described as a normal distribution use the described distribution to answer further questions 10.6 Computing environments the Stan program is named after the mathematician Stanislaw Ulam 10.7 Debugging Bayesian computing running multiple chains and checking for convergence and mixing debugging using fake data: pick a reasonable value as a “true” parameter vector \\(\\theta\\) (can sample from prior distributions unless too weak) if model is hierarchical, sample hyperparameters and use those for lower down values of \\(\\theta\\) simulate a fake dataset \\(y^{\\text{fake}}\\) from the data distribution \\(p(y|\\theta)\\) sample from the posterior \\(p(\\theta|y^{\\text{fake}})\\) compare estimated \\(\\theta\\) to known \\(\\theta\\) 4.2.3 Lecture notes 4.1 Numerical issues, Monte Carlo, how many simulation draws are needed, how many digits to report numerical accuracy: in R, more accuracy near 0: pbeta(0.5, 241945, 251527) #&gt; [1] 1 pbeta(0.5, 241945, 251527, lower.tail = FALSE) # 1 - p #&gt; [1] 1.145624e-42 use logarithms of probabilities and avoid exponentiation until as late as possible ex: for \\(a&gt;b\\), compute \\(\\log(\\exp(a) + \\exp(b)) = a + \\log(1 + \\exp(b-a))\\) \\(\\log(\\exp(800) + \\exp(800)) \\to \\infty\\) while \\(800 + \\log(1 + \\exp(800-800)) \\approx 800.69\\) using unnormalized posterior for computing expectations: \\(E_{p(\\theta|y)}[f(\\theta)] = \\int f(\\theta) p(\\theta|y) d \\theta\\) where \\(p(\\theta|y) = \\frac{p(y|\\theta) p(\\theta)}{\\int p(y|\\theta) p(\\theta) d \\theta}\\) easy to compute \\(p(y|\\theta) p(\\theta)\\) for any \\(\\theta\\), but the denominator is difficult thus, use \\(q(\\theta|y) = p(y|\\theta)p(\\theta)\\) and \\(q(\\theta|y) \\propto p(\\theta|y)\\) then: gird evaluation with self-normalization: \\(E_{p(\\theta|y)} [f(\\theta)] \\approx \\frac{\\sum^S [f(\\theta^s) q(\\theta^s|y)]}{\\sum^S q(\\theta^s|y)}\\) Monte Carlo methods that sample from \\(p(\\theta^s|y)\\) using \\(q(\\theta^s|y)\\): \\(E_{p(\\theta|y)}[f(\\theta)] \\approx \\frac{1}{S} \\sum^S f(\\theta^s)\\) number of posterior samples to take to get estimates of mean and variance, do not need too many draws, but if we want certain accuracy for percent intervals, may need more draws to accurately describe the tails (see slide 15, below) estimating the probability of \\(\\theta\\) to be in some interval \\(A\\), can estimate uncertainty as a binomial distribution and calculate certainty of a value for a given number of draws \\(S\\) and probability (slide 16) effect gets worse for smaller probabilities because need more samples to get enough draws of the rare event (demonstrated in slide 17, below) 4.2 Direct simulation, curse of dimensionality, rejection sampling, and importance sampling rejection sampling: have proposal \\(g(\\theta)\\) and target \\(q(\\theta|y)\\) distributions \\(g(\\theta)\\) must be greater than \\(q(\\theta|y)\\) at all possible \\(\\theta\\) for a given value of \\(\\theta\\), accept with probability \\(\\frac{q(\\theta|y)}{M g(\\theta)}\\) rejection-sampling importance sampling: unlike rejection sampling, proposal distribution does not need to be greater than the target re-sampling using normalized importance weights can be used to pick a smaller number of draws with uniform weights can use to correct an approximated distribution (e.g. if used normal approx.) selection of the proposal distribution is difficult in higher dimensions can use the weights to estimate the effective sample size \\(S_{eff}\\) and use this for estimates of accuracy of parameter values importance-sampling leave-one-out cross validation (LOO-CV) can be used for comparing models and how a single point impacts the model re-fit the model without data point \\(i\\) and then estimate the probability of that data point: \\(p(y_i|p_{-i})\\) use \\(p(\\theta|y)\\) as a proposal distribution for \\(p(\\theta|y_{-i})\\) \\(p(y_i | y_{-i}) = \\int p(y_i|\\theta) p(\\theta|y_{-i}) d \\theta\\) MCMC: pros: Markov chain goes where most of the posterior mass is can scale well to high dimensions cons: draws are dependent computationally heavy we will see Gibbs, Metropolis, and Dynamic Hamiltonian Monte Carlo (HMC; state-of-the-art) "],["section-5.-markov-chain-monte-carlo.html", "5 Section 5. Markov chain Monte Carlo 5.1 Resources 5.2 Notes", " 5 Section 5. Markov chain Monte Carlo 2021-09-26 knitr::opts_chunk$set(echo = TRUE, dpi = 300, comment = &quot;#&gt;&quot;) library(glue) library(ggtext) library(patchwork) suppressPackageStartupMessages(library(tidyverse)) theme_set(theme_bw()) 5.1 Resources BDA3 chapter 11 and reading instructions lectures: ‘5.1. Markov chain Monte Carlo, Gibbs sampling, Metropolis algorithm’ ‘5.2. Warm-up, convergence diagnostics, R-hat, and effective sample size’ slides Assignment 5 5.2 Notes 5.2.1 Reading instructions Outline of the chapter 11 Markov chain simulation: before section 11.1, pages 275-276 11.1 Gibbs sampler (an example of simple MCMC method) 11.2 Metropolis and Metropolis-Hastings (an example of simple MCMC method) 11.3 Using Gibbs and Metropolis as building blocks (can be skipped) 11.4 Inference and assessing convergence (important) 11.5 Effective number of simulation draws (important) 11.6 Example: hierarchical normal model (skip this) Animations Nice animations with discussion: (Markov Chains: Why Walk When You Can Flow?)[http://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/] And just the animations with more options to experiment: (The Markov-chain Monte Carlo Interactive Gallery)[https://chi-feng.github.io/mcmc-demo/] Convergence theoretical convergence in an infinite time is different than practical convergence in a finite time no exact moment when chain has converged convergence diagnostics can help to find out if the chain is unlikely to be representative of the target distribution \\(\\widehat{R}\\) effective sample size (ESS, previously \\(n_\\text{eff}\\)) there are many versions of \\(\\widehat{R}\\) and effective sample size some software packages compute these using old inferior approaches updated version in Rank-normalization, folding, and localization: An improved $ for assessing convergence of MCMC 5.2.2 Chapter 11. Basics of Markov chain simulation Introduction MCMC: general method based on drawing values of \\(\\theta\\) from approximate distributions and then correcting those draws to better approximate the target posterior distribution \\(p(\\theta, y)\\) Markov chain: a sequence of random variables \\(\\theta^1, \\theta^2, \\dots\\) for which, for any \\(t\\), the distribution of \\(\\theta^t\\) given all previous \\(\\theta\\)’s depends only on the previous value \\(\\theta^{t-1}\\) general process: create several independent sequences each sequence \\(\\theta^1, \\theta^2, \\dots\\) starts from some point \\(\\theta^0\\) for each \\(t\\), draws \\(\\theta^t\\) from the *transition distribution \\(T_t (\\theta^t | \\theta^{t-1})\\) essential to check convergence of chains this chapter introduces the Gibbs sampler and Metropolis-Hastings algorithm 11.1 Gibbs sampler algorithm: separate the parameter vector \\(\\theta\\) into \\(d\\) components (also called subvectors) \\(\\theta = (\\theta_1, \\dots, \\theta_d)\\) for each iteration \\(t\\), each component is cycled through (thus, there are \\(d\\) steps for each iteration) for each iteration \\(t\\), for each \\(j\\) component of \\(\\theta\\), each \\(\\theta_j^t\\) is sampled from the conditional distribution given all the other current values of \\(\\theta\\): \\(p(\\theta_j | \\theta_{-j}^{t-1})\\) where \\(\\theta_{-j}^{t-1} = (\\theta_1^t, \\dots, \\theta_{j-1}^t, \\theta_{j+1}^{t-1}, \\dots, \\theta_d^{t-1})\\) is just all of the current values of \\(\\theta\\) where some have yet to be update in iteration \\(t\\) ex: bivariate normal distribution a bivariate normally distribution population with mean \\(\\theta = (\\theta_1, \\theta_2)\\) (so \\(d = 2\\) for this example) and covariance matrix \\(\\begin{pmatrix} 1 &amp; \\rho \\\\ \\rho &amp; 1 \\\\ \\end{pmatrix}\\) given single observation \\((y_1, y_2)\\) uniform prior on \\(\\theta\\) posterior distribution defined in (5.1) need conditional posterior distribution for each \\(\\theta_j\\) on the other components of \\(\\theta\\) here, use equations A.1 from appendix A (pg. 582): (5.2) Gibbs sampler just alternatively samples from these two conditional distributions \\[\\begin{equation} \\begin{pmatrix} \\theta_1 \\\\ \\theta_2 \\end{pmatrix} | y \\sim \\text{N} \\begin{pmatrix} \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix}, \\begin{pmatrix} 1 &amp; \\rho \\\\ \\rho &amp; 1 \\\\ \\end{pmatrix} \\end{pmatrix} \\tag{5.1} \\end{equation}\\] \\[\\begin{align} \\begin{split} \\theta_1 | \\theta_2, y &amp;\\sim \\text{N}(y_1 + \\rho (\\theta_2 - y_2), 1 - \\rho^2) \\\\ \\theta_2 | \\theta_1, y &amp;\\sim \\text{N}(y_2 + \\rho (\\theta_1 - y_1), 1 - \\rho^2) \\end{split} \\tag{5.2} \\end{align}\\] below is the code for the example described above chain_to_df &lt;- function(chain, names) { purrr::map_dfr(chain, ~ as.data.frame(t(.x))) %&gt;% tibble::as_tibble() %&gt;% purrr::set_names(names) } # Run a single chain of a Gibbs sampler for a bivariate normal distribution. gibbs_sample_demo &lt;- function(data, rho, theta_t0, N = 100) { theta_1 &lt;- theta_t0[[1]] theta_2 &lt;- theta_t0[[2]] y1 &lt;- data[[1]] y2 &lt;- data[[2]] chain &lt;- as.list(rep(theta_t0, n = (2 * N) + 1)) chain[[1]] &lt;- c(theta_1, theta_2, 1) for (t in seq(2, N)) { theta_1 &lt;- rnorm(1, y1 + rho * (theta_2 - y2), 1 - rho^2) chain[[2 * (t - 1)]] &lt;- c(theta_1, theta_2, t) theta_2 &lt;- rnorm(1, y2 + rho * (theta_1 - y1), 1 - rho^2) chain[[2 * (t - 1) + 1]] &lt;- c(theta_1, theta_2, t) } chain_df &lt;- chain_to_df(chain, names = c(&quot;theta_1&quot;, &quot;theta_2&quot;, &quot;t&quot;)) return(chain_df) } rho &lt;- 0.8 y &lt;- c(0, 0) starting_points &lt;- list( c(-2.5, -2.5), c(2.5, -2.5), c(-2.5, 2.5), c(2.5, 2.5) ) set.seed(0) gibbs_demo_chains &lt;- purrr::map_dfr( seq(1, 4), ~ gibbs_sample_demo(y, rho, starting_points[[.x]]) %&gt;% add_column(chain = as.character(.x)) ) plot_chains &lt;- function(chain_df, x = theta_1, y = theta_2, color = chain) { chain_df %&gt;% ggplot(aes(x = {{ x }}, y = {{ y }}, color = {{ color }})) + geom_path(alpha = 0.6, show.legend = FALSE) + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set1&quot;) } plot_points &lt;- function(chain_df, x = theta_1, y = theta_2, color = chain) { chain_df %&gt;% ggplot(aes(x = {{ x }}, y = {{ y }}, color = {{ color }})) + geom_point(size = 0.75, alpha = 0.75) + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set1&quot;) } theta_axis_labs &lt;- function(p) { p + theme( axis.title.x = element_markdown(), axis.title.y = element_markdown() ) + labs(x = &quot;θ&lt;sub&gt;1&lt;/sub&gt;&quot;, y = &quot;θ&lt;sub&gt;2&lt;/sub&gt;&quot;) } gibbs_plot_chains &lt;- plot_chains(gibbs_demo_chains) %&gt;% theta_axis_labs() gibbs_plot_points &lt;- gibbs_demo_chains %&gt;% group_by(chain, t) %&gt;% slice_tail(n = 1) %&gt;% ungroup() %&gt;% plot_points() %&gt;% theta_axis_labs() (gibbs_plot_chains | gibbs_plot_points) + plot_annotation(title = &quot;Gibbs sampler&quot;) 11.2 Metropolis and Metropolis-Hastings algorithms the Metropolis-Hastings algorithm is a generalized version of the Metropolis algorithm The Metropolis algorithm is a random walk with an acceptance and rejection rule to converge to the target distribution steps: draws a starting point \\(\\theta^0\\) from a starting distribution \\(p_0(\\theta)\\) such that \\(p(\\theta^0|y) &gt; 0\\) for time \\(t = 1, 2, \\dots\\): sample a proposal \\(\\theta^*\\) from a jumping/proposal distribution \\(J_t(\\theta^*|\\theta^{t-1})\\) calculate the ratio of the densities: \\(r = \\frac{p(\\theta^*|y)}{p(\\theta^{t-1}|y)}\\) set \\(\\theta^t = \\theta^*\\) with probability \\(\\min(r, 1)\\), else \\(\\theta^t = \\theta^{t-1}\\) - if the proposal is more likely, it is always accepted, otherwise the ratio \\(r\\) is used as the probability of acceptance the jumping distribution \\(J_t\\) must be symmetric such that \\(J_t(\\theta_a|\\theta_b) = J_t(\\theta_b|\\theta_a)\\) the iteration still counts even if the proposal \\(\\theta^*\\) is rejected ex: bivariate normal distribution (same as before): target density as bivariate normal: \\(p(\\theta|y) = \\text{N}(\\theta | 0, I)\\) jumping distribution as a bivariate normal with smaller deviations and centered around the previous iteration’s \\(\\theta^{t-1}\\): \\(J_t(\\theta^*|\\theta^{t-1}) = \\text{N}(\\theta^* | \\theta^{t-1}, 0.2^2I)\\) thus, the density ratio: \\(r = \\text{N}(\\theta^*|0, I) / \\text{N}(\\theta^{t-1}|0, I)\\) calc_metropolis_density_ratio &lt;- function(t_star, t_m1, data, prior_cov_mat) { numerator &lt;- mvtnorm::dmvnorm(t_star, data, prior_cov_mat) denominator &lt;- mvtnorm::dmvnorm(t_m1, data, prior_cov_mat) return(numerator / denominator) } metropolis_algorithm_demo &lt;- function(data, theta_t0, N = 1000, quiet = FALSE) { theta_t &lt;- unlist(theta_t0) prior_dist_mu &lt;- data prior_dist_cov_mat &lt;- matrix(c(1, 0, 0, 1), nrow = 2) jumping_dist_cov_mat &lt;- prior_dist_cov_mat * 0.2^2 chain &lt;- as.list(rep(NA_real_, n = N + 1)) chain[[1]] &lt;- theta_t n_accepts &lt;- 0 for (t in seq(2, N + 1)) { theta_star &lt;- mvtnorm::rmvnorm( n = 1, mean = theta_t, sigma = jumping_dist_cov_mat )[1, ] density_ratio &lt;- calc_metropolis_density_ratio( t_star = theta_star, t_m1 = theta_t, data = data, prior_cov_mat = prior_dist_cov_mat ) accept &lt;- runif(1) &lt; min(c(1, density_ratio)) if (accept) { theta_t &lt;- theta_star n_accepts &lt;- n_accepts + 1 } chain[[t]] &lt;- theta_t } if (!quiet) { frac_accepts &lt;- n_accepts / N message(glue(&quot;fraction of accepted jumps: {frac_accepts}&quot;)) } return(chain_to_df(chain, names = c(&quot;theta_1&quot;, &quot;theta_2&quot;))) } set.seed(0) metropolis_chains &lt;- purrr::map_dfr( seq(1, 4), ~ metropolis_algorithm_demo(c(0, 0), starting_points[[.x]]) %&gt;% add_column(chain = as.character(.x)) ) #&gt; fraction of accepted jumps: 0.888 #&gt; fraction of accepted jumps: 0.868 #&gt; fraction of accepted jumps: 0.914 #&gt; fraction of accepted jumps: 0.869 metropolis_plot_chains &lt;- plot_chains(metropolis_chains) %&gt;% theta_axis_labs() metropolis_plot_points &lt;- metropolis_chains %&gt;% group_by(chain) %&gt;% slice_tail(n = 500) %&gt;% plot_points() %&gt;% theta_axis_labs() (metropolis_plot_chains | metropolis_plot_points) + plot_annotation(title = &quot;Metropolis algorithm&quot;) The Metropolis-Hastings algorithm two changes to generalize the Metropolis algorithm: the jumping rule \\(J_t\\) need not be symmetric generally results in a faster random walk a new ratio \\(r\\) (5.3) can interpret at a re-weighting of the numerator and denominator by the probability of accepting or rejecting \\(\\theta^*\\) \\[\\begin{equation} r = \\frac{p(\\theta^* | y) / J_t(\\theta^* | \\theta^{t-1})}{p(\\theta^{t-1} | y) / J_t(\\theta^{t-1} | \\theta^*)} \\tag{5.3} \\end{equation}\\] properties of a good jumping rule: easy to sample \\(J(\\theta^*|\\theta)\\) for any \\(\\theta\\) easy to compute the ratio \\(r\\) each jump travels a “reasonable” distance the jumpy are not rejected too frequently 11.2 Metropolis and Metropolis-Hastings algorithms for Bayesian analysis, we want to be able to use the posterior samples for inference, but requires special care when using iterative simulation Difficulties of inference from iterative simulation two main challenges: “if the iterations have not proceeded long enough… the simulations may be grossly unrepresentative of the target distribution” (pg 282) correlation between draws: “simulation inference from correlated draws is generally less precise than from the same number of independent draws” (pg 282) to address these issues: design the simulations to enable monitoring of convergence compare variation between and within chains Discarding early iterations of the simulation runs warm-up: remove first portion of draws to diminish the influence on the starting location how many to drop depends on the specific case, but dropping the first half of the chain is usually good Dependence of the iterations in each sequence thinning a chain: keeping every \\(k\\)th simulation draw not necessary if the chains have converged can help with preserving RAM if many parameters Multiple sequences with overdispersed starting points use multiple chains to be able to compare with each other mixing and stationarity discussed below Monitoring scalar estimands check estimated parameter values and any other computed values of interest to see if their posterior distributions settle Challenges of monitoring convergence: missing and stationarity mixing: when the chains converge to the same distribution stationarity: when each chains has converged to a consistent distribution of values Splitting each saved sequence into two parts a method for checking convergence and stationarity of multiple chains: (after adjusting for warm-up) split each chain in half and check if all of the halves have mixed checks mixing: if all of the chains have mixed, the separate parts of the different chains should also have mixed checks stationarity: the first and second half of each sequence should be traversing the same distribution Assessing mising using between- and within-sequence variances calculations for mixing of the split chains: \\(m\\): number of chains after splitting; \\(n\\): length of each split chain \\(\\psi\\): each labeled estimand (parameter or calculated value of interest) label the simulations as \\(\\psi_{ij}\\) where \\((i=1, \\dots, n; j=1, \\dots, m)\\) between-sequence variance \\(B\\) (5.4) and within-sequence variance \\(W\\) (5.5) estimate \\(\\text{var}(\\psi|y)\\) as a weighted average of \\(B\\) and \\(W\\) (5.6) is actually an overestimate use \\(\\widehat{\\text{var}}^+(\\psi|y)\\) to calculate a factor by which the scale of the current distribution for \\(\\psi\\) might be reduced if the simulations were continued \\(\\widehat{R}\\) the calculation for \\(\\widehat{R}\\) has been updated since publishing BDA3 if \\(\\widehat{R}\\) is above 1, indicates that letting the chains run longer would improve inference using these calculations of variance is more reliable than visually checking for mixing, convergence, and stationarity using trace-plots is also more practical when there are many parameters (such as is common for hierarchical distributions) \\[\\begin{equation} B = \\frac{n}{m-1} \\sum_j^m (\\bar{\\psi}_{.j} - \\bar{\\psi}_{..})^2 \\\\ \\quad \\text{where} \\quad \\bar{\\psi}_{.j} = \\frac{1}{n} \\sum _i^n \\psi_{ij} \\quad \\text{and} \\quad \\bar{\\psi}_{..} = \\frac{1}{m} \\sum_j^m \\bar{\\psi}_{.j} \\tag{5.4} \\end{equation}\\] \\[\\begin{equation} W = \\frac{1}{m} \\sum_j^m s_j^2 \\quad \\text{where} \\quad s_j^2 = \\frac{1}{n-1} \\sum_i^n (\\psi_ij - \\bar{\\psi}_{.j})^2 \\tag{5.5} \\end{equation}\\] \\[\\begin{equation} \\widehat{\\text{var}}^+(\\psi|y) = \\frac{n-1}{n}W + \\frac{1}{n}B \\tag{5.6} \\end{equation}\\] 11.5 Effective number of simulation draws compute an approximate “effective number of independent simulation draws” \\(n_\\text{eff}\\) if all draws were truly independent, then \\(B \\approx \\text{var}(\\psi|y)\\) but usually draws of \\(\\psi\\) are autocorrelated and \\(B\\) will be larger than \\(\\text{var}(\\psi|y)\\) with non-normal posterior samples, may need to first transform the draws before calculating \\(n_\\text{eff}\\) and \\(\\widehat{R}\\) recommendation is to sample until \\(\\widehat{R} \\le 1.1\\) and \\(n_\\text{eff} \\ge 5m\\) where \\(m\\) is the number of split chains (i.e. \\(\\text{number of chains} \\times 2\\)) (pg. 287) 5.2.3 Lecture notes 5.1. Markov chain Monte Carlo, Gibbs sampling, Metropolis algorithm Gibbs sampler with conditionally conjugate priors, the sampling from the conditional distributions is easy for wide range of models software: BUGS, WinBUGS, OpenBUGS, JAGS benefit: no algorithm parameters to tune slow if parameters are highly dependent in the posterior the high correlation create a narrow region in which the sampler moves, slowing exploration of the posterior 5.2. Warm-up, convergence diagnostics, R-hat, and effective sample size \\(\\widehat{R}\\) with only a few draws and with many draws: Rhat-with-few-draws - update \\(\\widehat{R}\\) is rank normalized \\(\\widehat{R}\\) - original \\(\\widehat{R}\\) requires that the target distribution has finite mean and variance - rank normalized removes this requirement - improved detection of different scales between chains - the paper also proposes local convergence diagnostics and practical MCSE estimates for quantiles - autocorrelation in the chains (think of as a time series analysis) - describes the correlation given a certain lag - how many steps does it take for the chain to forget a previous step - can be used to compare efficiency of MCMC algorithms and parameterizations - in the example below, the autocorrelation plot shows that it takes about 40 steps to reach a correlation of 0 - the x-axis should be “lag” - calculating autocorrelation function - \\(\\hat{\\rho}_{n,m}\\) is the autocorrelation at lag \\(n\\) for chain \\(m\\) of \\(M\\) chains - can see the use of \\(W\\) and \\(\\widehat{\\text{var}}^+\\) from the calculation of \\(\\widehat{R}\\) so that is accounts for how well the chains mix \\[ \\hat{\\rho}_n = 1 - \\frac{W - \\frac{1}{M} \\sum_m^M \\hat{\\rho}_{n,m}}{2 \\widehat{\\text{var}}^+} \\] "],["section-6.-hmc-nuts-and-stan.html", "6 Section 6. HMC, NUTS, and Stan 6.1 Resources 6.2 Notes", " 6 Section 6. HMC, NUTS, and Stan 2021-10-04 6.1 Resources BDA3 chapter 12 and reading instructions lectures: ‘6.1 HMC, NUTS, dynamic HMC and HMC specific convergence diagnostics’ ‘6.2 probabilistic programming and Stan’ slides Assignment 6 6.2 Notes 6.2.1 Reading instructions Outline of the chapter 12 12.1 Efficient Gibbs samplers (not part of the course) 12.2 Efficient Metropolis jump rules (not part of the course) 12.3 Further extensions to Gibbs and Metropolis (not part of the course) 12.4 Hamiltonian Monte Carlo (used in Stan) 12.5 Hamiltonian dynamics for a simple hierarchical model (read through) 12.6 Stan: developing a computing environment (read through) Hamiltonian Monte Carlo review of static HMC (the number of steps in dynamic simulation are not adaptively selected) is Neal (2012) Stan uses a variant of dynamic Hamiltonian Monte Carlo (using adaptive number of steps in the dynamic simulation), which has been further developed since BDA3 was published The first dynamic HMC variant was by Hoffman and Gelman (2011) The No-U-Turn Sampler (NUTS) is often associated with Stan, but the current dynamic HMC variant implemented in Stan has some further developments described (mostly) by Betancourt (2017) Instead of reading all above, you can also watch a video: Scalable Bayesian Inference with Hamiltonian Monte Carlo by Betancourt Divergences and BFMI divergences and Bayesian Fraction of Missing Information (BFMI) are HMC specific convergence diagnostics developed by Betancourt after BDA3 was published Divergence diagnostic checks whether the discretized dynamic simulation has problems due to fast varying density. See more in a case study BFMI checks whether momentum resampling in HMC is sufficiently efficient (Betancourt 2016) Brief Guide to Stan’s Warnings provides summary of available convergence diagnostics in Stan and how to interpret them. 6.2.2 Chapter 12. Computationally efficient Markov chain simulation (skipping sections 12.1-12.3) 12.4 Hamiltonian Monte Carlo random walk of Gibbs sampler and Metropolis algorithm is inherently inefficient Hamiltonian Monte Carlo (HMC) uses “momentum” to suppress the local random walk behavior of the Metropolis algorithm such that is moves more rapidly through the target distribution for each component \\(\\theta_j\\) in the target space, there is a corresponding momentum variable \\(\\phi_j\\) the posterior density \\(p(\\theta|y)\\) is augmented by an independent distribution \\(p(\\phi|y)\\) on the momentum: \\(p(\\theta, \\phi | y) = p(\\phi) p(\\theta | y)\\) to compute the momentum, HMC requires the gradient of the log-posterior density in practice, this is computed analytically The momentum distribution \\(p(\\phi)\\) common to use a multivariate normal distribution with mean 0 and a diagonal mass matrix \\(M\\) \\(\\phi_j \\sim \\text{N}(0, M_{jj})\\) for each \\(j = 1, \\dots, d\\) ideally, the mass matrix should scale with the inverse covariance matrix of the posterior distribution \\((\\text{var}(\\theta|y))^{-1}\\) The three steps of an HMC iteration update \\(\\phi\\) by sampling from its posterior (same as its prior): \\(\\phi \\sim \\text{N}(0, M)\\) simultaneously update \\(\\theta\\) and \\(\\phi\\) using a leapfrog algorithm to simulate physical Hamiltonian dynamics where the position and momentum evolve continuously; for \\(L\\) leapfrog steps with scaling factor \\(\\epsilon\\): use the gradient of the log-posterior density of \\(\\theta\\) to make a half-step of \\(\\phi\\): \\(\\phi \\leftarrow \\phi + \\frac{1}{2} \\epsilon \\frac{d \\log p(\\theta|y)}{d \\theta}\\) use the momentum \\(\\phi\\) to update position \\(\\theta\\): \\(\\theta \\leftarrow \\theta + \\epsilon M^{-1} \\phi\\) use the gradient of \\(\\theta\\) for the second half-step of \\(\\phi\\): \\(\\phi \\leftarrow \\phi + \\frac{1}{2} \\epsilon \\frac{d \\log p(\\theta|y)}{d \\theta}\\) calculate the accept/reject ratio \\(r\\) (6.1) set \\(\\theta^t = \\theta^*\\) with probability \\(\\min(r, 1)\\), else reject the proposed \\(\\theta\\) and set \\(\\theta^t = \\theta^{t-1}\\) \\[\\begin{equation} r = \\frac{p(\\theta^*, \\phi^* | y)}{p(\\theta^{t-1}, \\phi^{t-1} | y)} = \\frac{p(\\theta^*|y) p(\\phi^*)}{p(\\theta^{t-1}|y) p(\\phi^{t-1})} \\tag{6.1} \\end{equation}\\] Pause here and watch video on HMC by Betancourt: Scalable Bayesian Inference with Hamiltonian Monte Carlo. 12.5 Hamiltonian Monte Carlo for a hierarchical model (Walks through the process of deciding on model and HMC parameters and tuning \\(\\epsilon\\) and \\(L\\) for HMC.) 12.6 Stan: developing a computing environment (Very briefly describes Stan.) 6.2.3 Lecture notes 6.1 HMC, NUTS, dynamic HMC and HMC specific convergence diagnostics Definitely worth looking at the visualizations in this blog post: Markov Chains: Why Walk When You Can Flow? Interactively play with HMC and NUTS: MCMC demo Hamiltonian Monte Carlo uses gradient of log density for more efficient sampling of the posterior parameters: step size \\(\\epsilon\\), number of steps in each chain \\(L\\) if step size is too large, then the chain can get further and further away from the high density regions leading to “exploding error” can experiment with this in the simulation linked above No U-Turn Sampling (NUTS) and dynamic HMC adaptively selects the number of steps to improve robustness and sampling efficiency “dynamic” HMC refers to dynamic trajectory length to maintain “reversibility” condition for the Markov chain, must simulate in two directions dynamic HMC in Stan use a growing tree to increase simulation trajectory until no-U-turn stopping criterion there is a max tree depth parameter to control the size of this pick a draw along the trajectory with probability adjusted to account for the error in discretized dynamic simulation and higher probability for parts further away from the start therefore, don’t always end up at the end of the trajectory, but usually somewhere near the end Stan can also adjust the mass matrix to “reshape” the posterior to make more circular and reduce correlations between parameters to make sampling faster and more efficient occurs during the initial adaptation in the warm-up max tree depth diagnostic indicates inefficiency in sampling leading to higher autocorrelation and lower ESS possibly step size is too small different parameterizations matter divergences HMC specific indicates that there are unexpectedly fast changes in log-density comes from exploding error where the chain leaves high-density regions of the posterior and gets lost in other directions occurs in funnel geometries common in hierarchical models because in the neck of the funnel, the high-density region is so thin, the trajectory can easily leave and enter a very low-density region problematic distributions Nonlinear dependencies simple mass matrix scaling doesn’t help Funnels optimal step size depends on location can get stuck in the neck of the funnel causing divergences Multimodal difficult to move from one mode to another can be seen if multiple chains end up in different locations Long-tailed with non-finite variance and mean efficiency of exploration is reduced central limit theorem doesn’t hold for mean and variance 6.2 probabilistic programming and Stan example: Binomial model data { int &lt;lower=0&gt; N; // number of experiments int&lt;lower=0,upper=N&gt; y; // number of successes } parameters { real &lt;lower=0,upper=1&gt; theta ; // parameter of the binomial } model { theta ~ beta(1,1); //prior y ~ binomial (N, theta ); // observation model } example: running Stan from R library (rstan) rstan_options(auto_write = TRUE) options(mc.cores = parallel ::detectCores()) d_bin &lt;- list(N = 10, y = 7) fit_bin &lt;- stan(file = &quot;binom.stan&quot;, data = d_bin) example: running Stan from Python import pystan import stan_utility data = {&quot;N&quot;: 10, &quot;y&quot;: 8} model = stan_utility.compile_model(&#39;binom.stan&#39;) fit = model.sampling(data=data) example: Difference between proportions data { int&lt;lower=0&gt; N1; int&lt;lower=0&gt; y1; int&lt;lower=0&gt; N2; int&lt;lower=0&gt; y2; } parameters { real &lt;lower=0,upper=1&gt; theta1; real &lt;lower=0,upper=1&gt; theta2; } model { theta1 ~ beta(1,1); theta2 ~ beta(1,1); y1 ~ binomial(N1,theta1); y2 ~ binomial(N2,theta2); } generated quantities { real oddsratio; oddsratio = (theta2 / (1 - theta2)) / (theta1 / (1 - theta1)) } some HMC-specific diagnostics with ‘rstan’ check_treedepth(fit_bin2) check_energy(fit_bin2) check_div(fit_bin2) example of scaling data in the Stan language data { int&lt;lower=0&gt; N; // number of data points vector[N] x; vector[N] y; real xpred; // input location for prediction } transformed_data { vector[N] x_std; vector[N] y_std; real xpred_std; x_std = (x - mean(x)) / sd(x); y_std = (y - mean(y)) / sd(y); xpred_std = (xpred - mean(x)) / sd(x); } other useful R packages worth looking into: ‘rstanarm’ and ‘brms’: for quickly building models with the R formula language ‘shinystan’: interactive diagnostics ‘bayesplot’: visualization and model checking (see model checking in Ch 6) ‘loo’: cross-validation model assessment, comparison and averaging (see Ch 7) ‘projpred’: projection predictive variable selection References "],["section-7.-hierarchical-models-and-exchangeability.html", "7 Section 7. Hierarchical models and exchangeability 7.1 Resources 7.2 Notes", " 7 Section 7. Hierarchical models and exchangeability 2021-10-12 7.1 Resources BDA3 chapter 5 and reading instructions lectures: ‘7.1. Hierarchical models’ ‘7.2. Exchangeability’ slides Assignment 7 7.2 Notes 7.2.1 Reading instructions “The hierarchical models in the chapter are simple to keep computation simple. More advanced computational tools are presented in Chapters 10-12 (part of the course) and 13 (not part of the course).” Exchangeability vs. independence exchangeability and independence are two separate concepts; neither necessarily implies the other independent identically distributed variables/parameters are exchangeable exchangeability is less strict condition than independence Weakly informative priors for hierarchical variance parameters suggestions have changed since writing section 5.7 section 5.7 recommends use of half-Cauchy as weakly informative prior for hierarchical variance parameters now recommend a “half-normal if you have substantial information on the high end values, or or half-\\(t_4\\) if you there might be possibility of surprise” “half-normal produces usually more sensible prior predictive distributions and is thus better justified” “half-normal leads also usually to easier inference” 7.2.2 Chapter 5. Hierarchical models individual parameters for groups can be modeled as coming from a population distribution model these relationships hierarchically hierarchical models can often have more parameters than data but avoid overfitting of traditional linear models sections 5.2: how to construct a hierarchical prior distribution in the context of a fully Bayesian analysis 5.7: weakly informative priors 1. Constructing a parameterized prior distribution have historical data to inform our model can use it to construct a prior for our new data or use it as data to inform the posterior probably should not use it for both though, thus favor using it directly in the model alongside our new data for each experiment \\(j\\), with data \\(y_j\\), estimate the parameter \\(\\theta_j\\) the parameters \\(\\theta_j\\) can come from a population distribution parameterized by \\(\\text{Beta}(\\alpha, \\beta)\\) hierarchical structure graph 5.2 Exchangeability and hierarchical models if no information (other than \\(y\\)) is available to distinguish any of the \\(\\theta_j\\)’s, and no ordering (time) or grouping can be made, then we must assume symmetry among the parameters in the prior distribution this symmetry is represented probabilistically by exchangeability: the parameters \\((\\theta_1, \\dots, \\theta_J)\\) are exchangeable in the join distribution if \\(p(\\theta_1, \\dots, \\theta_J)\\) is invariant to permutations of the indices \\((1, \\dots, J)\\) “in practice, ignorance implies exchangeability” (pg. 104) the less we know about a problem, the more confident we can claim exchangeability (i.e. we don’t know any better) exchangeability is not the same as i.i.d: probability of a die landing on each face: parameters \\((\\theta_1, \\dots, \\theta_6)\\) are exchangeable because we think the faces are all the same, but they are not independent because the total must sum to 1 exchangeability when additional information is available on the groups if the observations can be grouped in their own submodels, but the group properties are unknown, can make a common prior distribution for the group properties if \\(y_i\\) has additional information \\(x_i\\) so that \\(y_i\\) are not exchangeable, but \\((y_i, x_i)\\) are exchangeable, we can make a join model for \\((y_i, x_i)\\) or a conditional model \\(y_i | x_i\\) the usual way to model exchangeability with covariates is through conditional independence \\[ p(\\theta_1, \\dots, \\theta_J | x_1, \\dots, x_J) = \\int [\\prod_{j=1}^J p(\\theta_j | \\phi, x_j)] p(\\phi|x) d \\phi \\] \\(phi\\) is unknown, so it gets a prior distribution, too \\(p(\\phi)\\) the posterior distribution is of the vector \\((\\phi, \\theta)\\) thus the joint prior is: \\(p(\\phi, \\theta) = p(\\phi) p(\\theta|\\phi)\\) joint posterior: \\[ \\begin{aligned} p(\\phi, \\theta | y) &amp;\\propto p(\\phi, \\theta) p(y|\\phi, \\theta) \\\\ &amp;= p(\\phi, \\theta) p(y|\\theta) \\end{aligned} \\] posterior predictive distributions get predictions on both levels 5.3 Bayesian analysis of conjugate hierarchical models analysis derivation of conditional and marginal distributions write the (unnormalized) joint posterior density \\(p(\\theta, \\phi | y)\\) as a product of the hyperprior \\(p(\\phi)\\), the population distribution \\(p(\\theta|\\phi)\\) and the likelihood \\(p(y|\\theta)\\) determine the conditional posterior density of \\(\\theta\\) given \\(\\phi\\): \\(p(\\theta | \\phi, y)\\) estimate \\(\\phi\\) from its marginal posterior distribution \\(p(\\phi|y)\\) drawing simulations from the posterior distribution draw \\(\\phi\\) from \\(p(\\phi|y)\\) draw \\(\\theta\\) from its conditional posterior distribution \\(p(\\theta | \\phi, y)\\) using the values of \\(\\phi\\) from the previous step draw predictive values \\(\\tilde{y}\\) given the values of \\(\\theta\\) example on rat tumors is a good demonstration of the shrinkage of parameter estimates in a hierarchical model the 1:1 line represents where the posteriors would be for a non-pooling model can see the shrinkage of the extreme values towards the average the effect is stronger for experiments with fewer rats rat tumor model posterior 5.4 Normal model with exchangeable parameters drawing posterior predictive samples: for new data \\(\\tilde{y}\\) of existing groups \\(J\\), use the posterior distributions for \\((\\theta_1, \\dots, \\theta_j)\\) for new data \\(\\tilde{y}\\) for \\(\\tilde{J}\\) new groups: draw values for the hyperparameters \\(\\mu, \\tau\\) (in this case) draw \\(\\tilde{J}\\) new parameters \\((\\tilde{\\theta}_1, \\dots, \\tilde{\\theta}_\\tilde{J})\\) from \\(p(\\tilde{\\theta} | \\mu, \\tau)\\) draw \\(\\tilde{y}\\) given \\(\\tilde{\\theta}\\) 5.5 Example: parallel experiments in eight schools a full example of a Bayesian hierarchical modeling process and analysis 5.6 Hierarchical modeling applied to a meta-analysis another good example of analyzing the results of a Bayesian hierarchical model notes the importance of interpreting both the mean and standard error hyperparameters to interpret the distribution of possible parameter values 5.7 Weakly informative priors for variance parameters “It turns out the the choice of ‘noninformative’ prior distribution can have a big effect on inferences,” (pg. 128) uniform prior distributions will often lead to overly-dispersed posteriors this is especially true for the standard error term of a hyperparameter when there are few groups half-Cauchy is often a good balance between restricting the prior to reasonable value but with fat enough tails to allow for uncertainty particularly good for variance parameters of hierarchical models with few groups 7.2.3 Lecture notes ‘7.1. Hierarchical models’ description of the diagram of a hierarchical model box: known value double box: indicates a fixed experimental value (e.g. decided how many rats to include in an experiment) circle: unknown parameter box with the subscript \\(j\\): indicates that everything within the box is repeated \\(J\\) times hierarchical box diagram hierarchical model shrinkage effects with sample size below example shows how shrinkage is stronger for data points with smaller sample size (county radon example) chrinkage with sample size below, I replicate the 8-schools model in Stan and try to make the plot of \\(\\theta\\) over \\(\\tau\\) library(rstan) #&gt; Loading required package: StanHeaders #&gt; Loading required package: ggplot2 #&gt; rstan (Version 2.21.2, GitRev: 2e1f913d3ca3) #&gt; For execution on a local, multicore CPU with excess RAM we recommend calling #&gt; options(mc.cores = parallel::detectCores()). #&gt; To avoid recompilation of unchanged Stan programs, we recommend calling #&gt; rstan_options(auto_write = TRUE) library(tidybayes) suppressPackageStartupMessages(library(tidyverse)) options(mc.cores = 2) rstan_options(auto_write = TRUE) schools_data &lt;- list( J = 8, y = c(28, 8, -3, 7, -1, 1, 18, 12), sigma = c(15, 10, 16, 11, 9, 11, 10, 18) ) eight_schools &lt;- stan( file = here::here(&quot;models&quot;, &quot;8-schools.stan&quot;), data = schools_data, chains = 4, warmup = 1000, iter = 2000, cores = 2, refresh = 0 ) eight_schools #&gt; Inference for Stan model: 8-schools. #&gt; 4 chains, each with iter=2000; warmup=1000; thin=1; #&gt; post-warmup draws per chain=1000, total post-warmup draws=4000. #&gt; #&gt; mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat #&gt; mu 7.93 0.10 5.11 -2.36 4.67 7.87 11.05 18.19 2776 1 #&gt; tau 6.51 0.13 5.48 0.18 2.45 5.28 9.10 20.66 1651 1 #&gt; eta[1] 0.37 0.01 0.97 -1.62 -0.26 0.38 1.04 2.22 4447 1 #&gt; eta[2] 0.01 0.01 0.86 -1.71 -0.54 0.00 0.56 1.73 5131 1 #&gt; eta[3] -0.20 0.01 0.91 -2.00 -0.80 -0.22 0.41 1.61 5300 1 #&gt; eta[4] -0.04 0.01 0.88 -1.80 -0.63 -0.05 0.55 1.70 4508 1 #&gt; eta[5] -0.33 0.01 0.86 -1.98 -0.91 -0.36 0.23 1.43 4005 1 #&gt; eta[6] -0.20 0.01 0.89 -1.95 -0.79 -0.21 0.37 1.63 4784 1 #&gt; eta[7] 0.33 0.01 0.90 -1.49 -0.27 0.38 0.93 2.07 4682 1 #&gt; eta[8] 0.05 0.01 0.92 -1.78 -0.54 0.06 0.66 1.87 5721 1 #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 9 rows ] #&gt; #&gt; Samples were drawn using NUTS(diag_e) at Tue Feb 8 07:01:41 2022. #&gt; For each parameter, n_eff is a crude measure of effective sample size, #&gt; and Rhat is the potential scale reduction factor on split chains (at #&gt; convergence, Rhat=1). theta_tau_post &lt;- eight_schools %&gt;% spread_draws(theta[school], tau) %&gt;% mutate(school = purrr::map_chr(school, ~ LETTERS[[.x]])) theta_tau_post %&gt;% filter(tau &lt; 20) %&gt;% arrange(tau) %&gt;% ggplot(aes(x = tau, y = theta, color = school)) + geom_smooth( method = &quot;loess&quot;, formula = &quot;y ~ x&quot;, n = 250, size = 0.8, alpha = 0.1 ) + scale_x_continuous(expand = expansion(c(0, 0))) + scale_y_continuous(expand = expansion(c(0.02, 0.02))) + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set1&quot;) + theme_classic() ‘7.2. Exchangeability’ exchangeability: parameters \\(\\theta_1, \\dots ,\\theta_J\\) (or observations \\(y_1, \\dots , y_J\\)) are exchangeable if the joint distribution \\(p\\) is invariant to the permutation of indices \\((1, \\dots, J)\\) e.g.: \\(p(\\theta_1, \\theta_2, \\theta_3) = p(\\theta_2, \\theta_3, \\theta_1)\\) exchangeability implies symmetry if there is no information which can be used a priori to separate \\(\\theta_j\\) form each other, we can assume exchangeability ”Ignorance implies exchangeability” "],["section-8.-model-checking-cross-validation.html", "8 Section 8. Model checking &amp; Cross-validation 8.1 Resources 8.2 Notes", " 8 Section 8. Model checking &amp; Cross-validation 2021-10-31 8.1 Resources reading: BDA3 ch. 6 “Model checking” and ch. 6 reading instructions BDA3 ch. 7 “Evaluating, comparing, and expanding models” and ch. 7 reading instructions read Visualization in Bayesian workflow (pdf, link) read Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC (pdf, link) additional reading material: Model assesment, selection and inference after selection Cross-validation FAQ lectures: ‘Lecture 8.1. Model Checking’ ‘Lecture 8.2. Cross-Validation (part 1)’ slides: ch 6 slides ch 7 slides 8.2 Notes 8.2.1 Chapter 6 reading instructions Replicates vs. future observation predictive \\(\\tilde{y}\\): the next yet unobserved possible observation \\(y^\\text{rep}\\): replicating the whole experiment (with same values of \\(x\\)) and obtaining as many replicated observations as in the original data Posterior predictive p-values do not recommend p-values any more especially in a form of hypothesis testing Prior predictive checking using just the prior predictive distributions for assessing the sensibility of the model and priors before observing any data 8.2.2 Chapter 6. Model checking 6.1 The place of model checking in applied Bayesian statistics must assess the fit of a model to the data and to our substantive domain knowledge Sensitivity analysis and model improvement sensitivity analysis: “how much do posterior inference change when other reasonable probability models are used in place of the present model?” (pg. 141) Judging model flaws by their practical implications not interested in if the model is true or false - will likely always be false more interested in the question: “Do the model’s deficiencies have a noticeable effect on the substantive inferences?” (pg. 142) keep focus on the more important parts of the model, too 6.2 Do the inferences from the model make sense? there will be knowledge that is not included in the model if the additional information suggests that posterior inferences are false, this suggests an option for improving the model’s accuracy External validation external validation: “using the model to make predictions about future data, and then collecting those data and comparing to their predictions” (pg. 142) 6.3 Posterior predictive checking if the model fits, then generated replicate data should look like the observed data “the observed data should look plausible under the posterior predictive distribution” (pg. 143) is a self-consistency check important to choose test quantities that are of interest of the goals of the model may be inaccurate in some regards, but the relevance should be taken into account need not worry about adjusting for multiple comparisons: “We are not concerned with ‘Type I error’ rate… because we use the checks not to accept or reject a model but rather to understand the limits of its applicability in realistic replications.” (pg. 150) 6.4 Graphical posterior predictive checks three types of graphical display to start a posterior predictive check: direct display of all the data may need to get clever with how to do this effectively display of data summaries or parameter inferences useful when dataset is very large or want to focus on a particular part of the model graphs of residuals or other measures of discrepancy between the model and data description of how to do this effectively for discrete data 6.5 Model checking for the educational testing example check that posterior parameter values and predictions are reasonable compare summary statistics of real data and predictive distributions min. and max. values, averages, skewness sensitivity analysis can assuage concerns that the outcome was not determined by specific choices of priors 8.2.3 Chapter 6. Lecture notes Lecture 8.1. Model Checking model checking overview: Sensibility with respect to additional information not used in modeling e.g., if posterior would claim that hazardous chemical decreases probability of death External validation compare predictions to completely new observations compare to theoretical values e.g., relativity theory predictions on the speed of light (not based on model optimized to data) Internal validation posterior predictive checking cross-validation predictive checking example of posterior checks with air quality model examples with binary data and logistic regression get posterior predictive distribution in Stan: data { int&lt;lower=1&gt; N; int&lt;lower=0&gt; y[N]; } parameters { real&lt;lower=0&gt; lambda; } model { lambda ~ exponential(0.2); y ~ poisson(lambda); } generated_quantities { real log_lik[N]; int y_rep[N]; for (n in 1:N) { y_rep[n] = poisson_rng(lambda); log_lik[n] = poisson_lpmf(y[n] | lambda); } } 8.2.4 Chapter 7 reading instructions reading 7.1 Measures of predictive accuracy 7.2 Information criteria and cross-validation replace with: Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC (Vehtari, Gelman, and Gabry 2017b) 7.3 Model comparison based on predictive performance replace with: Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC (Vehtari, Gelman, and Gabry 2017b) 7.4 Model comparison using Bayes factors 7.5 Continuous model expansion / sensitivity analysis 7.6 Example (may be skipped) extra material LOO package glossary summarizes many important terms used in the assignments (Vehtari et al. 2020) (Vehtari, Gelman, and Gabry 2017a) (Yao et al. 2017) article discussing “How should I evaluate my modelling choices?”: Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. (Navarro 2019) website about model selection by Vehtari: Model assesment, selection and inference after selection sections 1 &amp; 5 of Uncertainty in Bayesian Leave-One-Out Cross-Validation Based Model Comparison (Sivula, Magnusson, and Vehtari 2020) clarify how to interpret standard error in model comparison A survey of Bayesian predictive methods for model assessment, selection and comparison. (Vehtari and Ojanen 2012) Comparison of Bayesian predictive methods for model selection. (Piironen and Vehtari 2017) 8.2.5 Chapter 7. Evaluating, comparing, and expanding models goal of this chapter is not to check model fit but to compare models and explore directions for improvement 7.1 Measures of predictive accuracy can use predictive accuracy for comparing models log predictive density: the logarithmic score for predictions is the log predictive density \\(\\log p(y|\\theta)\\) expected log predictive density as a measure of overall model fit external validation: ideally, would check a model’s fit on out-of-sample (new) data Averaging over the distirbution of future data expected log predictive density (elpd) for a new data point: where \\(f\\) is the true data-generating process and \\(p_\\text{post}(y)\\) is the posterior probability of \\(y\\) \\(f\\) is usually unknown \\[ \\text{elpd} = \\text{E}_f(\\log p_\\text{post}(\\tilde{y}_i)) = \\int (\\log p_\\text{post}(\\tilde{y}_i)) f(\\tilde{y}_i) d\\tilde{y} \\] for a new dataset (instead of a single point) of \\(n\\) data points kept as pointwise so can be related to cross-validation \\[ \\text{elppd} = \\text{expected log pointwise predictive density} = \\sum_{i=1}^{n} \\text{E}_f (\\log p_\\text{post}(\\tilde{y}_i)) \\] Evaluating predictive accuracy for a fitted model in practice, we do not know \\(\\theta\\) so cannot know the log predictive density \\(\\log p(y|\\theta)\\) want to use the posterior distribution \\(p_\\text{post}(\\theta) = p(\\theta|y)\\) and summarize the predictive accuracy of a fitted model to data: \\[ \\begin{aligned} \\text{lppd} &amp;= \\text{log pointwise predictive density} \\\\ &amp;= \\log \\prod_{i=1}^{n} p_\\text{post}(y_i) \\\\ &amp;= \\sum_{i=1}^{n} \\log \\int p(y_i|\\theta) p_\\text{post}(\\theta) d\\theta \\end{aligned} \\] to actually compute lppd, evaluate the expectation using the draws from \\(p_\\text{post}(\\theta)\\), \\(\\theta^s\\): this equation is a biased version of elppd so need to correct it (next section in information criteria) \\[ \\begin{aligned} \\text{computed lppd} &amp;= \\text{computed log pointwise predictive density} \\\\ &amp;= \\sum_{i=1}^{n} \\log \\lgroup \\frac{1}{S} \\sum_{s=1}^{S} p(y_i|\\theta^s) \\rgroup \\end{aligned} \\] 7.2 Information criteria and cross-validation historically, measures of predictive accuracy are referred to as information criteria are typically defined based on the deviance Estimating out-of-sample predictive accuracy using available data estimate the expected predictive accuracy without waiting for new data some reasonable approximations for out-of-sample predictive accuracy within-sample predictive accuracy: “naive estimate of the expected log predictive density for new data is the log predictive density for existing data” (pg 170) adjusted within-sample predictive accuracy: information criteria such as WAIC cross-validation: estimate out-of-sample prediction error by fitting to training data and evaluating predictive accuracy on the held-out data descriptions of Akaike information criterion (AIC), deviance information criterion (DIC), and Watanabe-Akaike information criterion (or widely applicable information criterion; WAIC) DIC and WAIC try to adjust for the effective number of parameters WAIC is the best for Bayesian because it uses the full posterior distributions, not point estimates there are actually two formulations for WAIC, and Gelman et al. recommend the second form they describe Effective number of parameters as a random variable DIC and WAIC adjust the effective number of parameters according to the model structure and the data the latter seems unintuitive example: image a simple model: \\(y_i, \\dots, y_n \\sim N(\\theta, 1)\\) with \\(n\\) large and \\(\\theta \\sim U(0, \\infty)\\) \\(\\theta\\) is constrained to be positive but is otherwise uninformed if the measure of \\(y\\) is near 0, then the effective number of parameters \\(p\\) is effectively \\(\\frac{1}{2}\\) because the prior removed all negative values if the measure of \\(y\\) is a large positive value, then the constraint by the prior is unimportant and the effective number of parameters \\(p\\) is essentially 1 Bayesian information criterion (BIC) is not comparable to AIC, DIC, and WAIC as it serves a different purpose more discussion on pg. 175 7.3 Model comparison based on predictive performance in comparing “nested” models, the large model is often better fit, but is more difficult to understand and compute “nested” models are where one contains the structure of the other and a little more either broader priors or additional parameters key questions of model comparison: Is the improvement in fit large enough to justify the additional difficulty of fitting? Is the prior distribution on the additional parameters reasonable? for non-nested models, not typically interested in choosing one over the other, but more interested in seeing the differences between them ideally, could construct a single model containing both of the non-nested models authors recommend using LOO-=CV where possible and WAIC, otherwise (pg. 182) 7.4 Model comparison using Bayes factor generally not recommended (pg. 182 for reasons why) 7.5 Continuous model expansion posterior distributions of model parameters can either overestimate or underestimate different aspects of the “true” posterior uncertainty overestimate uncertainty because the model usually does not contain all of one’s substantive knowledge underestimate uncertainty by the model is almost always wrong (i.e. imperfect) - the reason for posterior predictive checking other reasonable models could have fit the data equally well - the reason for sensitivity analysis Adding parameters to a model reasons to expand a model: add knew parameters if the model does not fit the data or prior knowledge in some important way the class of models can be broadened if some modeling assumption was unfounded if two different models are under consideration, they can be combined into a larger model with a continuous parameterization that includes both models as special cases e.g. complete-pooling and no-pooling can be combined into a hierarchical model expanding a model to include new data Practical advice for model checking and expansion examine posterior distributions of substantively important parameters and predicted quantities e.g. number of zeros in a count model maximum and minimum predicted values compare posterior distributions and posterior predictions with substantive knowledge this includes the observed data 8.2.6 Additional Reading Visualization in Bayesian workflow (pdf, link) the phases of statistical workflow: exploratory data analysis aid in setting up an initial model computational model checks using fake-data simulation and the prior predictive distribution computational checks to ensure the inference algorithm works reliably posterior predictive checks and other juxtapositions of data and predictions under the fitted model model comparison via tools such as cross-validation 3. Fake data can be almost as valuable as real data for building your model visualize simulations from the prior marginal distribution of the data to assess the consistency of the chosen priors with domain knowledge weakly informative prior: if draws from the prior data generating distribution \\(p(y)\\) could represent any dataset that could plausibly be observed this prior predictive distribution for the data has at least some mass around extreme but plausible data sets there should be no mass on completely implausible data sets generate a “flip book” of simulated datasets that can be used to investigate the variability and multivariate structure of the distribution 4. Graphical Markov chain Monte Carlo diagnostics: moving beyond trace plots catching divergent draws heuristically is a powerful feature of HMC sometimes get falsely flagged, so must check that the divergences were infact outside of the typical set two additional plots for diagnosing troublesome areas of the parameter space bivariate scatterplots that highlight divergent transitions bad sign: if the divergences were clustered parallel coordinate plot bad sign: the divergences would have similar structure mcmc-diagnositcs-fig 5. How did we do? Posterior predictive checks are vital for model evaluation “The idea behind posterior predictive checking is simple: if a model is a good fit we should be able to use it to generate data that resemble the data we observed” “can also perform similar checks within levels of a grouping variable” check that predictions are calibrated using LOO-CV predictive cumulative density function values which should be uniform (for continuous data) 6. Pointwise plots for predictive model comparison identify unusual points in the data are other either outliers or points with high leverage indicate how the model can be modified to better fut the data main tool for this analysis is the LOO predictive distribution \\(p(y_i|y_{-i})\\) examine LOO log-predictive density values to find observations that are difficult to predict can be used for model comparison by checking which model best captures each held-out data point also compare the full data log-posterior predictive density against each LOO log-predictive density to see which data points are difficult to model but not very influential this is automatically calculated in PSIS-LOO as the parameter \\(\\hat{k}\\) Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC (pdf, link) Here we lay out fast and stable computations for LOO and WAIC that can be performed usingexisting simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in thefinite case with weak priors or influential observations. Introduction exact CV requires re-fitting the model with every new training set can approximate this with LOO-CV using importance sampling, but results can be very noisy use Pareto smoothed importance sampling (PSIS) to calculate a more accurate and stable estimate fit a Pareto distribution to the upper tail of the distribution of the importance weights this paper demonstrates that PSIS-LOO is better than WAIC in the finite case also provide diagnostics for which method, WAIC or PSIS-LOO, is better or whether k-fold CV should be used instead Estimating out-of-sample pointwise predictive accuracy using posterior simulations posterior predictive distribution: \\(p(\\tilde{y}|y) = \\int p(\\tilde{y}_i|\\theta) p(\\theta|y) d\\theta\\) expected log pointwise predictive density (ELPD) measure of predictive accuracy for the \\(n\\) data points in a dataset \\(p_t(\\tilde{y}_i)\\): distribution of the true data-generating process for \\(\\tilde{y}_i\\) \\(p_t(\\tilde{y}_i)\\) is usually unknown so CV and WAIC are used to approximate ELPD \\[ \\text{elpd} = \\sum_{i=1}^n \\int p_t(\\tilde{y}_i) \\log p(\\tilde{y}_i|y) d\\tilde{y}_i \\] useful quantity is the log pointwise predictive density (LPD) “The LPD of observed data \\(y\\) is an overestimate of the ELPD for future data.” \\[ \\text{lpd} = \\sum_{i=1}^n \\log p(y_i|y) = \\sum_{i=1}^n \\int p(y_i|\\theta) p(\\theta|y) d\\theta \\] to compute LPD in practice, evaluate the expectation using draws for the posteior \\(p_\\text{post}(\\theta)\\), \\(\\theta^s\\) for \\(s = 1, \\dots, S\\) \\(\\widehat{lpd}\\): computed log pointwise predictive density \\[ \\widehat{lpd} = \\sum_{i=1}^n \\lgroup \\frac{1}{S} \\sum_{s=1}^S p(y_i|\\theta^s) \\rgroup \\] ##### Pareto smoothed importance sampling {-} fit the right tail of importance weights to smooth the values The estimated shape parameter \\(\\hat{k}\\) of the generalized Pareto distribution can be used to assessthe reliability of the estimate: \\(k &lt; \\frac{1}{2}\\): the variance of the raw importance ratios is finite, the central limit theorem holds, and the estimate converges quickly \\(\\frac{1}{2} &lt; k &lt; 1\\): the variance of the raw importance ratios is infinite but the mean exists, the generalized central limit theorem for stable distributions holds, and the convergence of the estimate is slower the variance of the PSIS estimate is finite but may be large \\(k &gt; 1\\): the variance and the mean of the raw ratios distribution do not exist the variance of the PSIS estimate is finite but may be large “If the estimated tail shape parameter \\(\\hat{k}\\) exceeds 0.5, the user should be warned, although in practice we have observed good performance for values of\\(\\hat{k}\\) up to 0.7.” if the PSIS estimate has a finite variance, when \\(\\hat{k} &gt; 0.7\\) the user should consider: sampling directly from \\(p(\\theta^s|y_{−i})\\) for the problematic \\(i\\), use k-fold CV, or use a more robust model Model assesment, selection and inference after selection (link) Cross-validation FAQ (link) 8.2.7 Chapter 7. Lecture notes Lecture 8.2. Cross-Validation (part 1) predictive performance true predictive performance can be found by making predictions on new data and comparing to true observation external validation expected predictive performance as an approximation calculating the posterior predictive density for a data point: generate a posterior predictive distribution for the data point find the density of the distribution at the actual observed value good walk-through of calculating posterior predictive distributions and LOO analyses some discussion of making predictions in parts of \\(x\\) not in the data set e.g. predictions in the future of time series models References "],["section-9.-model-comparison-and-selection.html", "9 Section 9. Model comparison and selection 9.1 Resources 9.2 Notes", " 9 Section 9. Model comparison and selection 2021-11-09 9.1 Resources BDA3 chapter 7 and reading instructions lectures: ‘9.1 PSIS-LOO and K-fold-CV’ ‘9.2 Model comparison and selection’ ‘9.3 Variable selection with projection predictive variable selection’ slides: chapter 7b Assignment 8 9.2 Notes See notes for course section 8 for notes on ch. 7 of BDA3. 9.2.1 Lecture notes 9.1 PSIS-LOO and K-fold CV PSIS-LOO CV given some data \\(x\\) and observed \\(y\\) sample from posterior: \\(\\theta^{(s)} \\sim p(\\theta | x, y)\\) compute the predictive density for new \\(\\tilde{x}\\) and \\(\\tilde{y}\\): \\(p(\\tilde{y} | \\tilde{x}, x, y) \\approx \\frac{1}{S} \\sum_{s=1}^S p(\\tilde{y} | \\tilde{x} \\theta^{(s)})\\) LOO-CV but weighting the draws using importance sampling: importance ratio: \\(r_i^{(s)} = p(\\theta^{(s)} | x_{-i}, y_{-i}) / p(\\theta^{(s)} | x,y)\\) the ratio of the posterior without \\(x_i\\) and \\(y_i\\) to the full posterior distribution get higher \\(r_i\\) (more importance) for draws \\(s\\) where the probabilities are higher without the data points \\(i\\) than with them \\(r_i^{(s)} = p(\\theta^{(s)} | x_{-i}, y_{-i}) / p(\\theta^{(s)} | x,y) \\propto 1 / p(y_i|x_i, \\theta^{(s)})\\) because \\(p(\\theta^{(s)} | x,y) = \\prod_i^n p(y_i|x_i, \\theta^{(s)}) p(\\theta^{(s)})\\) and the difference for the ratio is that the numerator has one less data point (\\(-i\\)) than the denominator therefore, everything cancels out to leave \\(1 / p(y_i|x_i, \\theta^{(s)})\\) (multiplied against a constant) easier to work with logarithms: \\(\\log(1/p(y_i|x_i, \\theta^{(s)})) = -\\log(\\text{likelihood}[i])\\) importance-weighted predictive distribution: \\(p(y_i|x_i, x_{-i}, y_{-i}) \\approx \\sum_{s=1}^S (w_i^{(s)} p(y_i|x_i, \\theta^{(s)}))\\) where weight \\(w_i \\leftarrow \\text{PSIS}(r_i)\\) Pareto smoothing to help stabilize the importance weights can have problem where very large importance weights make it that there are very few effective draws for this calculation most draws will have little effect when there are a few dominating importance ratios can look at the distribution of the weights to see how reliable the importance sampling is compute the effective sample size \\(n_\\text{eff}\\) from the importance ratios Pareto smoothing can approximate the extreme tail of the importance ratios using a generalized Pareto distribution Pareto dist. has two parameters scale shape (\\(\\hat{k}\\)): how many finite moments the weight distribution has if the shape is less than 0.5, then the variance is finite else, the variance may be infinite and CLT may not hold - means the approximation is not reliable in practice, \\(\\hat{k} &lt; 0.7\\) is okay plot the Pareto \\(\\hat{k}\\) and \\(n_\\text{eff}\\) for each data point (will usually be inversely correlated) K-fold CV varieties can approximate LOO by removing some \\(n\\) number of data points leave-one-group-out for hierarchical models leave-one-block-out for time series remove all data from a certain time point or range 9.2 Model comparison and selection CV for model assessment CV is good for model assessment when application specific utility/cost functions are used also useful for PPC model mis-specification diagnostics using Pareto-\\(\\hat{k}\\) and \\(p_\\text{LOO}\\) (effective number of parameters) checking model calibration and LOO predictive error sometimes do not need CV sometimes comparing predictive distribution to observed is enough to compare models can compare LLPD between models to see which data points are best modeled by each can compare models using ELPD standard error of the difference in ELPD se_diff only works for normally-distributed error not always a good assumption only when the models are properly specific and the number of observations is large (&gt;100 data points) What is one is not clearly better than others? recommend “continuous expansion including all models” make a model that contains both of the others as special cases instead of a pooled model vs. separate model, use a hierarchical model use a negative binomial instead of a poisson sparse priors like regularized horseshoe prior instead of variable selection model averaging with Bayesian Model Averaging (BMA) or Bayesian stacking when continuous expansion is not an option if nested (e.g. use the model with 2 variables instead of the 10 variable model that contains those 2 variables) use the simpler model assuming some cost for extra variables or use the more complex model if you want to take into account all the uncertainties CV and model selection can use CV for model selection if small number of models the difference between models is clear do not use CV to choose from a large set of models selection process leads to overfitting more likely to chose the model that just happens to best fit the data overfitting in selection process is not unique for CV Take-home messages: it is good to think about predictions of observables, because observables are the only ones we can observe CV can simulate predicting and observing new data CV is good if you do not trust your model different variants of CV are useful in different scenarios CV has high variance, and if you trust your model you can beat CV in accuracy 9.3 Variable selection with projection predictive variable selection Rich model vs feature selection? If we care only about the predictive performance: include all available prior information integrate over all uncertainties no need for feature selection Variable selection can be useful if: need to reduce measurement or computation cost in the future improve explainability Two options for variable selection: find a minimal subset of features that yield a good predictive model identify all features that have predictive information shrinkage priors alone do not solve the problem common strategy to fit a model with shrinkage prior and select variable my their marginal posteriors (marginal posteriors = regression coefficients) issues: marginal posteriors are difficult to interpret if features are correlated their posteriors will be correlated may each have a posterior around 0, but their joint distribution is not how to do post-selection inference correctly? add average cumulative effect set to zero and re-fit etc… different approach: focus on predictive performance two-step process: construct the best predictive model we can \\(\\rightarrow\\) reference model variable selection and post-selection inference \\(\\rightarrow\\) projection instead of focusing on marginal posteriors, find the subset of features with closest predictive performance to the reference model (watch lecture for description with the example) "],["section-10.-decision-analysis.html", "10 Section 10. Decision analysis 10.1 Resources 10.2 Notes", " 10 Section 10. Decision analysis 2021-11-15 10.1 Resources reading BDA3 chapter 9 reading instructions lectures: ‘10.1 Decision analysis’ slides: Lecture 10.1 Assignment 9 10.2 Notes 10.2.1 Reading instructions outline of chapter 9 9.1 Context and basic steps (most important part) 9.2 Example 9.3 Multistage decision analysis (you may skip this example) 9.4 Hierarchical decision analysis (you may skip this example) 9.5 Personal vs. institutional decision analysis (important) the lectures have simpler examples and discuss some challenges in selecting utilities or costs ch 7 discusses how model selection con be considered as a decision problem 10.2.2 Chapter 9. Decision analysis how can inferences be used in decision making? examples in this chapter: section 9.2: simple example with hierarchical model on how incentives affect survey response rates compare expected response rates of various incentive structures to their expected cost section 9.3: option of performing a diagnostic test before deciding on a treatment for cancer example of “value of information” and balancing risks of the screening test against the information it would provide section 9.4: decision and utility analysis of the risk of radon exposure cost of measurement and fixing high exposure example of a full integration if inference with decision analysis 9.1 Bayesian decision theory in difference contexts use Bayesian inference in two ways when balancing costs and benefits of decision options under uncertainty: a decision depends on the predicted quantities which depend on the parameters of the model and type of data use Bayesian inference within a decisions analysis to estimate outcomes conditional on information from previous decisions Bayesian inference and decision trees decision analysis involves optimization over decisions and uncertainties Bayesian decision analysis is defined as the following steps: Enumerate the space of all possible decisions \\(d\\) and outcomes \\(x\\). Determine the probability distribution of \\(x\\) for each decision option \\(d\\). Define a utility function \\(U(x)\\) mapping outcomes onto real numbers (values of interest). Compute the expected utility \\(\\text{E}(U(x)|d)\\) as a function of the decision \\(d\\) and choose the decision with the highest expected utility. often, we only do the first two steps and the rest is left to the “decision makers” 10.2.3 Lecture notes 10.1 Decision analysis (no new notes) "],["section-11.-normal-approximation-frequency-properties.html", "11 Section 11. Normal approximation &amp; Frequency properties 11.1 Resources 11.2 Notes", " 11 Section 11. Normal approximation &amp; Frequency properties 2021-11-19 11.1 Resources reading: BDA3 ch 4. Asymptotics and connections to non-Bayesian approaches reading instructions lectures: Lecture 11.1. ‘Normal approximation (Laplace approximation)’ Lecture 11.2. ‘Large sample theory and counter examples’ slides 11.2 Notes 11.2.1 Reading instructions chapter outline: 4.1 Normal approximation (Laplace’s method) 4.2 Large-sample theory 4.3 Counterexamples 4.4 Frequency evaluation (not part of the course, but interesting) 4.5 Other statistical methods (not part of the course, but interesting) 11.2.2 Chapter 4. Asymptotics and connections to non-Bayesian approaches asymptotic theory: as sample size increased, the influence of the prior on the posteior decreases used as the justification of non-informative priors in many cases 4.1 Normal approximations of the posterior distribution if the posterior distribution \\(p(\\theta|y)\\) is unimodal and symmetric, it is useful to approximate it as a normal therefore, the log of the posterior is a quadratic function of \\(\\theta\\) “For a finite sample size \\(n\\), the normal approximation is typically more accurate for conditional and marginal distributions of components of \\(\\theta\\) than for the full joint distribution.” (pg. 85) common to use the normal approximations to quickly debug or sanity-check a model’s code 4.2 Large-sample theory asymptotic normality of the posterior distribution: with more data from the same underlying process, the posterior distribution of the parameter vector approaches multivariate normality even if the true distribution of the data is not within the parametric family under consideration (pg. 87) - particularly for independent samples from the data-generating process - summary at the limit of large \\(n\\): - the posterior mode \\(\\hat\\theta\\) approaches the true \\(\\theta_0\\) - the likelihood dominates the prior distribution 4.3 Counterexamples to the theorems there are many instances where large amounts of data do not allow for the normal approximation: underidentified models and nonidentified parameters “the model is underidentified given data \\(y\\) if the likelihood \\(p(\\theta|y)\\) is equal for a range of \\(\\theta\\)” (pg. 89) there is no single point \\(\\theta_0\\) to which the posterior distribution can converge given infinite data a parameter can be nonidentified if there is no supply of information about it results in its posterior being identical to its prior number of parameters increasing with sample size in complicated problems, the number of parameters can scale with the amount of data e.g. Gaussian processes or hierarchical models aliasing the same likelihood function repeats at a discrete set of points a special case of underidentified parameters e.g. a mixture model with two mixed distributions with the same parameters unbounded likelihoods if the likelihood is unbounded, there might not be any posterior mode with the parameter space invalidates bot the consistency results and the normal approximation improper posterior distributions an improper posterior integrates to infinity, not to 1 as is required by the normal approximation theory an improper posterior can only occur with an improper prior prior distributions that exclude the point of convergence convergence to the edge of parameter space if \\(\\theta_0\\) is at the edge of the parameter space, the distribution cannot be symmetric tails of the distribution the normal approximation can be true for almost all of the mass of the posterior but not be true at the tails 11.2.3 Lecture notes Lecture 11.1. ‘Normal approximation (Laplace approximation)’ (no additional notes) Lecture 11.2. ‘Large sample theory and counter examples’ large sample theory: consistency: if the true distribution is included in the parametric family then the posterior converges to a point \\(\\theta_0\\) when \\(n \\rightarrow \\infty\\) “included in the parametric family”: \\(f(y) = p(y|\\theta_0)\\) for some \\(\\theta_0\\) the point does not have uncertainty same result as MLE if the true distribution is not included in the parameteric family, then there is no true \\(\\theta_0\\), so replace it with the \\(\\theta_0\\) that minimized the KL divergence "],["section-12.-extended-topics.html", "12 Section 12. Extended topics 12.1 Resources 12.2 Notes", " 12 Section 12. Extended topics 2021-12-02 12.1 Resources reading: end of BDA3 ch. 4 optional: BDA3 ch. 8, 14-18, 21 lectures: ‘12.1 Frequency evaluation, hypothesis testing and variable selection’ ‘12.2 Overview of modeling data collection, BDA3 Ch 8, linear models, BDA Ch 14-18, lasso, horseshoe and Gaussian processes, BDA3 Ch 21’ slides 12.2 Notes 12.2.1 Lecture 12.1 Frequency evaluation, hypothesis testing and variable selection Bayesian vs. Frequentist Bayesian theory has epistemic and aleatory probabilities Frequency evaluations focus on frequency properties given aleatoric repetition of an observation and modeling on “null hypothesis testing”: often inappropriate to test the probability that a value is 0 for continuous data, the probability of a single value is always 0 “region of practical equivalence” (ROPE) is another option best to focus on describing the full posterior e.g. amount of the posterior greater than or less than an important value e.g. where most of the posterior density is (89% or 95% HDI) be careful about only looking at marginal posteriors, too joint posterior distributions may be informative e.g. height and weight variables in beta-blocker model are highly correlated; both marginals overlap 0, but joint does not most common statistical tests are linear models longer list with more illustrations: https://lindeloev.github.io/tests-as-linear classical test Bayesian equivalent in ‘rstanarm’ t-test mean of data stan_glm(y ~ 1) paired t-test mean of diffs stan_glm((y1 - y2) ~ 1) Pearson correlation linear model stan_glm(y ~ 1 + x) two-sample t-test group means stan_glm(y ~ 1 + gid) ANOVA hierarchical model stan_glm(y ~ 1 + (1|gid)) 12.2.2 Lecture 12.2 Overview of modeling data collection, BDA3 Ch 8, linear models, BDA Ch 14-18, lasso, horseshoe and Gaussian processes, BDA3 Ch 21 LASSO and Bayesian LASSO Bayesian LASSO uses Laplace distribution as a prior is equivalent to L1 penalty in MLE LASSO, but because we still integrate over the entire posterior, it does not have the same “sparsifying” effect therefore, Bayesian LASSO is empirically worse than MLE LASSO final thought: best to separate the process of prior selection, posterior inference, and decision analysis regularized horseshoe prior a better choice if you have prior information that only some of the covariates are informative projpred selection vs LASSO "],["section-13.-notes-on-ch-14.-introduction-to-regression-models.html", "13 Section 13. Notes on ‘Ch 14. Introduction to regression models’ 13.1 Chapter 14. Introduction to regression models 13.2 14.4 Goals of regression analysis 13.3 14.5 Assembling the matrix of explanatory variables 13.4 14.6 Regularization and dimension reduction", " 13 Section 13. Notes on ‘Ch 14. Introduction to regression models’ 2021-12-06 These are just notes on a single chapter of BDA3 that were not part of the course. 13.1 Chapter 14. Introduction to regression models 13.1.1 14.1 Conditional modeling question: how does one quantity \\(y\\) vary as a function of another quantity or vector of quantities \\(x\\)? conditional distribution of \\(y\\) given \\(x\\) parameterized as \\(p(y|\\theta,x)\\) key statistical modeling issues: defining \\(y\\) and \\(x\\) so that \\(y\\) is reasonably linear as a function of the columns of \\(X\\) may need to transform \\(x\\) set priors on the model parameters 13.1.2 14.2 Bayesian analysis of classical regression simplest case: ordinary linear regression observation errors are independent and have equal variance \\[ y | \\beta, \\sigma, X \\sim \\text{N}(X \\beta, \\sigma^2 I) \\] Posterior predictive distribution for new data posterior predictive distribution has two sources of uncertainty: the inherent variability in the model represented by \\(\\sigma\\) in \\(y\\) posterior uncertainty in \\(\\beta\\) and \\(\\sigma\\) draw a random sample \\(\\tilde{y}\\) from the posterior predictive distribution: draw \\((\\beta, \\sigma)\\) from their posteriors draw \\(\\tilde{y} \\sim \\text{N}(\\tilde{X} \\beta, \\sigma^2 I)\\) 13.2 14.4 Goals of regression analysis at least three goals: understand the behavior of \\(y\\) given \\(x\\) predict \\(y\\) given \\(x\\) causal inference; predict how \\(y\\) would change if \\(x\\) were changed 13.3 14.5 Assembling the matrix of explanatory variables 13.3.1 Identifiability and collinearity “the parameters in a classical regression cannot be uniquely estimated if there are more parameters than data points or, more generally, if the columns of the matrix \\(X\\) of explanatory variables are not linearly independent” (pg 365) 13.3.2 Nonlinear relations may need to transform variables can include more than one transformation in the model as separate covariates GLMs and non-linear models are discussed in later chapters 13.3.3 Indicator variables include a categorical variable in a regression using a indicator variable separate effect for each category or model as related with a hierarchical model 13.3.4 Interactions “If the response to a unit change in \\(x_i\\) depends in what value another predictor \\(x_j\\) has been fixed at, then it is necessary to include interaction terms in the model” (pg 367) \\((x_i - \\bar{x_i})(x_j - \\bar{x_j})\\) 13.4 14.6 Regularization and dimension reduction see lecture notes on regularization for more updated recommendations “Bayesian regularization”: location and scale of the prior analytic form of the prior (e.g. normal vs. Laplacian vs. Cauchy) how the posterior inference is summarized "],["section-14.-notes-on-ch-15.-hierarchical-linear-models.html", "14 Section 14. Notes on ‘Ch 15. Hierarchical linear models’ 14.1 Chapter 15. Hierarchical linear models", " 14 Section 14. Notes on ‘Ch 15. Hierarchical linear models’ 2021-12-09 These are just notes on a single chapter of BDA3 that were not part of the course. Also, these notes are rather sparse because I have a bit of experience with these models already. 14.1 Chapter 15. Hierarchical linear models “Hierarchical regression models are useful as soon as there are predictors at different levels of variation” (pg 381) or for data obtained by stratified/clustered sampling general recommendation to start simple and build up the model’s complexity "],["section-17.-notes-on-ch-19.-parametric-nonlinear-models.html", "15 Section 17. Notes on ‘Ch 19. Parametric nonlinear models’ 15.1 Chapter 19. Parametric nonlinear models", " 15 Section 17. Notes on ‘Ch 19. Parametric nonlinear models’ 2021-12-09 These are just notes on a single chapter of BDA3 that were not part of the course. 15.1 Chapter 19. Parametric nonlinear models examples: a ratio; \\(\\text{E}(y = \\frac{a_1 + b_1 x_1}{a_2 + b_2 x_2}\\) sum of nonlinear functions: \\(\\text{E}(y) = A_1 e^{-\\alpha_1x} + A_2 e^{-\\alpha_2x}\\) parameters of a nonlinear model are often harder to interpret often requires custom visualization techniques “Generally each new modeling problem must be tackled afresh.” (pg 471) these models are less systematic than linear modeling 19.1 Example: serial dilution assay estimate 10 unknown concentrations of an allergen based off of serial dilutions of a known standard The model Notation: parameters of interest: concentrations of unknown samples \\(\\theta_1, \\dots, \\theta_10\\) known concentration of the standard \\(\\theta_0\\) dilution of measure \\(i\\) as \\(x_i\\) and color intensity (measurement) as \\(y_i\\) Curve of expected measurements given the concentration use the following equation that is standard in the field parameters: \\(\\beta_1\\): color intensity at the limit of 0 concentration \\(\\beta_2\\): the increase to saturation \\(\\beta_3\\): concentration at which the gradient of the curve turns \\(\\beta_4\\): rate at which saturation occurs \\[ \\text{E}(y | x, \\beta) = g(x, \\beta) = \\beta_1 + \\frac{\\beta_2}{1 + (x / \\beta_3)^{-\\beta_4}} \\] Measurement error modeled as normally distributed with unequal variances parameters: \\(\\alpha\\): models the pattern that variances are higher for larger measurements restricted \\([0, 1]\\) \\(A\\) is a arbitrary constant to scale the data so \\(\\sigma\\) can be interpreted as the deviation from “typical” values \\(\\sigma\\): deviation of a measure from the “typical” \\[ y_i \\sim \\text{N}(g(x_i, \\beta), (\\frac{g(x_i, \\beta)}{A})^{2\\alpha} \\sigma_y^2) \\] Dilution errors two possible sources: initial dilution: the accuracy of the creation of the initial standard concentration serial dilutions: error in creation of the subsequent dilutions (low enough to ignore for this analysis) use a normal model on the log scale of the initial dilution error parameters: \\(\\theta_0\\): known concentration of the standard solution \\(d_0^\\text{init}\\): known initial dilution of the standard that is called for without error, the concentration of the initial solution would be \\(d_0^\\text{init} \\theta_0\\) \\(x_0^\\text{init}\\): the actual (unknown) concentration of the initial dilution \\[ \\log(x_0^\\text{init}) \\sim \\text{N}(\\log(d_0^\\text{init} \\cdot \\theta_0), (\\sigma^\\text{init})^2) \\] - Dilution errors (cont) - there is no initial dilution for the unknown samples being tested - therefore, the unknown initial concentration for sample \\(j\\) is \\(x^\\text{init} = \\theta_j\\) for \\(j = 1, \\dots, 10\\) - for the dilutions of the unknown samples, set \\(x_i = d_i \\cdot x_{j(i)}^\\text{init}\\) - \\(j(i)\\) is the sample \\(j\\) corresponding to measurement \\(i\\) - \\(d_i\\) is the dilution of measurement \\(i\\) relative to the initial concentration Prior distributions priors used as described by book (are likely different than what would be recommended now): \\(\\log(\\beta) \\sim U(-\\infty, \\infty)\\) \\(\\sigma_y \\sim U(0, \\infty)\\) \\(\\alpha \\sim U(0,1)\\) \\(p(\\log \\theta_j) \\propto 1\\) for each unknown \\(j = 1, \\dots, 10\\) cannot estimate \\(\\sigma^\\text{init}\\) because we only have a single standard use a fixed value of 0.02 based on a previous analysis of different plates 19.2 Example: population toxicokinetics this is a more complex model uses a physiological model with parameters that cannot be solely determined using the data requires informative priors based on previous studies "],["section-18.-notes-on-ch-20.-basis-function-models.html", "16 Section 18. Notes on ‘Ch 20. Basis function models’ 16.1 Chapter 20. Basis function models 16.2 20.2 Basis selection and shrinkage coefficients 16.3 20.3 Non-normal models and regression surfaces", " 16 Section 18. Notes on ‘Ch 20. Basis function models’ 2022-01-12 These are just notes on a single chapter of BDA3 that were not part of the course. 16.1 Chapter 20. Basis function models chapter 19 focused on nonlinear models with \\(\\text{E}(y|X,\\beta) = \\mu(X_i,\\phi)\\) where \\(\\mu\\) is a parametric nonlinear function of unknowns \\(\\phi\\) in this and following chapters, consider models where \\(\\mu\\) is also unknown 20.1 Splines and weighted sums of basis functions replace \\(X_i \\beta\\) with \\(\\mu(X_i)\\) where \\(\\mu(\\cdot)\\) is some class of nonlinear functions different options for modeling \\(\\mu\\) including with basis function expansions or Gaussian processes (next chapter) basis function approach: \\(\\mu(x) = \\sum_{h=1}^{H} \\beta_h b_h(x)\\) \\(b_h\\): set of basis functions \\(\\beta_h\\): vector of basis coefficients common choices for basis functions are: Gaussian radial basis functions: multiple centers of the basis functions with a width parameter controlling a set of Gaussian functions B-spline: a piecewise continuous function based on a set of knots knots locations control the flexibility of the basis knots cn be placed uniformly or non-uniformly (e.g. based on the density of the data) can use a “free knot approach” with a prior on the number and location of knots, but is computationally demanding instead can use priors on the coefficients \\(\\beta\\) to shrink values to near 0 16.2 20.2 Basis selection and shrinkage coefficients common to not know which basis functions are really needed can use a variable selection approach to allow the model to estimate the “importance” of each basis function can then either select the best model from the posterior or average over all possible models by weighting each basis by its importance possible for some bias based on initial choice of the basis functions implied prior information on the smoothness and shape of the model can include multiple types of basis functions in the initial collection Shrinkage priors allowing basis function coefficients to be zero with positive probability represents a challenge for sampling from the posterior with many basis functions, it is computationally infeasible to visit all possible states may be better to use shrinkage priors instead there are various options discussed in the book and there are likely others recommended now 16.3 20.3 Non-normal models and regression surfaces Other error distributions may want to model data that is not a continuous output variable \\(y\\) or does not have Gaussian residuals can modify the residual densities with different prior distributions to accommodate outliers can use the basis function and its coefficients \\(\\eta_i = w_i \\beta\\) as the linear component in a GLM Multivariate regression surfaces careful with curse of dimensionality one option is to assume additive of the covariates so can model as the sum of univariate regression functions this does not always make sense and a different approach using a tensor product is described at the end of the section can use informative priors to help restrict the search space is a form of including prior information, so still proper Bayesian results and measures of uncertainty e.g. if we know a priori that the mean response variable is non-decreasing, restrict the coefficients \\(\\beta\\) to be non-negative "],["section-19.-notes-on-ch-21.-gaussian-process-models.html", "17 Section 19. Notes on ‘Ch 21. Gaussian process models’ 17.1 Chapter 21. Gaussian process models", " 17 Section 19. Notes on ‘Ch 21. Gaussian process models’ 2022-01-13 These are just notes on a single chapter of BDA3 that were not part of the course. 17.1 Chapter 21. Gaussian process models Gaussian process (GP): “flexible class of models for which any finite-dimensional marginal distribution is Gaussian” (pg. 501) “can be viewed as a potentially infinite-dimensional generalization of Gaussian distribution” (pg. 501) 21.1 Gaussian process regression realizations from a GP correspond to random functions good prior for an unknown regression function \\(\\mu(x)\\) \\(\\mu \\sim \\text{GP}(m,k)\\) \\(m\\): mean function \\(k\\): covariance function \\(\\mu\\) is a random function (“stochastic process”) where the values at any \\(n\\) pooints \\(x_1, \\dots, x_n\\) are drawn from the \\(n-dimensional\\) normal distribution with mean \\(m\\) and covariance \\(K\\): \\[ \\mu(x_1), \\dots, \\mu(x_n) \\sim \\text{N}((m(x_1), \\dots, m(x_n)), K(x_1, \\dots, x_n)) \\] the GP \\(\\mu \\sim \\text{GP}(m,k)\\) is nonparametric with infinitely many parameters the mean function \\(m\\) represents an inital guess at the regression function the covariance function \\(k\\) represents the covariance between the process at any two points controls the smoothness of realizations from the GP and degree of shrinkage towards the mean below is an example of realizations from a GP with mean function 0 and the squared exponential (a.k.a. exponentiated quadratic, Gaussian) covariance function with different parameters \\[ k(x, x^\\prime) = \\tau^2 \\exp(-\\frac{|x-x^\\prime|^2}{2l^2}) \\] squared_exponential_cov &lt;- function(x, tau, l) { n &lt;- length(x) k &lt;- matrix(0, nrow = n, ncol = n) denom &lt;- 2 * (l^2) for (i in 1:n) { for (j in 1:n) { a &lt;- x[i] b &lt;- x[j] k[i, j] &lt;- tau^2 * exp(-(abs(a - b)^2) / (denom)) } } return(k) } my_gaussian_process &lt;- function(x, tau, l, n = 3) { m &lt;- rep(0, length(x)) k &lt;- squared_exponential_cov(x = x, tau = tau, l = l) gp_samples &lt;- mvtnorm::rmvnorm(n = n, mean = m, sigma = k) return(gp_samples) } tidy_gp &lt;- function(x, tau, l, n = 3) { my_gaussian_process(x = x, tau = tau, l = l, n = n) %&gt;% as.data.frame() %&gt;% as_tibble() %&gt;% set_names(x) %&gt;% mutate(sample_idx = as.character(1:n())) %&gt;% pivot_longer(-sample_idx, names_to = &quot;x&quot;, values_to = &quot;y&quot;) %&gt;% mutate(x = as.numeric(x)) } set.seed(0) x &lt;- seq(0, 10, by = 0.1) gp_samples &lt;- tibble(tau = c(0.25, 0.5, 0.25, 0.5), l = c(0.5, 0.5, 2, 2)) %&gt;% mutate(samples = purrr::map2(tau, l, ~ tidy_gp(x = x, tau = .x, l = .y, n = 3))) %&gt;% unnest(samples) gp_samples %&gt;% mutate(grp = glue(&quot;\\u03C4 = {tau}, \\u2113 = {l}&quot;)) %&gt;% ggplot(aes(x = x, y = y)) + facet_wrap(vars(grp), nrow = 2) + geom_line(aes(color = sample_idx)) + scale_x_continuous(expand = expansion(c(0, 0))) + scale_y_continuous(expand = expansion(c(0.02, 0.02))) + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set1&quot;) + theme(legend.position = &quot;none&quot;, axis.text.y = element_markdown()) + labs(x = &quot;x&quot;, y = &quot;\\u03BC(x)&quot;) Covariance functions “Different covariance functions can be used to add structural prior assumptions like smoothness, nonstationarity, periodicity, and multi-scale or hierarchical structures.” (pg. 502) sums and products of GPs are also GPs so can combine them in the same model can also use “anisotropic” GPs covariance functions for multiple predictors Inference computing the mean and covariance in the \\(n\\)-variate normal conditional posterior for \\(\\tilde{\\mu}\\) involves a matrix inversion that requires \\(O(n^3)\\) computation this needs to be repeated for each MCMC step limits the size of the data set and number of covariates in a model Covariance function approximations there are approximations to the GP that can speed up computation generally work by reducing the matrix inversion burden 21.3 Latent Gaussian process models with non-Gaussian likelihoods, the GP prior becomes a latent function \\(f\\) which determines the likelihood \\(p(y|f,\\phi)\\) through a link function 21.4 Functional data analysis functional data analysis: considers responses and predictors not a scalar/vector-valued random variables but as random functions with infinitely-many points GPs fit this need well with little modification 21.5 Density estimation and regression can get more flexibility by modeling the conditional observation model as a nonparametric GP so far have used a GP as a prior for a function controlling location or shape of a parametric observation model one solution is the logistic Gaussian process (LGP) or a Dirichlet process (covered in a later chapter) Density estimation LGP generates a random surface from a GP and then transforms the surface to the space of probability densities with 1D, the surface is just a curve use the continuous logistic transformation to constrain to non-negative and integrate to 1 there is illustrative example in the book on page 513 Density regression generalize the LPG to density regression by putting a prior on the collection of conditional densities Latent-variable regression an alternative to LPG "],["section-20.-notes-on-ch-22.-finite-mixture-models.html", "18 Section 20. Notes on ‘Ch 22. Finite mixture models’ 18.1 Chapter 22. Finite mixture models", " 18 Section 20. Notes on ‘Ch 22. Finite mixture models’ 2022-01-18 These are just notes on a single chapter of BDA3 that were not part of the course. 18.1 Chapter 22. Finite mixture models “when measurements of a random variable are taken under two different conditions” (pg. 519) where the data contains multiple subpopulations where each has a different, relatively simple model basic mixture modeling principle is to introduce unobserved indicators \\(z\\) to specify the mixture component for an observation can think of a mixture indicator as missing data 22.1 Setting up and interpreting mixture models Finite mixtures want to model the distribution of \\(y = (y_1, \\dots, y_n)\\) or \\(y|x\\) as a mixture of \\(H\\) components for each component \\(h \\in (1, \\dots, H)\\), the distribution \\(f_h(y_i | \\theta_h)\\) depends on a parameter vector \\(\\theta_h\\) \\(\\lambda_h\\) denotes the proportion of the population in component \\(h\\) \\(\\sum_{h=1}^{H} \\lambda_h = 1\\) common to assume all mixture components have the same parametric form thus, the sampling distribution of \\(y\\) is: \\[ p(y_i | \\theta, \\lambda) = \\lambda_1 f(y_i | \\theta_1) + \\dots + \\lambda_H f(y_i | \\theta_H) \\] can think of the mixture distribution probabilities \\(\\lambda\\) as priors over the parameters \\(\\theta_h\\) or as a description of the variation in \\(\\theta\\) in a population akin to a hierarchical model introduce the indicator variables \\(z_{ih}\\) where \\(z_{ih} = 1\\) if the \\(i\\)th data point is drawn from component \\(h\\) and 0 otherwise the \\(lambda\\) values are used to determine \\(z\\) can think of \\(lambda\\) as a hyperprior over \\(z\\) joint distribution of the observed data \\(y\\) and the unobserved indicators \\(z\\) conditions on the model parameters: only one \\(z_{ih}\\) can be 1 for each \\(i\\) \\[ \\begin{aligned} p(y, z | \\theta, \\lambda) &amp;= p(z | \\lambda) p(y | z, \\theta) \\\\ &amp;= \\prod_{i=1}^n \\prod_{h=1}^H (\\lambda_h f(y_i | \\theta_h))^{z_{i,h}} \\end{aligned} \\] Continuous mixtures generalize the finite mixture to allow probability of an observation belongs to a class hierarchical models are a form a continuous mixture model each observed value \\(y_i\\) is modeled as coming from a mixture of models defined by the probability of values for \\(\\theta\\) in the book, the focus is on finite mixtures and “minor modifications” are generally required to form a continuous distribution Identifiabilitiy of the mxixture likelihood all finite mixture models are nonidentifiable: the distribution is unchanged if the group labels are permuted in many cases, purposeful, informative priors can solve the issue Priors distributions the priors for a finite mixture model’s parameters \\(\\theta\\) and \\(\\lambda\\) are usually the product of the two independent priors on each variable because the vector of mixture indicators \\(z_i = (z_{i,1}, \\dots, z_{i,H})\\) is multinomial with parameter \\(\\lambda\\), a common prior for \\(\\lambda\\) is the Dirichlet \\(\\lambda \\sim \\text{Dirichlet}(\\alpha_1, \\dots, \\alpha_H)\\) \\(\\theta = (\\theta_1, \\dots, \\theta_H)\\) is the vector of parameters for each component’s sub-model some can be shared across components (i.e. equal variance for a group of normal distributions) Number of mixture components can model \\(H\\) as unknown but is computationally expensive usually can just build models with different \\(H\\) and compare their goodness of fit compare the posterior predictive distributions with a “suitably chosen” test quantity Mixtures as true models or approximating distributions two classes of thought1: theoretical: a mixture model is “a realistic characterization of the true data-generating mechanism” (pg. 522) pragmatic: “trying to infer latent subpopulations is an intrinsically ill-defined statistical problem, but finite mixture models are nonetheless useful” (pg. 523) 22.4 Unspecifed number of mixture components can assign a Poisson distribution as a on \\(H\\) (the number of groups/components in the mixture model) computationally intensive more common to just fit the model with different \\(H\\) and compare with some statistic and a penalty for model complexity WAIC is theoretically justified, but ignores the uncertainty over \\(H\\) LOO-CV may be even better "],["section-21.-notes-on-ch-23.-dirichlet-process-models.html", "19 Section 21. Notes on ‘Ch 23. Dirichlet process models’ 19.1 Chapter 23. Dirichlet process models", " 19 Section 21. Notes on ‘Ch 23. Dirichlet process models’ 2022-01-20 These are just notes on a single chapter of BDA3 that were not part of the course. 19.1 Chapter 23. Dirichlet process models Dirichlet process: an infinite-dimensional generalization of the Dirichlet distribution used as a prior on unknown distributions can extend finite component mixture models to infinite mixture models 23.1 Bayesian histograms the histogram as a simple form of density estimation demonstrate a flexible parametric version that motivates the non-parametric in the following section prespecified knots: \\(\\xi = (\\xi_0, \\dots, \\xi_k)\\) with \\(\\xi_{n-1} &lt; \\xi_n\\) probability model for the density (a histogram): where \\(\\pi = (\\pi_1, \\dots, \\pi_k)\\) is an unknown probability vector \\[ f(y) = \\sum_{h=1}^k 1_{\\xi_{h-1} &lt; y \\le \\xi_h} \\frac{\\pi_h}{(\\xi_h - \\xi_{h-1})} \\] prior for the probabilities \\(\\pi\\) as a Dirichlet distribution: \\[ p(\\pi|a) = \\frac{\\Gamma(\\sum_{h=1}^k a_h)}{\\prod_{h=1}^k \\Gamma(a_h)} \\prod_{h=1}^k \\pi _h^{a_h - 1} \\] replace the hyperparameter vector: \\(a = \\alpha \\pi_0\\) where \\(\\pi_0\\) is: \\[ \\text{E}(\\pi|a) = \\pi_0 = \\left( \\frac{a_1}{\\sum_h a_h}, \\dots, \\frac{a_k}{\\sum_h a_h} \\right) \\] the posterior for \\(\\pi\\) becomes: where \\(n_i\\) is the number of observations \\(y\\) in the \\(i\\)th bin \\[ p(\\pi | y) \\propto \\prod_{h=1}^k \\pi_h^{a_h + n_h - 1} = \\text{Dirichlet}(a_1 + n_1, \\dots, a_k + n_k) \\] this histogram estimator does well but is sensitive to the specification of the knots 23.2 Dirichlet process prior distributions Definition and basic properties goal is to not need to prespecify the bins of the histogram let: \\(\\Omega\\): sample space \\(B_1, \\dots, B_k\\): measure subsets of \\(\\Omega\\) if \\(\\Omega = \\Re\\), then \\(B_1, \\dots, B_k\\) are non-overlapping intervals that partition the real line into a finite number of bins \\(P\\): unknown probability measure of \\((\\Omega, \\mathcal{B})\\) \\(\\mathcal{B}\\): “collection of all possible subsets of the sample space \\(\\Omega\\)” \\(P\\) assigns probabilities to the subsets \\(\\mathcal{B}\\) probability for a set of bins \\(B_1, \\dots, B_k\\) partitioning \\(\\Omega\\): \\[ P(B_1), \\dots, P(B_k) = \\left( \\int_{B_1} f(y) dy, \\dots, \\int_{B_k} f(y) dy \\right) \\] \\(P\\) is a random probability measure (RPM), so the bin probabilities are random variables a good prior for the bin probabilities is the Dirichlet distribution @ref(eq:dirichlet-prior where \\(P_0\\) is a base probability measure providing the initial guess at \\(P\\) where \\(\\alpha\\) is a prior concentration parameter controls shrinkage of \\(P\\) towards \\(P_0\\) \\[ P(B_1), \\dots, P(B_k) \\sim \\text{Dirichlet}(\\alpha P_0(B_1), \\dots, \\alpha P_0(B_k)) \\tag{19.1} \\] difference with previous Bayesian histogram: only specifies that bin \\(B_k\\) is assigned probability \\(P(B_k)\\) and not how probability mass is distributed across the bin \\(B_k\\) thus, for a fixed set s of bins, this equation does not full specify the prior for \\(P\\) need to eliminate the sensitivity to the choice of bins by assuming the prior holds for all possible partitions \\(B_1, \\dots, B_k\\) for all \\(k\\) then it is a fully specified prior for \\(P\\) “must exist a random probability measure \\(P\\) such that the probabilities assigned to any measurable partition \\(B_1, \\dots, B_k\\) by \\(P\\) is \\(\\text{Dirichlet}(\\alpha P_0(B_1), \\dots, \\alpha P_0(B_k))\\)” the resulting \\(P\\) is a Dirichlet process: \\(P \\sim \\text{DP}(\\alpha P_0)\\) \\(\\alpha &gt; 0\\): a scalar precision parameter \\(P_0\\): baseline probability measure also on \\((\\Omega, \\mathcal{B})\\) implications of DP: the marginal random probability assigned to any subset \\(B\\) is a beta distribution \\(P(B) \\sim \\text{Beta}(\\alpha PP_0(B), \\alpha (1-P_0(B)))\\) for all \\(B \\in \\mathcal{B}\\) the prior for \\(P\\) is centered on \\(P_0\\): \\(E(P(B)) = P_0(B)\\) \\(\\alpha\\) controls variance \\(\\text{var}(P(B)) = \\frac{P_0(B)(1 - P_0(B))}{1 + \\alpha}\\) get posterior for \\(P\\): let \\(y_i \\stackrel{iid}{\\sim} P\\) fir \\(i = 1, \\dots, n\\) \\(P \\sim \\text{DP}(\\alpha P_0)\\) \\(P\\) denotes the probability measure and its corresponding distribution from (19.1), for any partition \\(B_1, \\dots, B_k\\): \\[ p(B_1), \\dots, P(B_k) | y_1, \\dots, y_k \\sim \\text{Dirichlet} \\left( \\alpha P_0(B_1) + \\sum_{i=1}^n 1_{y_i \\in B_1}, \\dots, \\alpha P_0(B_k) + \\sum_{i=1}^n 1_{y_i \\in B_k} \\right) \\] this can be converted to the following: \\[ P | y_1, \\dots, y_n \\sim \\text{DP} \\left( \\alpha P_0 \\sum_i \\delta_{y+i} \\right) \\] finally, the posterior expectation of \\(P\\): \\[ \\text{E}(P(B) | y^n) = \\left(\\frac{\\alpha}{\\alpha + n} \\right) P_0(B) + \\left(\\frac{n}{\\alpha + n} \\right) \\sum_{i=1}^n \\frac{1}{n} \\delta_{y_i} \\tag{19.2} \\] DP is a model similar to a random histogram but without dependence on the bins cons of a DP prior: lack of smoothness induces negative correlation between \\(P(B_1)\\) and \\(P(B_2)\\) for any two disjoint bins with no account for the distance between them realizations from the DP are discrete distributions with \\(P \\sim \\text{DP}(\\alpha P_0)\\), \\(P\\) is atomic and have nonzero weights only on a set of atoms, not a continuous density on the real line Stick-breaking construction more intuitive understanding of DP induce \\(P \\sim \\text{DP}(\\alpha P_0)\\) by letting: \\[ \\begin{aligned} P(\\cdot) &amp;= \\sum_{h=1}^{\\infty} \\pi_h \\delta_{\\theta_h}(\\cdot) \\\\ \\pi_h &amp;= V_h \\prod_{l&lt;h} (1 - V_i) \\\\ V_h &amp;\\sim \\text{Beta}(1, \\alpha) \\\\ \\theta_h &amp;\\sim P_0 \\end{aligned} \\] where: \\(P_0\\): base distribution \\(\\delta_\\theta\\): degenerate distribution with all mass at \\(\\theta\\) \\((\\theta_h)_{h=1}^{\\infty}\\): the atoms generated independently by from \\(P_0\\) the atoms are generated by the stick-breaking process this ensures the weights sum to 1 \\(\\pi_h\\): probability mass at atom \\(\\theta_h\\) the stick-breaking process: start with a stick of length 1 represents the total probability allocated to all the atoms break off a random piece of length \\(V_1\\) determined by a draw from \\(\\text{Beta}(1, \\alpha)\\) set \\(\\pi_1 = V_1\\) as the probability weight to the randomly generated first atom \\(\\theta_1 \\sim P_0\\) break off another piece of the remaining stick (now length \\(1-V_1\\)): \\(V_2 \\sim \\text{Beta}(1, \\alpha)\\) set \\(\\pi_2 = V_2(1-V_1)\\) as the probability weight to the next atom \\(\\theta_2 \\sim P_0\\) repeat until the stick is fully used implications: during the process, the stick get shorter, so lengths allocated to later indexed atoms decrease stochastically rate of decrease of stick length depends on \\(\\alpha\\) \\(\\alpha\\) near 0 lead to high weights early on below are realizations of the stick breaking process set \\(P_0\\) as a standard normal distribution and vary \\(\\alpha\\) stick_breaking_process &lt;- function(alpha, n = 1000) { theta &lt;- rnorm(n, 0, 1) # P0 = standard normal vs &lt;- rbeta(n, 1, alpha) pi &lt;- rep(0, n) pi[1] &lt;- vs[1] stick &lt;- 1.0 - vs[1] for (h in 2:n) { pi[h] &lt;- vs[h] * stick stick &lt;- stick - pi[h] } return(list(theta = theta, pi = pi)) } dp_realization &lt;- stick_breaking_process(10) sum(dp_realization$pi) #&gt; [1] 1 set.seed(549) tibble(alpha = c(0.5, 1, 5, 10)) %&gt;% mutate( dp = purrr::map(alpha, stick_breaking_process, n = 1000), theta = purrr::map(dp, ~ .x$theta), pi = purrr::map(dp, ~ .x$pi) ) %&gt;% select(-dp) %&gt;% unnest(c(theta, pi)) %&gt;% ggplot(aes(x = theta, y = pi)) + facet_wrap(vars(alpha), nrow = 2, scales = &quot;fixed&quot;) + geom_col(width = 0.05) + scale_x_continuous(expand = expansion(c(0.02, 0.02))) + scale_y_continuous(expand = expansion(c(0, 0.02))) + labs(x = &quot;\\u03B8&quot;, y = &quot;\\u03C0&quot;) 23.3 Dirichlet process mixtures Specification and Polya urns “the DP is more appropriately used as a prior for an unknown mixture of distributions” (pg 549) in the case of density estimation, a general kernel mixture model can be specified as (19.3) \\(\\mathcal{K}(\\cdot | \\theta)\\): a kernel \\(\\theta\\): location and possibly scale parameters \\(P\\): “mixing measure” \\[ f(y|P) = \\int \\mathcal{K}(y|\\theta) d P(\\theta) \\tag{19.3} \\] treating \\(P\\) as discrete results in a finite mixture model setting a prior on \\(P\\) creates an infinite mixture model prior: \\(P \\sim \\pi_\\mathcal{P}\\) \\(\\mathcal{P}\\): space of all probability measures on \\((\\Omega, \\mathcal{B})\\) \\(\\pi_\\mathcal{P}\\): the prior over the space defined by \\(\\mathcal{P}\\) if set \\(\\pi_\\mathcal{P}\\) as a DP prior, results in a DP mixture model from (19.2) and (19.3), a DP prior on \\(P\\) results in (19.4) where: \\(\\pi = \\sim \\text{stick}(\\alpha)\\) denotes that the probability weights are from the stick-breaking process with parameter \\(\\alpha\\) \\(\\theta_h \\sim P_0\\) independently for each \\(h=1, \\dots, \\infty\\) \\[ f(y) = \\sum_{h=1}^\\infty \\pi_h \\mathcal{K}(y | \\theta_h^*) \\tag{19.4} \\] equation (19.4) resembles a finite mixture model except the number of mixture components in set to infinity does not mean there will be infinite number of components instead the model is just flexible to add more mixture components if necessary consider the following specification issue of how to conduct posterior computation with a DP mixture (DPM) because \\(P\\) has infinitely many parameters \\[ y_i \\sim \\mathcal{K}(\\theta_i) \\text{,} \\quad \\theta_i \\sim P \\text{,} \\quad P \\sim \\text{DP}(\\alpha P_0) \\] can marginalize out \\(P\\) to get an induced prior on the subject-specific parameters \\(\\theta^n = (\\theta_1, \\dots, \\theta_n)\\) results in the Polya urn predictive rule: \\[ p(\\theta_i | \\theta_1, \\dots, \\theta_{i-1}) \\sim \\left( \\frac{\\alpha}{\\alpha + i -1} \\right) P_0(\\theta_i) + \\sum_{j=1}^{i-1} \\left( \\frac{1}{\\alpha + i - 1} \\right) \\delta_{\\theta_j} \\tag{19.5} \\] Chinese restaurant process as a metaphor for the Polya urn predictive rule (19.5): consider a restaurant with infinitely many tables the first customers sits at a table with dish \\(\\theta_1^*\\) the second customer sits at the first table with probability \\(\\frac{1}{1+\\alpha}\\) or a new table with probability \\(\\frac{\\alpha}{1+\\alpha}\\) repeat this process for the \\(i\\)th customer: sit at an occupied table with probability \\(\\frac{c_j}{1 - i + \\alpha}\\) where \\(c_j\\) is the number of customers already at the table -sit at a new table with probability \\(\\frac{\\alpha}{n-i+\\alpha}\\) interpretation: each table represents a cluster of subjects the number of clusters depends on the number of subjects makes sense to have the possibility of more clusters with more subjects (instead of a fixed number of clusters as in a finite mixture model) there is a description of the sampling process for the posterior of \\(\\theta_i | \\theta_{-i}\\) Hyperprior distribution \\(\\alpha\\): the DP precision parameter plays a role in controlling the prior on the number of clusters small, fixed \\(\\alpha\\) favors allocation to few clusters (relative to sample size) if \\(\\alpha=1\\), the prior indicates that two randomly selected subjects have a 50/50 chance of belonging to the same cluster alternatively can set a hyperprior on \\(\\alpha\\) and let the data inform the value common to use a Gamma distribution: \\(\\Gamma(a_\\alpha, b_\\alpha)\\) authors indicate that setting a hyperprior on \\(\\alpha\\) tends to work well in practice \\(P_0\\): base probability for the DP can think of \\(P_0\\) as setting the prior for the cluster locations can put hyperpriors on \\(P_0\\) parameters 23.4 Beyond density estimation Nonparametric residual distributions “The real attraction of Dirichlet process mixture (DPM) models is that they can be used much more broadly for relaxing parametric assumptions in hierarchical models.” (pg 557) consider the linear regression with a nonparametric error distribution (19.6) \\(X_i = (X_{i1}, \\dots, X_{ip})\\): vector of predictors \\(\\epsilon_i\\): error term with distribution \\(f\\) \\[ y_i = X_i \\beta + \\epsilon_i \\text{,} \\quad \\epsilon_i \\sim f \\tag{19.6} \\] can relax the assumption that \\(f\\) has parametric form \\[ \\epsilon_i \\sim N(0, \\phi_i^{-1}) \\text{,} \\quad \\phi \\sim P \\text{,} \\quad P \\sim \\text{DP}(\\alpha P_0) \\] Nonparametric models for parameters that vary by group consider hierarchical linear models with varying coefficients can account for uncertainty about the distribution of coefficients by placing a DP or DPM priors on them where: \\(y_i = (y_{i1}, \\dots, y_{in_i})\\): repeated measurements for item \\(i\\) \\(\\mu_i\\): subject-specific mean \\(\\epsilon_{ij}\\): observation specific residual \\[ y_{ij} = \\mu_i + \\epsilon_{ij} \\text{,} \\quad \\mu_i \\sim f \\text{,} \\quad \\epsilon_{ij} \\sim g \\tag{19.7} \\] typically for (19.7): \\(f \\equiv N(\\mu, \\phi^{-1})\\) \\(g \\equiv N(0, \\sigma^2)\\) can let more flexibility in characterizing variability among subjects: \\(\\mu_i \\sim P \\text{,} \\quad P \\sim \\text{DP}(\\alpha P_0)\\) the DP prior induces a latent class model the subjects are grouped into an unknown number of clusters (19.8) \\(S_i \\in \\{1, \\dots, \\infty\\}\\): latent class index \\(\\pi_h\\): probability of allocation to latent class \\(h\\) \\[ \\mu_i = \\mu^*_{S_i} \\text{,} \\quad \\Pr(S_i = h) = \\pi_h \\text{,} \\quad h = 1, 2, \\dots \\tag{19.8} \\] There is more to this chapter, but it is currently beyond my understanding. I hope to return to this chapter later with a better understanding of Dirichlet processes in the future. sessionInfo() #&gt; R version 4.1.2 (2021-11-01) #&gt; Platform: x86_64-apple-darwin17.0 (64-bit) #&gt; Running under: macOS Big Sur 10.16 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices datasets utils methods base #&gt; #&gt; other attached packages: #&gt; [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.7 purrr_0.3.4 #&gt; [5] readr_2.0.1 tidyr_1.1.3 tibble_3.1.3 ggplot2_3.3.5 #&gt; [9] tidyverse_1.3.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] Rcpp_1.0.7 lubridate_1.7.10 clisymbols_1.2.0 assertthat_0.2.1 #&gt; [5] digest_0.6.27 utf8_1.2.2 R6_2.5.0 cellranger_1.1.0 #&gt; [9] backports_1.2.1 reprex_2.0.1 evaluate_0.14 httr_1.4.2 #&gt; [13] highr_0.9 pillar_1.6.2 rlang_0.4.11 readxl_1.3.1 #&gt; [17] rstudioapi_0.13 jquerylib_0.1.4 rmarkdown_2.10 labeling_0.4.2 #&gt; [21] munsell_0.5.0 broom_0.7.9 compiler_4.1.2 modelr_0.1.8 #&gt; [25] xfun_0.25 pkgconfig_2.0.3 htmltools_0.5.1.1 tidyselect_1.1.1 #&gt; [29] bookdown_0.24 fansi_0.5.0 crayon_1.4.1 tzdb_0.1.2 #&gt; [33] dbplyr_2.1.1 withr_2.4.2 grid_4.1.2 jsonlite_1.7.2 #&gt; [37] gtable_0.3.0 lifecycle_1.0.0 DBI_1.1.1 magrittr_2.0.1 #&gt; [41] scales_1.1.1 cli_3.0.1 stringi_1.7.3 farver_2.1.0 #&gt; [45] renv_0.14.0 fs_1.5.0 xml2_1.3.2 bslib_0.2.5.1 #&gt; [49] ellipsis_0.3.2 generics_0.1.0 vctrs_0.3.8 tools_4.1.2 #&gt; [53] glue_1.4.2 hms_1.1.0 yaml_2.2.1 colorspace_2.0-2 #&gt; [57] rvest_1.0.1 knitr_1.33 haven_2.4.3 sass_0.4.0 "],["assignments-intro.html", "Introduction", " Introduction The sections in this part of the book are for the nine course assignments. Some may be missing a question or two because it is a text-based answer that I was confident in my answer, too. "],["assignment-1.html", "20 Assignment 1 20.1 Setup 20.2 Exercise 1 20.3 Exercise 3 20.4 Exercise 4 20.5 Exercise 5", " 20 Assignment 1 2021-08-19 Assignment 1 20.1 Setup knitr::opts_chunk$set(echo = TRUE, comment = &quot;#&gt;&quot;, dpi = 300) library(glue) 20.2 Exercise 1 (Basic probability theory notation and terms). This can be trivial or you may need to refresh your memory on these concepts. Note that some terms may be different names for the same concept. Explain each of the following terms with one sentence: probability: how likely some assertion is to be true probability mass: how likely a discrete random variable is to be some value probability density: how likely a continuous random variable is to be some value probability mass function (pmf): a function describing how likely a discrete random variable is to be any possible value probability density function (pdf): a function describing how likely a continuous random variable is to be any possible value probability distribution: a function describing how likely a random variable is to be of some value discrete probability distribution: a probability distribution over discrete values continuous probability distribution: a probability distribution over continuous values cumulative distribution function (cdf): the cumulative sum of probabilities from a probability distribution likelihood: how probable some event is under a given hypothesis 20.3 Exercise 3 (Bayes’ theorem) A group of researchers has designed a new inexpensive and painless test for detecting lung cancer. The test is intended to be an initial screening test for the population in general. A positive result (presence of lung cancer) from the test would be followed up immediately with medication, surgery or more extensive and expensive test. The researchers know from their studies the following facts: Test gives a positive result in 98% of the time when the test subject has lung cancer. Test gives a negative result in 96 % of the time when the test subject does not have lung cancer. In general population approximately 1 person in 1000 has lung cancer. The researchers are happy with these preliminary results (about 97% success rate), and wish to get the test to market as soon as possible. How would you advise them? Base your answer on Bayes’ rule computations. Hint: Relatively high false negative (cancer doesn’t get detected) or high false positive (unnecessarily administer medication) rates are typically bad and undesirable in tests. Hint: Here are some probability values that can help you figure out if you copied the right conditional probabilities from the question. \\(P(\\text{Test gives positive} | \\text{Subject does not have lung cancer}) = 0.04\\) \\(P(\\text{Test gives positive and Subject has lung cancer}) = 0.00098\\) this is also referred to as the joint probability of test being positive and the subject having lung cancer. We are interested in the false positive and false negative rates. The false positive rate, a positive test when the patient does not have cancer, is calculated below using Bayes’ rule: \\[ \\Pr(\\text{no cancer} | \\text{positive test}) = \\frac{\\Pr(\\text{no cancer}) \\Pr(\\text{positive test} | \\text{no cancer})}{\\Pr(\\text{positive test})} \\] Each of the components: \\[ \\Pr(\\text{no cancer}) = 999/1000\\\\ \\Pr(\\text{positive test} | \\text{no cancer}) = 4\\% = 4/100\\\\ \\begin{aligned} \\Pr(\\text{positive test}) &amp;= \\Pr(\\text{positive test AND cancer}) + \\Pr(\\text{positive test AND no cancer}) \\\\ &amp;= \\frac{98}{100} \\frac{1}{1000} + \\frac{4}{100} \\frac{999}{1000} = \\frac{4094}{100000} \\end{aligned} \\] thus \\[ \\begin{aligned} \\Pr(\\text{no cancer} | \\text{positive test}) &amp;= \\frac{\\Pr(\\text{no cancer}) \\Pr(\\text{positive test} | \\text{no cancer})}{\\Pr(\\text{positive test})} \\\\ &amp;= \\frac{\\frac{999}{1000} \\frac{4}{100}}{\\frac{4094}{100000}} \\\\ &amp;= 0.976 \\\\ &amp;= 97.6 \\% \\end{aligned} \\] The false positive rate, a negative test when the patient does have cancer, is calculated below using Bayes’ rule: \\[ \\Pr(\\text{cancer} | \\text{negative test}) = \\frac{\\Pr(\\text{cancer}) \\Pr(\\text{negative test} | \\text{cancer})}{\\Pr(\\text{negative test})} \\] Each of the components: \\[ \\Pr(\\text{cancer}) = 1/1000\\\\ \\Pr(\\text{negative test} | \\text{cancer}) = 1-0.98 = 2/100 \\\\ \\begin{aligned} \\Pr(\\text{negative test}) &amp;= \\Pr(\\text{negative test AND cancer}) + \\Pr(\\text{negative test AND no cancer}) \\\\ &amp;= \\frac{2}{100} \\frac{1}{1000} + \\frac{96}{100} \\frac{999}{1000} = \\frac{95906}{100000} \\end{aligned} \\] Thus, \\[ \\begin{aligned} \\Pr(\\text{cancer} | \\text{negative test}) &amp;= \\frac{\\Pr(\\text{cancer}) \\Pr(\\text{negative test} | \\text{cancer})}{\\Pr(\\text{negative test})} \\\\ &amp;= \\frac{\\frac{1}{1000} \\frac{2}{100}}{\\frac{95906}{100000}} \\\\ &amp;= 0.0000209 \\\\ &amp;= 0.00209 \\% \\end{aligned} \\] The false negative rate is quite low, primarily because the cancer is relatively rare to begin with. But, for the same reason, the false positive rate is very high. Therefore, it could be advised that positive tests are confirmed with an independently-conducted second test or another testing procedure (e.g. CT scan). Taking the test twice will only help if the false positive is caused by randomness and is not due to some other factor of the patient (e.g. the test is picking up some metabolite this patient produces due to their specific diet). 20.4 Exercise 4 We have three boxes, A, B, and C. There are 2 red balls and 5 white balls in the box A, 4 red balls and 1 white ball in the box B, and 1 red ball and 3 white balls in the box C. Consider a random experiment in which one of the boxes is randomly selected and from that box, one ball is randomly picked up. After observing the color of the ball it is replaced in the box it came from. Suppose also that on average box A is selected 40% of the time and box B 10% of the time (i.e. P (A) = 0.4). What is the probability of picking a red ball? If a red ball was picked, from which box it most probably came from? Implement two functions in R that computes the probabilities. 20.4.1 4.a \\[ \\Pr(red) = \\Sigma_{b}^{boxes} \\Pr(\\text{red} | \\text{box}_b) \\Pr(\\text{box}_b) \\] # Contents of the boxes. boxes &lt;- matrix( c(2, 4, 1, 5, 1, 3), ncol = 2, dimnames = list(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), c(&quot;red&quot;, &quot;white&quot;)) ) # Probability of selecting each box. box_probs &lt;- matrix( c(0.4, 0.1, 0.5), ncol = 1, dimnames = list(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)) ) # Calculate the probability of red per box. p_red_per_box &lt;- function(boxes) { return(boxes[, &quot;red&quot;] / apply(boxes, 1, sum)) } # Calculate the probability of pulling red. p_red &lt;- function(boxes, box_probs) { red_probs &lt;- p_red_per_box(boxes) return(sum(red_probs * box_probs)) } prob_red &lt;- p_red(boxes, box_probs) print(glue(&quot;probability of red: {prob_red}&quot;)) #&gt; probability of red: 0.319285714285714 # Calculate the prob. that each box was used given a red ball was selected. p_box &lt;- function(boxes, box_probs) { prob_red &lt;- p_red(boxes, box_probs) red_probs &lt;- p_red_per_box(boxes) box_probs_red &lt;- c() for (box in rownames(box_probs)) { p &lt;- unlist(box_probs[box, ]) * unlist(red_probs[box]) / prob_red box_probs_red &lt;- c(box_probs_red, p) } names(box_probs_red) &lt;- rownames(box_probs) return(box_probs_red) } probs_of_boxes &lt;- p_box(boxes = boxes, box_probs = box_probs) stopifnot(sum(probs_of_boxes) == 1) probs_of_boxes #&gt; A B C #&gt; 0.3579418 0.2505593 0.3914989 20.5 Exercise 5 Assume that on average fraternal twins (two fertilized eggs and then could be of different sex) occur once in 150 births and identical twins (single egg divides into two separate embryos, so both have the same sex) once in 400 births (Note! This is not the true values, see Exercise 1.6, page 28, in BDA3). American male singer-actor Elvis Presley (1935 – 1977) had a twin brother who died in birth. Assume that an equal number of boys and girls are born on average. What is the probability that Elvis was an identical twin? Show the steps how you derived the equations to compute that probability. State the problem as a conditional probability and use Bayes’ rule to decompose into simpler terms. \\[ \\begin{aligned} \\Pr(\\text{Elvis was an identical twin}) &amp;= \\\\ \\Pr(\\text{identical} | \\text{twin AND brother}) &amp;= \\frac{\\Pr(\\text{identical})\\Pr(\\text{twin AND bro} | \\text{identical})}{\\Pr(\\text{twin AND bro})} \\\\ \\end{aligned} \\] Each component separately. \\[ \\Pr(\\text{identical}) = \\frac{1}{400} \\\\ \\Pr(\\text{twin AND bro} | \\text{identical}) = \\frac{1}{2} \\\\ \\] \\[ \\begin{aligned} \\Pr(\\text{twin AND bro}) &amp;= \\Pr(\\text{identical AND bro}) + \\Pr(\\text{fraternal AND bro}) \\\\ &amp;= \\frac{1}{400} \\frac{1}{2} + \\frac{1}{150} \\frac{1}{4} \\\\ &amp;= \\frac{7}{2400} \\\\ \\end{aligned} \\] Thus, \\[ \\Pr(\\text{identical} | \\text{twin AND brother}) = \\frac{\\frac{1}{400} \\frac{1}{2}}{\\frac{7}{2400}} = 0.429 \\] Implement this as a function in R that computes the probability. p_identical_twin &lt;- function(fraternal_prob, identical_prob) { (identical_prob * 0.5) / (identical_prob * 0.5 + fraternal_prob * 0.25) } # Tests from provided examples. stopifnot(round(p_identical_twin(1 / 125, 1 / 300), 7) == 0.4545455) stopifnot(round(p_identical_twin(1 / 100, 1 / 500), 7) == 0.2857143) p_identical_twin(fraternal_prob = 1 / 150, identical_prob = 1 / 400) #&gt; [1] 0.4285714 "],["assignment-2.html", "21 Assignment 2 21.1 Setup 21.2 Exercise 1. Inference for binomial proportion", " 21 Assignment 2 2021-08-30 Assignment 2 21.1 Setup knitr::opts_chunk$set(echo = TRUE, comment = &quot;#&gt;&quot;, dpi = 300) for (f in list.files(here::here(&quot;src&quot;), pattern = &quot;R$&quot;, full.names = TRUE)) { source(f) } # Libraries library(aaltobda) library(glue) library(tidyverse) # Data algae &lt;- readLines(here::here(&quot;data&quot;, &quot;algae.txt&quot;)) algae &lt;- as.integer(algae) 21.2 Exercise 1. Inference for binomial proportion Algae status is monitored in 274 sites at Finnish lakes and rivers. The observations for the 2008 algae status at each site are presented in file “algae.txt” (’0’: no algae, ’1’: algae present). Let \\(\\pi\\) be the probability of a monitoring site having detectable blue-green algae levels and \\(y\\) the observations in algae. Use a binomial model for the observations \\(y\\) and a \\(\\text{Beta}(2, 10)\\) prior for binomial model parameter \\(\\pi\\) to formulate a Bayesian model. a) Formulate (1) the likelihood \\(p(y|\\pi)\\) as a function of \\(\\pi\\), (2) the prior \\(p(\\pi)\\), and (3) the resulting posterior \\(p(\\pi|y)\\). print(head(algae)) #&gt; [1] 0 1 1 0 0 0 print(paste(&quot;Number of data points:&quot;, length(algae))) #&gt; [1] &quot;Number of data points: 274&quot; print(paste(&quot;Number of 1&#39;s:&quot;, sum(algae))) #&gt; [1] &quot;Number of 1&#39;s: 44&quot; print(paste(&quot;Prop. of 1&#39;s:&quot;, round(mean(algae), 3))) #&gt; [1] &quot;Prop. of 1&#39;s: 0.161&quot; likelihood: \\(p(y|\\pi) = \\text{Beta}(44, 274-44)\\) prior: \\(p(\\pi) = \\text{Beta}(2, 10)\\) posterior: \\(p(\\pi|y) = \\text{Beta}(46, 240)\\) b) What can you say about the value of the unknown according to the observations and your prior knowledge? Summarize your results with a point estimate (i.e. \\(E(\\pi|y)\\)) and a 90% posterior interval. Some test data provided by the question to check if I’m on the right track. algae_test &lt;- c(0, 1, 1, 0, 0, 0) beta_point_est &lt;- function(prior_alpha, prior_beta, data) { y &lt;- sum(data) n &lt;- length(data) posterior &lt;- (prior_alpha + y) / (prior_alpha + prior_beta + n) return(posterior) } posterior_test &lt;- beta_point_est( prior_alpha = 2, prior_beta = 10, data = algae_test ) stopifnot(round(posterior_test, 7) == 0.2222222) beta_point_est(prior_alpha = 2, prior_beta = 10, data = algae) #&gt; [1] 0.1608392 beta_interval &lt;- function(prior_alpha, prior_beta, data, prob = 0.9) { y &lt;- sum(data) n &lt;- length(data) p_low &lt;- (1 - prob) / 2 q_low &lt;- qbeta(p_low, prior_alpha + y, prior_beta + n - y) q_high &lt;- qbeta(1 - p_low, prior_alpha + y, prior_beta + n - y) return(c(q_low, q_high)) } posterior_interval_test &lt;- beta_interval( prior_alpha = 2, prior_beta = 10, data = algae_test, prob = 0.9 ) stopifnot(round(posterior_interval_test, 7) == c(0.0846451, 0.3956414)) beta_interval(prior_alpha = 2, prior_beta = 10, data = algae, prob = 0.9) #&gt; [1] 0.1265607 0.1978177 c) What is the probability that the proportion of monitoring sites with detectable algae levels \\(\\pi\\) is smaller than \\(\\pi_\\theta = 0.2\\) that is known from historical records? beta_low &lt;- function(prior_alpha, prior_beta, data, pi_0 = 0.2) { y &lt;- sum(data) n &lt;- length(data) prob &lt;- pbeta(pi_0, prior_alpha + y, prior_beta + n - y, lower.tail = TRUE) return(prob) } test_prob &lt;- beta_low( prior_alpha = 2, prior_beta = 10, data = algae_test, pi_0 = 0.2 ) stopifnot(round(test_prob, 7) == 0.4511238) beta_low(prior_alpha = 2, prior_beta = 10, data = algae, pi_0 = 0.2) #&gt; [1] 0.9586136 d) What assumptions are required in order to use this kind of a model with this type of data? (No need to discuss exchangeability yet, as it is discussed in more detail in BDA Chapter 5 and Lecture 7.) We need to assume that the data is independently and identically distributed, which included the assumption that the data is exchangable. We are also assuming the data is accuractely collected in a consistent manner. We are assuming there are no subgroups within the data that would necessitate a hierarchical model to account for the random effects variation. e) Make prior sensitivity analysis by testing a couple of different reasonable priors and plot the different posteriors. Summarize the results by one or two sentences. # Some interesting priors. priors &lt;- tibble::tribble( ~prior_alpha, ~prior_beta, 1, 1, 2, 2, 2, 10, 4, 20, 20, 100, ) %&gt;% mutate( lbl = glue(&quot;Beta({prior_alpha},{prior_beta})&quot;), lbl = fct_inorder(lbl) ) priors #&gt; # A tibble: 5 × 3 #&gt; prior_alpha prior_beta lbl #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 1 1 Beta(1,1) #&gt; 2 2 2 Beta(2,2) #&gt; 3 2 10 Beta(2,10) #&gt; 4 4 20 Beta(4,20) #&gt; 5 20 100 Beta(20,100) posterior_distribution &lt;- function(prior_alpha, prior_beta, data, step = 0.001, ...) { y &lt;- sum(data) n &lt;- length(data) pi &lt;- seq(0, 1, step) posterior &lt;- dbeta(pi, prior_alpha + y, prior_beta + n - y) return(tibble(pi = pi, posterior = posterior)) } # Get the posterior distribution for each prior. posteriors &lt;- priors %&gt;% mutate(posterior = purrr::map2( prior_alpha, prior_beta, posterior_distribution, data = algae )) %&gt;% unnest(posterior) # Plot the most interesting region of the posteriors. posteriors %&gt;% filter(0.05 &lt; pi &amp; pi &lt; 0.3) %&gt;% ggplot(aes(x = pi, y = posterior)) + geom_line(aes(group = lbl, color = lbl), size = 0.9) + scale_x_continuous(expand = expansion()) + scale_y_continuous(expand = expansion(mult = c(0.01, 0.02))) + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set1&quot;) + theme_bw() + theme(legend.position = c(0.85, 0.7)) + labs(x = &quot;pi&quot;, y = &quot;posterior probability&quot;, color = &quot;prior&quot;) The posterior is not very sensitive to the prior save for the exception of an overly-confident prior of \\(\\text{Beta}(20, 100)\\). This is likely due to the large amount of data, meaning that the likelihood dominated the posterior. "],["assignment-3.html", "22 Assignment 3 22.1 Setup 22.2 Exercise 1. Inference for normal mean and deviation 22.3 Exercise 2. Inference for the difference between proportions 22.4 Exercise 3. Inference for the difference between normal means", " 22 Assignment 3 2021-09-07 Assignment 3 22.1 Setup knitr::opts_chunk$set(echo = TRUE, comment = &quot;#&gt;&quot;, dpi = 300) for (f in list.files(here::here(&quot;src&quot;), pattern = &quot;R$&quot;, full.names = TRUE)) { source(f) } library(glue) library(tidyverse) theme_set(theme_bw() + theme(plot.title = element_text(hjust = 0.5))) set.seed(748) 22.2 Exercise 1. Inference for normal mean and deviation A factory produces car windshields and we have sample of data from testing their hardness. Assume the observations follow a normal distribution with unknown standard deviation. Also use an uninformative prior \\(p(\\mu, \\sigma) \\propto \\sigma^{-1}\\). windshieldy &lt;- read_data(&quot;windshieldy1.txt&quot;) windshieldy &lt;- as.numeric(windshieldy) windshieldy_test &lt;- c(13.357, 14.928, 14.896, 14.820) a) What can you say about the unknown \\(\\mu\\)? Summarize your results using Bayesian point estimate (i.e. \\(E(\\mu|y)\\)), a posterior interval (95%), and plot the density. The point estimate and 95% CI for \\(\\mu\\) can be calculated using the \\(t\\)-distribution and scaling the result according to the following equation for BDA3 (pg. 66): \\[ \\frac{\\mu - \\bar{y}}{s / \\sqrt{n}} | y \\sim t_{n-1} \\] where \\[ s = \\frac{1}{n-1} \\Sigma(y - \\bar{y})^2 \\] and \\(n\\) is the total number of data points. calc_s_statistic &lt;- function(a) { s_sqr &lt;- (1 / (length(a) - 1)) * sum((a - mean(a))^2) return(sqrt(s_sqr)) } mu_point_est &lt;- function(data, q = 0.5) { y &lt;- data n &lt;- length(y) y_bar &lt;- mean(y) s &lt;- calc_s_statistic(y) t_prob &lt;- qt(q, df = n - 1) return(t_prob * s / sqrt(n) + y_bar) } stopifnot(close_to(mu_point_est(data = windshieldy_test), 14.5)) mu_point_est(data = windshieldy) #&gt; [1] 14.61122 mu_interval &lt;- function(data, prob = 0.95) { lower_q &lt;- (1 - prob) / 2.0 upper_q &lt;- 1 - lower_q return(c(mu_point_est(data, lower_q), mu_point_est(data, upper_q))) } stopifnot(all(close_to( mu_interval(data = windshieldy_test, prob = 0.95), c(13.3, 15.7), epsilon = 0.1 ))) mu_interval(data = windshieldy) #&gt; [1] 13.47808 15.74436 The probability density function of \\(\\mu\\) can be estimated using the same equations. The PDF is plotted below. mu_density &lt;- function(mu, data) { y &lt;- data n &lt;- length(y) y_bar &lt;- mean(y) s &lt;- calc_s_statistic(y) mu_trans &lt;- (mu - y_bar) / (s / sqrt(n)) d &lt;- dt(mu_trans, df = n - 1) return(d) } mus &lt;- seq(11.5, 17.5, 0.01) mu_dens &lt;- purrr::map_dbl(mus, ~ mu_density(.x, windshieldy)) plot_dist( mus, mu_dens, xlab = &quot;mu&quot;, ylab = &quot;probability&quot;, main = &quot;posterior distribution of mu&quot; ) The PDF for \\(\\sigma\\) can be calculated analytically from equation 3.5 in BDA (pg. 65). \\[ \\sigma^2 | y \\sim \\text{Inv-}\\chi^2(n-1, s^2) \\] where \\(n\\) and \\(s\\) have the same description as above. The \\(\\text{Inv-}\\chi^2(\\nu, s^2)\\) distribution is the scaled inverse chi-squared distribution parameterized by the degrees of freedom \\(\\nu\\) and scale \\(s\\) (BDA3, Appendix A, pg. 578). I used the function dinvchisq() from the package ‘LaplacesDemon’ to calculate the probabilities of values of \\(\\sigma^2\\). The PDF for \\(sigma^2\\) is plotted below. sigma_probability &lt;- function(x, data) { nu &lt;- length(data) - 1 s &lt;- calc_s_statistic(data) d &lt;- LaplacesDemon::dinvchisq(x = x, df = nu, scale = s) return(d) } sigmas &lt;- seq(0, 10.0, 0.01) sigmas &lt;- sigmas[2:length(sigmas)] sigma_dens &lt;- purrr::map_dbl(sigmas, ~ sigma_probability(.x, windshieldy)) plot_dist( sigmas, sigma_dens, xlab = &quot;sigma^2&quot;, ylab = &quot;probability&quot;, main = &quot;posterior distribution of sigma^2&quot; ) b) What can you say about the hardness of the next windshield coming from the production line before actually measuring the hardness? Summarize your results using Bayesian point estimate, a predictive interval (95%), and plot the density. Random values of \\(\\mu\\) can be sampled from the \\(t\\)-distribution (and transformed as explained above) and samples for \\(\\sigma^2\\) can be sampled from the \\(\\text{Inv-}\\chi^2\\) distribution. Another option for sampling \\(\\sigma^2\\) is to first sample values \\(X\\) from the \\(\\chi_\\nu^2\\) distribution and transform them by \\(\\nu s^2 / X\\) (BDA3, Appendix A, pg. 583). The posterior predictive sampling procedure was to sample 1,000 random values for \\(\\mu\\) and \\(\\sigma\\) then sample a random value from a normal distribution described with each pair of the random values. random_mu &lt;- function(n, data) { y &lt;- data nu &lt;- length(y) y_bar &lt;- mean(y) s &lt;- calc_s_statistic(y) r &lt;- rt(n, df = nu) return(r * s / sqrt(nu) + y_bar) } scaled_rinvchiq &lt;- function(n, data) { nu &lt;- length(data) - 1 s &lt;- calc_s_statistic(data) theta &lt;- LaplacesDemon::rinvchisq(n = n, df = nu, scale = s) return(theta) } n &lt;- 1e4 r_sigmas_sqrd &lt;- scaled_rinvchiq(n, data = windshieldy) r_mus &lt;- random_mu(n, data = windshieldy) y_tildes &lt;- rnorm(n, mean = r_mus, sd = sqrt(r_sigmas_sqrd)) The plot below shows 100 of the randomly created normal distributions form the sampled values of \\(\\mu\\) and \\(\\sigma\\). get_densities_over_x &lt;- function(mu, sigma, a = 10, b = 20, stepsize = 0.1) { x &lt;- seq(a, b, stepsize) y &lt;- dnorm(x, mean = mu, sd = sigma) return(tibble(x, y)) } plot_n &lt;- 100 tibble( sigma = head(sqrt(r_sigmas_sqrd), n = plot_n), mu = head(r_mus, n = plot_n) ) %&gt;% mutate( grp = glue(&quot;mu = {round(mu, 2)}, sigma = {round(sigma, 2)}&quot;), dist_data = purrr::map2(mu, sigma, get_densities_over_x) ) %&gt;% unnest(dist_data) %&gt;% ggplot(aes(x = x, y = y)) + geom_line(aes(group = grp), alpha = 0.25) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = expansion(mult = c(0, 0.02))) + labs( x = &quot;windshield hardness&quot;, y = &quot;probability&quot;, title = &quot;Posterior distributions for the hardness of windshield&quot; ) The density of the posterior samples for \\(\\mu\\) and \\(\\sigma\\) is shown in the plot below. post_pred_df &lt;- tibble( mu = r_mus, sigma = sqrt(r_sigmas_sqrd), y_tilde = y_tildes ) post_pred_df %&gt;% ggplot(aes(x = mu, y = sigma)) + geom_point(alpha = 0.5, size = 0.2) + geom_density2d() + scale_x_continuous(expand = expansion(mult = c(0.02, 0.02))) + scale_y_continuous(expand = expansion(mult = c(0.02, 0.02))) + labs(title = &quot;Posterior samples for distribution parameters&quot;) Finally, the following is the posterior predictive distribution. post_pred_df %&gt;% add_column(grp = &quot;y_tilde&quot;) %&gt;% bind_rows(tibble(y_tilde = windshieldy, grp = &quot;y&quot;)) %&gt;% ggplot(aes(x = y_tilde)) + geom_rug(aes(x = y), data = tibble(y = windshieldy)) + geom_density(aes(color = grp)) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = expansion(mult = c(0, 0.02))) + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set1&quot;) + labs( x = &quot;windshield hardness&quot;, y = &quot;density&quot;, color = NULL, title = &quot;Posterior predicitive distribution&quot; ) Using the functions created above, I can address the specific tests provided with the question. It would be better to provide an analytic solution by integrating over the probability densities of \\(\\sigma\\) and \\(\\mu\\), but these sampling-based solutions are pretty close. post_pred_sample &lt;- function(data, n) { mu &lt;- random_mu(n, data = data) sigma &lt;- sqrt(scaled_rinvchiq(n, data = data)) purrr::map2_dbl(mu, sigma, ~ rnorm(1, mean = .x, sd = .y)) } mu_pred_point_est &lt;- function(data, n = 1e6, iters = 5) { lapply( seq(1, iters), function(x) { mean(post_pred_sample(data = data, n = n)) } ) %&gt;% unlist() %&gt;% mean() } mu_pred_interval &lt;- function(data, prob, n = 1e7) { lower_q &lt;- (1.0 - prob) / 2.0 upper_q &lt;- 1.0 - lower_q post_pred_samples &lt;- post_pred_sample(data = data, n = n) quantile(post_pred_samples, c(lower_q, upper_q)) } stopifnot(close_to( mu_pred_point_est(data = windshieldy_test), 14.5, epsilon = 0.1 )) stopifnot(all(close_to( mu_pred_interval(data = windshieldy_test, prob = 0.95), c(11.8, 17.2), epsilon = 0.5 ))) mu_pred_point_est(data = windshieldy) #&gt; [1] 14.61259 mu_pred_interval(data = windshieldy, prob = 0.95) #&gt; 2.5% 97.5% #&gt; 11.61276 17.61140 22.3 Exercise 2. Inference for the difference between proportions An experiment was performed to estimate the effect of beta-blockers on mortality of cardiac patients. A group of patients was randomly assigned to treatment and control groups: out of 674 patients receiving the control, 39 died, and out of 680 receiving the treatment, 22 died. Assume that the outcomes are independent and binomially distributed, with probabilities of death of \\(p_0\\) and \\(p_1\\) under the control and treatment, respectively. Set up a non-informative or weakly informative prior distribution on \\((p_0,p_1)\\). a) Summarize the posterior distribution for the odds ratio, \\(\\frac{p_1 / (1-p_1)}{p_0 / (1-p_0)}\\). Compute the point estimate, a posterior interval (95%), and plot the histogram. priors: \\(p_0, p_1 \\sim \\text{Beta}(2, 5)\\) x &lt;- seq(0, 1, 0.01) p &lt;- dbeta(x, 2, 5) plot_dist( x = x, y = p, xlab = &quot;proportion&quot;, ylab = &quot;probability&quot;, main = &quot;Prior distribution for p0, p1 ~ Beta(2, 5)&quot; ) likelihoods: \\(y_0|p_0, n_0 \\sim \\text{Binomial}(p_0, n_0)\\) \\(y_1|p_1, n_1 \\sim \\text{Binomial}(p_1, n_1)\\) posteriors: \\(p_0|y_0, n_0 \\sim \\text{Beta}(y_0 + 2, n_0 - y_0 + 5)\\) \\(p_1|y_1, n_1 \\sim \\text{Beta}(y_1 + 2, n_1 - y_1 + 5)\\) # Calculate the odds ratio given two values or vectors. posterior_odds_ratio &lt;- function(p0, p1) { or &lt;- (p1 / (1 - p1)) / (p0 / (1 - p0)) return(or) } # Calculate a point estimate (mean) for the OR. posterior_odds_ratio_point_est &lt;- function(p0, p1) { return(mean(posterior_odds_ratio(p0, p1))) } # Find probability intervals for the posterior OR. posterior_odds_ratio_interval &lt;- function(p0, p1, prob = 0.95) { lower_q &lt;- (1.0 - prob) / 2.0 upper_q &lt;- 1.0 - lower_q or &lt;- posterior_odds_ratio(p0, p1) return(quantile(or, c(lower_q, upper_q))) } I can check my calculations and implementation using the test data provided with the exercise. # test data set.seed(4711) p0 &lt;- rbeta(100000, 5, 95) p1 &lt;- rbeta(100000, 10, 90) stopifnot(close_to( posterior_odds_ratio_point_est(p0 = p0, p1 = p1), 2.676, epsilon = 0.01 )) stopifnot(all(close_to( posterior_odds_ratio_interval(p0 = p0, p1 = p1, prob = 0.9), c(0.875, 6.059), epsilon = 0.01 ))) Finally, I can address the question using the following values: \\(n_0= 674\\), \\(y_0 = 39\\), \\(n_1=680\\), and \\(y_1 = 22\\). I used a weakly informative prior \\(\\text{Beta}(2, 5)\\) I first drew samples from the posteriors for \\(p_0\\) and \\(p_1\\) then used those to calculate the posterior for the odds ratio. n0 &lt;- 674 y0 &lt;- 39 n1 &lt;- 680 y1 &lt;- 22 prior_a &lt;- 2 prior_b &lt;- 5 sample_posterior_p &lt;- function(prior_a, prior_b, y, n, draws = 1e6) { a &lt;- prior_a + y b &lt;- prior_b + n - y return(rbeta(draws, a, b)) } p0_post &lt;- sample_posterior_p(prior_a, prior_b, y = y0, n = n0) p1_post &lt;- sample_posterior_p(prior_a, prior_b, y = y1, n = n1) post_or &lt;- posterior_odds_ratio(p0_post, p1_post) The posterior distributions of \\(p_0\\) and \\(p_1\\) are shown below. From this plot, it appears that \\(p_1\\) is likely lower than \\(p_0\\) and we should expect an \\(OR &lt; 1\\). plot_two_distributions(p0_post, &quot;p0&quot;, p1_post, &quot;p1&quot;) + labs( x = &quot;parameter value&quot;, y = &quot;density&quot;, color = &quot;parameter&quot;, fill = &quot;parameter&quot; ) The posterior distribution for the odds ratio is plotted below and it is shifted primarily to values less than 1. plot_single_distribution(post_or) + labs(x = &quot;odds ratio&quot;, y = &quot;density&quot;) b) Discuss the sensitivity of your inference to your choice of prior density with a couple of sentences. # Non-informative priors prior_a &lt;- 1 prior_b &lt;- 1 sample_posterior_p &lt;- function(prior_a, prior_b, y, n, draws = 1e6) { a &lt;- prior_a + y b &lt;- prior_b + n - y return(rbeta(draws, a, b)) } p0_post_noinfo &lt;- sample_posterior_p(prior_a, prior_b, y = y0, n = n0) p1_post_noinfo &lt;- sample_posterior_p(prior_a, prior_b, y = y1, n = n1) post_or_noinfo &lt;- posterior_odds_ratio(p0_post_noinfo, p1_post_noinfo) plot_single_distribution(post_or_noinfo) plot_two_distributions(post_or, &quot;weakly info.&quot;, post_or_noinfo, &quot;non-info.&quot;) + labs(x = &quot;odds ratio&quot;, y = &quot;density&quot;, color = &quot;prior&quot;, fill = &quot;prior&quot;) The difference in influence on the posterior inference between a weakly informative prior \\(\\text{Beta}(2, 5)\\) and non-informative, uniform prior \\(\\text{Beta}(1, 1)\\) is negligible. The large number of data points overwhelms the prior’s influence. This can be tested by experimenting with a very strong prior \\(\\text{Beta}(1000, 5)\\), as shown below. # Strong priors prior_a &lt;- 1000 prior_b &lt;- 5 sample_posterior_p &lt;- function(prior_a, prior_b, y, n, draws = 1e6) { a &lt;- prior_a + y b &lt;- prior_b + n - y return(rbeta(draws, a, b)) } p0_post_strong &lt;- sample_posterior_p(prior_a, prior_b, y = y0, n = n0) p1_post_strong &lt;- sample_posterior_p(prior_a, prior_b, y = y1, n = n1) post_or_strong &lt;- posterior_odds_ratio(p0_post_strong, p1_post_strong) plot_two_distributions(post_or, &quot;weakly info.&quot;, post_or_strong, &quot;strong&quot;) + labs(x = &quot;odds ratio&quot;, y = &quot;density&quot;, color = &quot;prior&quot;, fill = &quot;prior&quot;) 22.4 Exercise 3. Inference for the difference between normal means Consider a case where the same factory has two production lines for manufacturing car windshields. Independent samples from the two production lines were tested for hardness. We assume that the samples have unknown standard deviations \\(\\sigma_1\\) and \\(\\sigma_2\\). Use uninformative or weakly informative priors. windshieldy1 &lt;- read_data(&quot;windshieldy1.txt&quot;) %&gt;% as.numeric() windshieldy2 &lt;- read_data(&quot;windshieldy2.txt&quot;) %&gt;% as.numeric() a) What can you say about \\(\\mu_d = \\mu_1 - \\mu_2\\)? I calculated \\(\\mu_1\\) and \\(\\mu_2\\) as in Exercise 1. The posterior distributions for these parameters is plotted below along with the actual observed values along the x-axis. mus &lt;- seq(11.5, 17.5, 0.01) mu1_dens &lt;- purrr::map_dbl(mus, ~ mu_density(.x, windshieldy1)) mu2_dens &lt;- purrr::map_dbl(mus, ~ mu_density(.x, windshieldy2)) data_tibble &lt;- tibble( prod_line = c(rep(&quot;1&quot;, length(windshieldy1)), rep(&quot;2&quot;, length(windshieldy2))), y = c(windshieldy1, windshieldy2) ) tibble( mu = c(mus, mus), prob = c(mu1_dens, mu2_dens), prod_line = c(rep(&quot;1&quot;, length(mu1_dens)), rep(&quot;2&quot;, length(mu2_dens))) ) %&gt;% ggplot() + geom_line(aes(x = mu, y = prob, color = prod_line)) + geom_rug(aes(x = y, color = prod_line), data = data_tibble, size = 1.2) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = expansion(mult = c(0, 0.02))) + labs(x = &quot;windshield hardness&quot;, y = &quot;probability&quot;, color = &quot;production line&quot;) As before, I can sample from the posteriors of \\(\\mu_1\\) and \\(\\mu_2\\) and use these simulated values for further calculations, in this case \\(\\mu_d = \\mu_1 - \\mu_2\\). The distribution for \\(\\mu_d\\) is plotted below. n &lt;- 1e6 mu1_draws &lt;- random_mu(n, data = windshieldy1) mu2_draws &lt;- random_mu(n, data = windshieldy2) mud_draws &lt;- mu1_draws - mu2_draws plot_single_distribution(mud_draws) + theme(axis.title.x = ggtext::element_markdown()) + labs(x = &quot;µ&lt;sub&gt;d&lt;/sub&gt;&quot;, y = &quot;probability density&quot;) Using the simulated posterior, I can get an estimate for the expected value of \\(\\mu_d\\) as the mean of the posterior distribution. glue( &quot;point estimate for µ_d as mean of posterior = {round(mean(mud_draws), 3)}&quot; ) #&gt; point estimate for µ_d as mean of posterior = -1.21 I can also use the simulated values to get 95% CI of the posterior. mud_95ci &lt;- round(quantile(mud_draws, c(0.025, 0.975)), 3) glue(&quot;95% CI of posterior for µ_d: {mud_95ci[[1]]}, {mud_95ci[[2]]}&quot;) #&gt; 95% CI of posterior for µ_d: -2.432, 0.012 Lastly, I can calculate the probability that \\(\\mu_1\\) is less than \\(\\mu_2\\), i.e. \\(\\mu_d &lt; 0\\). prob_mud_neg &lt;- mean(mud_draws &lt; 0) glue(&quot;Pr(µ_1 &lt; µ_2) = {round(prob_mud_neg, 3)}&quot;) #&gt; Pr(µ_1 &lt; µ_2) = 0.974 b) Given the model used, what is the probability that the means are exactly the same (\\(\\mu_1 = \\mu_2\\))? Explain your reasoning. The probability that \\(\\mu_1 = \\mu_2\\) is technically 0 because we cannot compute the probability of individual values. Instead, we can define a region of practical equivalence (ROPE) that represents a range of values where we would say the values are effectively the same. Ideally, we would ask someone with domain expertise to devise a region based on the real-world meaning of the values, but, in this example with windshield hardness, that is not possible. Thus, I will define the ROPE to be 1% of the standard deviation of the observed hardness measurements: \\(0.01 \\times \\sigma(y_1, y_2)\\). rope &lt;- sd(c(windshieldy1, windshieldy2)) * 0.01 rope #&gt; [1] 0.01278151 prob_rope &lt;- mean((mud_draws &gt; -rope) &amp; (mud_draws &lt; rope)) glue(&quot;probability that µ_d is within the ROPE: {round(prob_rope, 3)}&quot;) #&gt; probability that µ_d is within the ROPE: 0.002 "],["assignment-4.html", "23 Assignment 4 23.1 Setup 23.2 Exercise 1. Bioassay model", " 23 Assignment 4 2021-09-23 Assignment 4 23.1 Setup knitr::opts_chunk$set(echo = TRUE, comment = &quot;#&gt;&quot;, dpi = 300) for (f in list.files(here::here(&quot;src&quot;), pattern = &quot;R$&quot;, full.names = TRUE)) { source(f) } library(glue) library(tidyverse) theme_set(theme_classic()) light_blue &lt;- &quot;#7AAED1&quot; dark_blue &lt;- &quot;#011F4B&quot; 23.2 Exercise 1. Bioassay model In this exercise, you will use a dose-response relation model that is used in Section 3.7. The used likelihood is the same, but instead of uniform priors, we will use a bivariate normal distribution as the joint prior distribution of the parameters \\(\\alpha\\) and \\(\\beta\\). Below is a description of the bioassay from the reading instructions (with some minor changes to help the grammar): The example is from Racine et al. (1986) (see ref in the end of the BDA3). [This] Swiss company makes classification[s] of chemicals to different toxicity categories defined by [governmental] authorities (like [the] EU). Toxicity classification is based on [the] lethal dose 50% (LD50) which [indicates] what amount of [a] chemical [that] kills 50% of the subjects. [The] [s]maller the LD50, [the] more lethal the chemical is. The original paper mentions “1983 Swiss poison Regulation” which defines [the] following categories for chemicals orally given to rats (mg/ml): Class LD50 1 &lt;5 2 5-50 3 50-500 4 500-2000 5 2000-5000 To reduce the number of rats needed in the experiments, the company started to use Bayesian methods. The paper mentions that in those days, [the] use of just 20 rats to define the classification was very little. [The] book gives the LD50 in log(g/ml). When the result from demo3_6 is transformed to mg/ml, we see that the mean LD50 is about 900 and \\(p(500 &lt; LD50 &lt; 2000) \\approx 0.99\\). Thus, the tested chemical can be classified as category 4 toxic. a) In the prior distribution for \\(\\alpha, \\beta)\\), the marginal distributions are \\(\\alpha \\sim N(0, 2^2)\\) and \\(\\beta \\sim N(10, 10^2)\\), and the correlation between them is \\(\\text{corr}(\\alpha, \\beta) = 0.6\\). Report the mean (vector of two values) and covariance (two by two matrix) of the bivariate normal distribution. The definition of a bivariate normal distribution is \\[ \\begin{pmatrix} X_1 \\\\ X_2 \\end{pmatrix} \\sim N \\begin{bmatrix} \\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\end{pmatrix} , \\begin{pmatrix} \\sigma_1^2 &amp; \\rho \\sigma_2 \\sigma_1 \\\\ \\rho \\sigma_1 \\sigma_2 &amp; \\sigma_2^2 \\\\ \\end{pmatrix} \\end{bmatrix} \\] Because \\(\\alpha\\) and \\(\\beta\\) are both normal distributions, but the mean vector is \\[ \\begin{pmatrix} \\mu_\\alpha \\\\ \\mu_\\beta \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 10 \\end{pmatrix} \\] and the covariance matrix is \\[ \\begin{aligned} \\begin{pmatrix} \\sigma_\\alpha^2 &amp; \\rho \\sigma_\\beta \\sigma_\\alpha \\\\ \\rho \\sigma_\\alpha \\sigma_\\beta &amp; \\sigma_\\beta^2 \\\\ \\end{pmatrix} &amp;= \\begin{pmatrix} 2^2 &amp; 0.6 \\times 10 \\times 2 \\\\ 0.6 \\times 2 \\times 10 &amp; 10^2 \\\\ \\end{pmatrix} \\\\ &amp;= \\begin{pmatrix} 4 &amp; 12 \\\\ 12 &amp; 100 \\\\ \\end{pmatrix} \\end{aligned} \\] get_prior_parameters &lt;- function() { mu_a &lt;- 0 sigma_a &lt;- 2 mu_b &lt;- 10 sigma_b &lt;- 10 rho &lt;- 0.6 cov_value &lt;- rho * sigma_a * sigma_b mu &lt;- c(mu_a, mu_b) cov_mat &lt;- matrix( c(sigma_a^2, cov_value, cov_value, sigma_b^2), nrow = 2, byrow = FALSE ) return(list(mu = mu, cov_mat = cov_mat)) } sample_from_prior &lt;- function(n) { params &lt;- get_prior_parameters() bvn &lt;- MASS::mvrnorm(n, mu = params$mu, Sigma = params$cov_mat) return(bvn) } plot_df &lt;- as.data.frame(sample_from_prior(1e5)) %&gt;% as_tibble() %&gt;% set_names(&quot;alpha&quot;, &quot;beta&quot;) plot_points_and_density &lt;- function(df, x, y, n_samples = 1000, point_alpha = 0.6, density_bins = 5) { df %&gt;% ggplot(aes(x = {{ x }}, y = {{ y }})) + geom_point( data = sample_n(df, size = min(c(nrow(df), n_samples))), alpha = point_alpha, color = light_blue ) + geom_density_2d(bins = density_bins, linetype = 2, color = dark_blue) } plot_points_and_density(plot_df, alpha, beta) source: PennState, Elberl College of Science: “4.2 - Bivariate Normal Distribution” b) You are given 4000 independent draws from the posterior distribution of the model. Report the mean as well as 5% and 95% quantiles separately for both \\(\\alpha\\) and \\(\\beta\\). Report also the Monte Carlo standard errors (MCSEs) for the mean and quantile estimates. Explain in words what does Monte Carlo standard error mean and how you decided the number of digits to show. bioassay_posterior &lt;- read_data( &quot;bioassay_posterior.txt&quot;, read_tsv, col_names = FALSE ) #&gt; Rows: 4000 Columns: 2 #&gt; ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────── #&gt; Delimiter: &quot;\\t&quot; #&gt; dbl (2): X1, X2 #&gt; #&gt; ℹ Use `spec()` to retrieve the full column specification for this data. #&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. colnames(bioassay_posterior) &lt;- c(&quot;alpha&quot;, &quot;beta&quot;) head(bioassay_posterior) #&gt; # A tibble: 6 × 2 #&gt; alpha beta #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -0.0205 10.0 #&gt; 2 1.22 4.50 #&gt; 3 3.05 16.2 #&gt; 4 1.32 4.92 #&gt; 5 1.36 12.9 #&gt; 6 1.09 5.94 p &lt;- plot_points_and_density( bioassay_posterior, alpha, beta, n_samples = Inf, point_alpha = 0.3 ) p MCSE accuracy of averages: \\(s_\\theta / \\sqrt(S)\\) where \\(s_\\theta\\) is the standard deviation of the draws and \\(S\\) is the number of draws. apply(bioassay_posterior, 2, function(s) { sd(s) / sqrt(length(s)) }) #&gt; alpha beta #&gt; 0.01482435 0.07560016 Calculate the means of the posterior distributions. print(&quot;Posterior means:&quot;) #&gt; [1] &quot;Posterior means:&quot; apply(bioassay_posterior, 2, mean) #&gt; alpha beta #&gt; 0.9852263 10.5964813 Calculate the MCSE of the quantiles. apply(bioassay_posterior, 2, function(x) { unlist(c( aaltobda::mcse_quantile(x, 0.05), aaltobda::mcse_quantile(x, 0.95) )) }) #&gt; alpha beta #&gt; mcse 0.02600412 0.07043125 #&gt; mcse 0.04206342 0.24121289 print(&quot;Posterior 5% and 95% quantiles:&quot;) #&gt; [1] &quot;Posterior 5% and 95% quantiles:&quot; apply(bioassay_posterior, 2, function(x) { quantile(x, c(0.05, 0.95)) }) #&gt; alpha beta #&gt; 5% -0.4675914 3.991403 #&gt; 95% 2.6102028 19.340365 Accounting for the precisions of MCSE: \\(\\mu_\\alpha = 1.0\\) with 5% and 95% CI: \\((-0.5, 2.6)\\) \\(\\mu_\\beta = 10.6\\) with 5% and 95% CI: \\((4.0, 19)\\) MCSE is the expected error from the stochastic process of Monte Carlo simulations. Here, it is used to determine the number of digits to report where we report the digits where the MCSE is 0. p + geom_vline(xintercept = 1.0, color = &quot;red&quot;) + geom_ribbon(aes(xmin = -0.5, xmax = 2.6), alpha = 0.1, fill = &quot;red&quot;) + geom_hline(yintercept = 10.6, color = &quot;orange&quot;) + geom_ribbon(aes(ymin = 4.0, ymax = 19), alpha = 0.1, fill = &quot;orange&quot;) + scale_x_continuous(expand = expansion(0)) + scale_y_continuous(expand = expansion(0)) c) Implement a function for computing the log importance ratios (log importance weights) when the importance sampling target distribution is the posterior distribution, and the proposal distribution is the prior distribution from question a). Explain in words why it’s better to compute log ratios instead of ratios. It is better to compute log ratios to avoid overflow or underflow that can occur more easily when using the ratios. As hinted in the assignment (see PDF), because we are using the prior distribution as the proposal distribution, the calculation of the importance weights is much easier. The importance weight \\(w(\\theta^s)\\) is calculated as follows: \\[ w(\\theta^s) = \\frac{q(\\theta^s|y)}{g(\\theta^s)} \\] With the proposal distribution \\(g\\) set as the prior distribution, \\(g(\\theta) = p(\\theta)\\), the equation simplifies to: \\[ \\begin{aligned} w(\\theta^s) &amp;= \\frac{q(\\theta^s|y)}{g(\\theta^s)} \\\\ &amp;= \\frac{p(\\theta^s) p(y|\\theta^s)}{p(\\theta^s)} \\\\ &amp;= p(y|\\theta^s) \\end{aligned} \\] Thus, the importance weight is just the likelihood for the model. In the question(again, see the PDF), we are asked to use aaltobda::bioassaylp() to calculate the logarithm of the likelihood. log_importance_weights &lt;- function(a, b) { bioassay_data &lt;- read_bioassay_data(show_col_types = FALSE) aaltobda::bioassaylp( alpha = a, beta = b, x = bioassay_data$x, y = bioassay_data$y, n = bioassay_data$n ) } # Test data. alpha &lt;- c(1.896, -3.6, 0.374, 0.964, -3.123, -1.581) beta &lt;- c(24.76, 20.04, 6.15, 18.65, 8.16, 17.4) test_results &lt;- round(log_importance_weights(alpha, beta), 2) stop_if_not_all_close_to( test_results, c(-8.95, -23.47, -6.02, -8.13, -16.61, -14.57) ) d) Implement a function for computing normalized importance ratios from the unnormalized log ratios in question c). In other words, exponentiate the log ratios and scale them such that they sum to one. Explain in words what is the effect of exponentiating and scaling so that sum is one. The normalized importance weights are just the exponentiated log importance weights divided by the total to sum to one. This is conducted in normalized_importance_weights(), below. normalized_importance_weights &lt;- function(alpha, beta) { weights &lt;- exp(log_importance_weights(alpha, beta)) return(weights / sum(weights)) } # Test data. test_results &lt;- round( normalized_importance_weights(alpha = alpha, beta = beta), 3 ) stop_if_not_all_close_to( test_results, c(0.045, 0.000, 0.852, 0.103, 0.000, 0.000) ) The exponentiation is to put the importance weights into a linear-scale instead of a log-scale in which they are calculated. They are normalized such that they sum to one so they can be used to scale the values of \\(\\theta\\) without changing the mean of \\(\\theta\\) for importance sampling. Also, normalizing to sum to 1 makes them comparable regardless of the values of \\(\\theta\\). e) Sample 4000 draws of \\(\\alpha\\) and \\(\\beta\\) from the prior distribution from a). Compute and plot a histogram of the 4000 normalized importance ratios. Use the functions you implemented in c) and d). prior_draws &lt;- sample_from_prior(4000) norm_importance_ratios &lt;- normalized_importance_weights( alpha = prior_draws[, 1], beta = prior_draws[, 2] ) plot_single_hist( x = norm_importance_ratios, bins = 30, alpha = 0.3, color = &quot;black&quot; ) + labs(x = &quot;normalized importance ratios&quot;) f) Using the importance ratios, compute the importance sampling effective sample size \\(S_\\text{eff}\\) and report it. From equation 10.4 in BDA3: \\[ S_\\text{eff} = \\frac{1}{\\sum^S (\\tilde{w}(\\theta^s))^2} \\] where \\(\\tilde{w}(\\theta^s)\\) are the normalized importance weights. S_eff &lt;- function(alpha, beta) { w_tilde &lt;- normalized_importance_weights(alpha, beta) s_eff &lt;- 1 / sum(w_tilde^2) return(s_eff) } # Test data. test_results &lt;- round( S_eff(alpha = alpha, beta = beta), 3 ) stop_if_not_close_to(test_results, 1.354) bioassy_s_eff &lt;- S_eff(bioassay_posterior$alpha, bioassay_posterior$beta) glue(&quot;S_eff for posterior draws of bioassy model: {round(bioassy_s_eff, 3)}&quot;) #&gt; S_eff for posterior draws of bioassy model: 3066.061 g) Explain in your own words what the importance sampling effective sample size represents. Also explain how the effective sample size is seen in the histogram of the weights that you plotted in e). The importance sampling effective sample size indicates how well the samples from the importance sampling cover the density of the target distribution \\(q(\\theta|y)\\). Ideally, the weights are uniform, resulting in a \\(S_\\text{eff}\\) near the true number of draws (i.e. 4000 in this case). If there are some samples with very high importance, then \\(S_\\text{eff}\\) gets smaller to indicate that the sampling did accurately cover the target distribution. prior_s_eff &lt;- S_eff(prior_draws[, 1], prior_draws[, 2]) glue(&quot;S_eff for prior draws of bioassy model: {round(prior_s_eff, 3)}&quot;) #&gt; S_eff for prior draws of bioassy model: 1116.397 The \\(S_\\text{eff}\\) for the prior draws is calculated above. We can see that even though there were 4000 draws, the effective sampling size is about 1116. This means that the prior samples do no accurately sample from the target distribution. We can see this in the histogram with most importance weights near 0 and a thick tail of higher values. This is also shown in the plot below of the prior samples colored by their importance ratios. There is a density of higher importance ratios in one region of the samples, likely indicating where there is a lot of posterior density for the model. p &lt;- tibble( alpha = prior_draws[, 1], beta = prior_draws[, 2], norm_imp_ratio = norm_importance_ratios ) %&gt;% ggplot(aes(x = alpha, y = beta, color = norm_imp_ratio)) + geom_point(size = 1, alpha = 0.5) + scale_color_viridis_b() + labs(x = &quot;alpha&quot;, y = &quot;beta&quot;, color = &quot;normalized\\nimportance\\nratio&quot;) p h) Implement a function for computing the posterior mean using importance sampling, and compute the mean using your 4000 draws. Explain in your own words the computation for importance sampling. Report the means for \\(\\alpha\\) and \\(\\beta\\), and also the Monte Carlo standard errors (MCSEs) for the mean estimates. Report the number of digits for the means based on the MCSEs. Hint. Use the same equation for the MCSE of \\(\\text{E}[\\theta]\\) as earlier \\(\\sqrt{\\text{Var}[\\theta]/S}\\), but now replace \\(S\\) with \\(S_\\text{eff}\\). To compute \\(\\text{Var}[\\theta]\\) with importance sampling, use the identity \\(\\text{Var}[\\theta] = \\text{E}[\\theta^2] − \\text{E}[\\theta]^2\\). The posterior mean (expectation) of \\(\\theta = (\\alpha, \\beta)\\) can be computed using importance sampling using the following equation (eq. 10.3 in BDA3): \\[ \\text{E}(h(\\theta|y)) = \\frac{\\frac{1}{S} \\sum^S h(\\theta^s) w(\\theta^s)}{\\frac{1}{S} \\sum^S w(\\theta^s)} \\\\ w(\\theta^s) = \\frac{q(\\theta^s|y)}{g(\\theta^s)} \\] where \\(w(\\theta^s)\\) is the importance weight calculated as the quotient of the target distribution \\(q\\) and the proposal distribution \\(g\\). The importance weights are calculated in log_importance_weights() in question c). In this case, \\(h(\\theta|y)\\) is the posterior distribution of \\(\\theta\\) and \\(\\text{E}(h(\\theta|y))\\) is the mean of the posterior distribution of \\(\\theta\\). \\(h(\\theta)\\) is the prior distribution. Thus, the algorithm is weight prior draws by their importance weight. posterior_mean &lt;- function(alpha, beta) { weights &lt;- exp(log_importance_weights(alpha, beta)) theta &lt;- tibble(alpha = alpha, beta = beta) # Remove values that have NA weights (lazy solution). if (any(is.na(weights))) { num_missing &lt;- sum(is.na(weights)) warning(glue(&quot;NA weights - removing {num_missing} sample(s).&quot;)) theta &lt;- theta[!is.na(weights), ] weights &lt;- weights[!is.na(weights)] } denominator &lt;- sum(weights) mu_theta_post &lt;- apply(theta, 2, function(x) { sum(x * weights) / sum(weights) }) return(mu_theta_post) } test_results &lt;- round(posterior_mean(alpha = alpha, beta = beta), 3) stop_if_not_all_close_to(test_results, c(0.503, 8.275)) Importance sampling is really just a method for weighting possible values of \\(\\theta\\) by their importance ratio. In this case, because we used the prior distribution at the proposal distribution, the importance ratio is the probability of \\(\\theta\\) under the unnormalized posterior distribution. Thus, this procedure weights possible values of \\(\\theta\\) by how likely they are given the posterior distribution. prior_a &lt;- prior_draws[, 1] prior_b &lt;- prior_draws[, 2] post_means &lt;- posterior_mean(prior_a, prior_b) post_means #&gt; alpha beta #&gt; 0.9692832 10.7213716 As stated in the hint with the question, we can calculate the MCSE of \\(\\text{E}[\\theta]\\) as \\(\\sqrt{\\text{Var}[\\theta]/S},\\), using \\(S_\\text{eff}\\) for \\(S\\), and \\(\\text{Var}[\\theta]\\) as \\(\\text{E}[\\theta^2] − \\text{E}[\\theta]^2\\) e_theta_squared &lt;- posterior_mean(prior_a^2, prior_b^2) #&gt; Warning in posterior_mean(prior_a^2, prior_b^2): NA weights - removing 70 #&gt; sample(s). var_theta &lt;- abs(e_theta_squared - (post_means^2)) s_eff &lt;- S_eff(prior_a, prior_b) mcse &lt;- sqrt(var_theta / s_eff) mcse #&gt; alpha beta #&gt; 0.01003902 0.30847776 a_post_mean &lt;- round(post_means[[1]], 2) b_post_mean &lt;- round(post_means[[2]], 0) glue(&quot;alpha post mean: {a_post_mean}, beta post mean: {b_post_mean}&quot;) #&gt; alpha post mean: 0.97, beta post mean: 11 The posterior means for \\(\\alpha\\) and \\(\\beta\\) are indicated by the red dot over-layed on the distribution of importance weights from a previous question. p + geom_point(x = a_post_mean, y = b_post_mean, color = &quot;red&quot;, shape = 4, size = 3) "],["assignment-5.html", "24 Assignment 5 24.1 Setup 24.2 Generalized linear model: Bioassay with Metropolis", " 24 Assignment 5 2021-10-01 Assignment 5 24.1 Setup knitr::opts_chunk$set(echo = TRUE, comment = &quot;#&gt;&quot;, dpi = 300) for (f in list.files(here::here(&quot;src&quot;), pattern = &quot;R$&quot;, full.names = TRUE)) { source(f) } library(glue) library(patchwork) library(tidyverse) theme_set( theme_classic() + theme( strip.background = element_blank(), panel.grid.major = element_line() ) ) bioassay &lt;- read_bioassay_data() bioassay ## # A tibble: 4 × 3 ## x n y ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.86 5 0 ## 2 -0.3 5 1 ## 3 -0.05 5 3 ## 4 0.73 5 5 24.2 Generalized linear model: Bioassay with Metropolis Metropolis algorithm: Replicate the computations for the bioassay example of section 3.7 in BDA3 using the Metropolis algorithm. The Metropolis algorithm is described in BDA3 Chapter 11.2. More information on the bioassay data can be found in Section 3.7 in BDA3, and in Chapter 3 notes. 24.2.1 Exercise 1. Implement the Metropolis algorithm as an R function for the bioassay data. Use the Gaussian prior as in Assignment 4, that is \\[ \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix} \\sim \\text{N} (\\mu_0, \\Sigma_0) \\quad \\text{where} \\quad \\mu_0 = \\begin{bmatrix} 0 \\\\ 10 \\end{bmatrix} \\quad \\text{and} \\quad \\Sigma_0 = \\begin{bmatrix} 2^2 &amp; 12 \\\\ 12 &amp; 10^2 \\end{bmatrix} \\] a) Start by implementing a function called density_ratio to compute the density ratio function, \\(r\\) in Eq. (11.1) in BDA3. \\[ r = \\frac{p(\\theta^*|y)}{p(\\theta^{t-1}|y)} \\] prob_theta_under_prior &lt;- function(a, b) { mu &lt;- c(0, 10) sigma &lt;- matrix(c(2^2, 12, 12, 10^2), nrow = 2) mvtnorm::dmvnorm(c(a, b), mean = mu, sigma = sigma) } log_posterior_prob &lt;- function(a, b, x, y, n) { log_likelihood &lt;- aaltobda::bioassaylp( alpha = a, beta = b, x = x, y = y, n = n ) prior_prob &lt;- prob_theta_under_prior(a, b) log_post &lt;- log_likelihood + log(prior_prob) return(log_post) } density_ratio &lt;- function(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n) { log_post_new &lt;- log_posterior_prob(alpha_propose, beta_propose, x, y, n) log_post_old &lt;- log_posterior_prob(alpha_previous, beta_previous, x, y, n) return(exp(log_post_new - log_post_old)) } test_1 &lt;- density_ratio( alpha_propose = 1.89, alpha_previous = 0.374, beta_propose = 24.76, beta_previous = 20.04, x = bioassay$x, y = bioassay$y, n = bioassay$n ) stop_if_not_close_to(test_1, 1.305179) test_2 &lt;- density_ratio( alpha_propose = 0.374, alpha_previous = 1.89, beta_propose = 20.04, beta_previous = 24.76, x = bioassay$x, y = bioassay$y, n = bioassay$n ) stop_if_not_close_to(test_2, 0.7661784) b) Now implement a function called Metropolis_bioassay() which implements the Metropolis algorithm using the density_ratio(). # Helper function to turn the chains into a data frame. chain_to_df &lt;- function(chain, names) { purrr::map_dfr(chain, ~ as.data.frame(t(.x))) %&gt;% tibble::as_tibble() %&gt;% purrr::set_names(names) } propose_theta &lt;- function(theta_old, a_sigma = 1, b_sigma = 5) { c( rnorm(1, mean = theta_old[[1]], sd = a_sigma), rnorm(1, mean = theta_old[[2]], sd = b_sigma) ) } Metropolis_bioassay &lt;- function(theta_t0, x, y, n, alpha_jump = 1, beta_jump = 5, N = 1000, quiet = FALSE) { theta_t &lt;- unlist(theta_t0) chain &lt;- as.list(rep(NA_real_, n = N + 1)) chain[[1]] &lt;- theta_t n_accepts &lt;- 0 for (t in seq(2, N + 1)) { theta_star &lt;- propose_theta( theta_t, a_sigma = alpha_jump, b_sigma = beta_jump ) density_ratio &lt;- density_ratio( alpha_propose = theta_star[[1]], alpha_previous = theta_t[[1]], beta_propose = theta_star[[2]], beta_previous = theta_t[[2]], x = x, y = y, n = n ) accept &lt;- runif(1) &lt; min(c(1, density_ratio)) if (accept) { theta_t &lt;- theta_star n_accepts &lt;- n_accepts + 1 } chain[[t]] &lt;- theta_t } if (!quiet) { frac_accepts &lt;- n_accepts / N message(glue::glue(&quot;fraction of accepted jumps: {frac_accepts}&quot;)) } return(chain_to_df(chain, names = c(&quot;alpha&quot;, &quot;beta&quot;))) } # Plot the trace of the chains. plot_trace &lt;- function(chains_df, alpha = 0.8) { chains_df %&gt;% group_by(chain) %&gt;% mutate(step = row_number()) %&gt;% ungroup() %&gt;% pivot_longer(-c(chain, step)) %&gt;% ggplot(aes(x = step, y = value)) + facet_grid(rows = vars(name), scales = &quot;free_y&quot;) + geom_line(aes(color = chain), alpha = alpha) + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set2&quot;) + scale_x_continuous(expand = expansion(c(0, 0))) } # Plot the chains in 2 dimensions. plot_chains &lt;- function(chains_df, alpha = 0.8) { chains_df %&gt;% ggplot(aes(x = alpha, y = beta)) + geom_path(aes(color = chain), alpha = alpha) + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set2&quot;) } # Plot the posterior density of `x`. Used by `plot_posterior()`. plot_posterior_density &lt;- function(chains_df, x, color) { chains_df %&gt;% ggplot(aes(x = {{ x }}, color = {{ color }}, fill = {{ color }})) + geom_density(size = 0.7, alpha = 0.2) + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set2&quot;) + scale_fill_brewer(type = &quot;qual&quot;, palette = &quot;Set2&quot;) + theme(legend.position = &quot;none&quot;, axis.title = element_blank()) } # Plot the posterior distributions after removing warm-up steps. plot_posterior &lt;- function(chains_df, alpha = 0.8, size = 0.6, warm_up = 0.5) { chains_without_warmup &lt;- chains_df %&gt;% group_by(chain) %&gt;% mutate(step = row_number()) %&gt;% ungroup() %&gt;% filter(step &gt; (max(step) * !!warm_up)) scatter &lt;- chains_without_warmup %&gt;% ggplot(aes(x = alpha, y = beta)) + geom_density_2d(alpha = 0.7) + geom_point(aes(color = chain), size = size, alpha = alpha) + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set2&quot;) + theme(legend.position = &quot;left&quot;) alpha_dist &lt;- plot_posterior_density(chains_without_warmup, alpha, chain) + scale_y_continuous(expand = expansion(c(0, 0))) beta_dist &lt;- plot_posterior_density(chains_without_warmup, beta, chain) + scale_y_continuous(expand = expansion(c(0, 0))) + coord_flip() patch_design &lt;- &quot; AAAA# BBBBC BBBBC BBBBC BBBBC &quot; patch &lt;- alpha_dist + scatter + beta_dist + plot_layout(design = patch_design) return(patch) } Run the Metropolis algorithm with the default values from the question. I chose a grid of starting points \\((\\pm 2.5, \\pm 2.5)\\) and ran four chains for 1,000 iterations. starting_points &lt;- list( c(-2.5, -2.5), c(2.5, -2.5), c(-2.5, 2.5), c(2.5, 2.5) ) set.seed(0) metropolis_chains &lt;- purrr::map_dfr( seq(1, 4), ~ Metropolis_bioassay( starting_points[[.x]], x = bioassay$x, y = bioassay$y, n = bioassay$n ) %&gt;% add_column(chain = as.character(.x)) ) #&gt; fraction of accepted jumps: 0.402 #&gt; fraction of accepted jumps: 0.428 #&gt; fraction of accepted jumps: 0.445 #&gt; fraction of accepted jumps: 0.456 plot_trace(metropolis_chains) plot_chains(metropolis_chains, alpha = 0.5) plot_posterior(metropolis_chains) The chains mixed well, but I tried reducing the proposal distributions standard deviations by an order of magnitude. set.seed(0) metropolis_chains &lt;- purrr::map_dfr( seq(1, 4), ~ Metropolis_bioassay( starting_points[[.x]], x = bioassay$x, y = bioassay$y, n = bioassay$n, alpha_jump = 0.1, beta_jump = 1 ) %&gt;% add_column(chain = as.character(.x)) ) #&gt; fraction of accepted jumps: 0.847 #&gt; fraction of accepted jumps: 0.866 #&gt; fraction of accepted jumps: 0.889 #&gt; fraction of accepted jumps: 0.858 plot_trace(metropolis_chains) plot_chains(metropolis_chains, alpha = 0.5) plot_posterior(metropolis_chains) The chains did not mix well with these smaller proposal distribution standard deviations. Below, I try slightly larger values for the jump sizes and also run 2,000 total iterations (1,000 warm-up steps). set.seed(0) metropolis_chains &lt;- purrr::map_dfr( seq(1, 4), ~ Metropolis_bioassay( starting_points[[.x]], x = bioassay$x, y = bioassay$y, n = bioassay$n, alpha_jump = 1, beta_jump = 3, N = 2000 ) %&gt;% add_column(chain = as.character(.x)) ) #&gt; fraction of accepted jumps: 0.4955 #&gt; fraction of accepted jumps: 0.523 #&gt; fraction of accepted jumps: 0.519 #&gt; fraction of accepted jumps: 0.5285 plot_trace(metropolis_chains) plot_chains(metropolis_chains, alpha = 0.5) plot_posterior(metropolis_chains) 24.2.2 Exercise 2. a) Describe in your own words in one paragraph the basic idea of the Metropolis algorithm (see BDA3 Section 11.2, and lecture video 5.1). The Metropolis algorithm is a biased random walk through the space of the model parameters. The bias is calculated by the ratio of the unnormalized probability of a new set of values to that of the current values. If the new location has a higher probability, the random walk will always go to the proposed location, otherwise, the new position is accepted with a probability equal to the ratio. This way, the random walk will always tend towards space with higher probability, and then once in a region with relatively high probabilty, will still explore the space at a frequency proportional to the probability density of the region. b) The proposal distribution (related to jumping rule) you used. Describe briefly in words how you chose the final proposal distribution you used for the reported results. I chose the final distribution because it produced, visually, good mixing of the chains and exploration of the parameter space. c) The initial points of your Metropolis chains (or the explicit mechanism for generating them). I just chose a grid to make sure there was enough variability in the starting locations. This strategy helped me to understand the effect (if any) of the starting location of the chain on its exploration of the posterior. d) Report the chain length or the number of iterations for each chain. Run the simulations long enough for approximate convergence (see BDA Section 11.4, and lecture 5.2). I ran the chain for 2,000 steps, 1,000 of which were warm-ups. e) Report the warm-up length (see BDA Section 11.4, and lecture 5.2). The warm-up length was 1,000 steps. f) The number of Metropolis chains used. It is important that multiple Metropolis chains are run for evaluating convergence (see BDA Section 11.4, and lecture 5.2). I used 4 chains to make sure that the starting location was not influential in the final location of the chains. g) Plot all chains for \\(\\alpha\\) in a single line-plot. Overlapping the chains in this way helps in visually assessing whether chains have converged or not. (I have already plotted the traces in Exercise 1.) h) Do the same for \\(\\beta\\). (I have already plotted the traces in Exercise 1.) 24.2.3 Exercise 3 In complex scenarios, visual assessment is not sufficient and \\(\\widehat{R}\\) is a more robust indicator of convergence of the Markov chains. Use \\(\\widehat{R}\\) for convergence analysis. You can either use Eq. (11.4) in BDA3 or the more recent version described here. You should specify which \\(\\widehat{R}\\) you used. In R the best choice is to use function Rhat() from [the] package ‘rstan’ Remember to remove the warm-up samples before computing \\(\\widehat{R}\\). Report the \\(\\widehat{R}\\) values for \\(\\alpha\\) and \\(\\beta\\) separately. Report the values for the proposal distribution you finally used. long_chains_df_to_matrix &lt;- function(chains_df, mdl_param, drop_cols = c(), warm_up = -1) { chains_df %&gt;% select(-c(tidyselect::any_of(drop_cols))) %&gt;% group_by(chain) %&gt;% mutate(idx__ = row_number()) %&gt;% ungroup() %&gt;% filter(idx__ &gt; warm_up) %&gt;% pivot_wider(idx__, names_from = chain, values_from = {{ mdl_param }}) %&gt;% select(-idx__) %&gt;% as.matrix() } alpha_rhat &lt;- rstan::Rhat( long_chains_df_to_matrix( metropolis_chains, alpha, drop_cols = &quot;beta&quot;, warm_up = 1000 ) ) print(glue(&quot;alpha Rhat: {round(alpha_rhat, 3)}&quot;)) #&gt; alpha Rhat: 1.027 beta_rhat &lt;- rstan::Rhat( long_chains_df_to_matrix( metropolis_chains, beta, drop_cols = &quot;alpha&quot;, warm_up = 1000 ) ) print(glue(&quot;beta Rhat: {round(beta_rhat, 3)}&quot;)) #&gt; beta Rhat: 1.056 a) Describe briefly in your own words the basic idea of \\(\\widehat{R}\\) and how to to interpret the obtained \\(\\widehat{R}\\) values. \\(\\widehat{R}\\) is a metric for how well the chains have converged by comparing the variance within and between chains to the within-chain variance alone. If the value is 1, then the between- and within-chain variance are about equal meaning that the chains have both converged and mixed. If it is above 1, this is likely because the between-chain variance is greater than the within-chain variance indicating that the chains have yet to mix. The value itself represents the degree to which the estimate of the parameter posterior would change if the chains were able to full mix. b) Tell whether you obtained good \\(\\widehat{R}\\) with first try, or whether you needed to run more iterations or how did you modify the proposal distribution. The \\(\\widehat{R}\\) for \\(\\alpha\\) looks fine, but the value for \\(\\beta\\) is a bit large. I would just run the chains for a bit longer, perhaps 3,000 steps, or I could continue tweaking the standard deviations of the jump/proposal distribution. 24.2.4 Exercise 4 Plot the draws for \\(\\alpha\\) and \\(\\beta\\) (scatter plot) and include this plot in your report. You can compare the results to Figure 3.3b in BDA3 to verify that your code gives sensible results Notice though that the results in Figure 3.3b are generated from posterior with a uniform prior, so even when if your algorithm works perfectly, the results will look slightly different (although fairly similar). Below is the same plot that was created in Exercise 2. plot_posterior(metropolis_chains) sessionInfo() #&gt; R version 4.1.2 (2021-11-01) #&gt; Platform: x86_64-apple-darwin17.0 (64-bit) #&gt; Running under: macOS Big Sur 10.16 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices datasets utils methods base #&gt; #&gt; other attached packages: #&gt; [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.7 purrr_0.3.4 #&gt; [5] readr_2.0.1 tidyr_1.1.3 tibble_3.1.3 ggplot2_3.3.5 #&gt; [9] tidyverse_1.3.1 patchwork_1.1.1 glue_1.4.2 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] matrixStats_0.61.0 fs_1.5.0 lubridate_1.7.10 #&gt; [4] bit64_4.0.5 RColorBrewer_1.1-2 httr_1.4.2 #&gt; [7] rprojroot_2.0.2 rstan_2.21.2 tools_4.1.2 #&gt; [10] backports_1.2.1 bslib_0.2.5.1 utf8_1.2.2 #&gt; [13] R6_2.5.0 DBI_1.1.1 colorspace_2.0-2 #&gt; [16] withr_2.4.2 gridExtra_2.3 tidyselect_1.1.1 #&gt; [19] prettyunits_1.1.1 processx_3.5.2 curl_4.3.2 #&gt; [22] bit_4.0.4 compiler_4.1.2 cli_3.0.1 #&gt; [25] rvest_1.0.1 xml2_1.3.2 isoband_0.2.5 #&gt; [28] labeling_0.4.2 bookdown_0.24 sass_0.4.0 #&gt; [31] scales_1.1.1 checkmate_2.0.0 aaltobda_0.3.1 #&gt; [34] mvtnorm_1.1-2 callr_3.7.0 StanHeaders_2.21.0-7 #&gt; [37] digest_0.6.27 rmarkdown_2.10 pkgconfig_2.0.3 #&gt; [40] htmltools_0.5.1.1 dbplyr_2.1.1 highr_0.9 #&gt; [43] rlang_0.4.11 readxl_1.3.1 rstudioapi_0.13 #&gt; [46] jquerylib_0.1.4 farver_2.1.0 generics_0.1.0 #&gt; [49] jsonlite_1.7.2 vroom_1.5.4 inline_0.3.19 #&gt; [52] magrittr_2.0.1 loo_2.4.1 Rcpp_1.0.7 #&gt; [55] munsell_0.5.0 fansi_0.5.0 lifecycle_1.0.0 #&gt; [58] stringi_1.7.3 yaml_2.2.1 MASS_7.3-54 #&gt; [61] pkgbuild_1.2.0 grid_4.1.2 parallel_4.1.2 #&gt; [64] crayon_1.4.1 haven_2.4.3 hms_1.1.0 #&gt; [67] knitr_1.33 ps_1.6.0 pillar_1.6.2 #&gt; [70] codetools_0.2-18 clisymbols_1.2.0 stats4_4.1.2 #&gt; [73] reprex_2.0.1 evaluate_0.14 V8_3.4.2 #&gt; [76] RcppParallel_5.1.4 renv_0.14.0 modelr_0.1.8 #&gt; [79] vctrs_0.3.8 tzdb_0.1.2 cellranger_1.1.0 #&gt; [82] gtable_0.3.0 assertthat_0.2.1 xfun_0.25 #&gt; [85] broom_0.7.9 ellipsis_0.3.2 here_1.0.1 "],["assignment-6.html", "25 Assignment 6 25.1 Setup 25.2 Exercise 1. Generalized linear model: Bioassay with Stan", " 25 Assignment 6 2021-10-07 Assignment 6 25.1 Setup knitr::opts_chunk$set(echo = TRUE, comment = &quot;#&gt;&quot;, dpi = 300) for (f in list.files(here::here(&quot;src&quot;), pattern = &quot;R$&quot;, full.names = TRUE)) { source(f) } library(rstan) library(tidybayes) library(bayesplot) library(tidyverse) theme_set( theme_classic() + theme( plot.title = element_text(hjust = 0.5), panel.grid.major = element_line() ) ) rstan_options(auto_write = TRUE) 25.2 Exercise 1. Generalized linear model: Bioassay with Stan Replicate the computations for the bioassay example of section 3.7 (BDA3) using Stan. The model is located in “models/assignment06-bioassay.stan. I have copied it below: data { int&lt;lower=0&gt; N; // number of data points vector[N] x; // dose int&lt;lower=0&gt; n[N]; // number of animals int&lt;lower=0&gt; y[N]; // number of deaths vector[2] mu; // prior on mean of theta matrix&lt;lower=0&gt;[2, 2] sigma; // prior on covariance matrix of theta } parameters { vector[2] mdl_params; } transformed parameters { vector[N] theta; theta = mdl_params[1] + mdl_params[2] * x; } model { mdl_params ~ multi_normal(mu, sigma); y ~ binomial_logit(n, theta); } 25.2.1 1. Write down the model for the bioassay data in Stan syntax. Use the Gaussian prior as in Assignment 4 and 5, that is: \\[ \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix} \\sim \\text{N} (\\mu_0, \\Sigma_0) \\quad \\text{where} \\quad \\mu_0 = \\begin{bmatrix} 0 \\\\ 10 \\end{bmatrix} \\quad \\text{and} \\quad \\Sigma_0 = \\begin{bmatrix} 2^2 &amp; 12 \\\\ 12 &amp; 10^2 \\end{bmatrix} \\] Hint! You will need Stan functions multi_normal and binomial_logit for implementing the prior and observation model, respectively. In Stan code, it is easiest to declare a variable (say theta) which is a two-element vector so that the first value denotes \\(\\alpha\\) and latter one \\(\\beta\\). This is because the multi_normal function that you need for implementing the prior requires a vector as an input. bioassay &lt;- read_bioassay_data() #&gt; Rows: 4 Columns: 1 #&gt; ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────── #&gt; Delimiter: &quot;\\t&quot; #&gt; chr (1): x n y #&gt; #&gt; ℹ Use `spec()` to retrieve the full column specification for this data. #&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. bioassay_mdl_posterior &lt;- stan( file = here::here(&quot;models&quot;, &quot;assignment06-bioassay.stan&quot;), data = list( N = nrow(bioassay), x = bioassay$x, n = bioassay$n, y = bioassay$y, mu = c(0, 10), sigma = matrix(c(2^2, 12, 12, 10^2), nrow = 2) ) ) #&gt; #&gt; SAMPLING FOR MODEL &#39;assignment06-bioassay&#39; NOW (CHAIN 1). #&gt; Chain 1: #&gt; Chain 1: Gradient evaluation took 5.5e-05 seconds #&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.55 seconds. #&gt; Chain 1: Adjust your expectations accordingly! #&gt; Chain 1: #&gt; Chain 1: #&gt; Chain 1: Iteration: 1 / 2000 [ 0%] (Warmup) #&gt; Chain 1: Iteration: 200 / 2000 [ 10%] (Warmup) #&gt; Chain 1: Iteration: 400 / 2000 [ 20%] (Warmup) #&gt; Chain 1: Iteration: 600 / 2000 [ 30%] (Warmup) #&gt; Chain 1: Iteration: 800 / 2000 [ 40%] (Warmup) #&gt; Chain 1: Iteration: 1000 / 2000 [ 50%] (Warmup) #&gt; Chain 1: Iteration: 1001 / 2000 [ 50%] (Sampling) #&gt; Chain 1: Iteration: 1200 / 2000 [ 60%] (Sampling) #&gt; Chain 1: Iteration: 1400 / 2000 [ 70%] (Sampling) #&gt; Chain 1: Iteration: 1600 / 2000 [ 80%] (Sampling) #&gt; Chain 1: Iteration: 1800 / 2000 [ 90%] (Sampling) #&gt; Chain 1: Iteration: 2000 / 2000 [100%] (Sampling) #&gt; Chain 1: #&gt; Chain 1: Elapsed Time: 0.03982 seconds (Warm-up) #&gt; Chain 1: 0.033487 seconds (Sampling) #&gt; Chain 1: 0.073307 seconds (Total) #&gt; Chain 1: #&gt; #&gt; SAMPLING FOR MODEL &#39;assignment06-bioassay&#39; NOW (CHAIN 2). #&gt; Chain 2: #&gt; Chain 2: Gradient evaluation took 1.3e-05 seconds #&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds. #&gt; Chain 2: Adjust your expectations accordingly! #&gt; Chain 2: #&gt; Chain 2: #&gt; Chain 2: Iteration: 1 / 2000 [ 0%] (Warmup) #&gt; Chain 2: Iteration: 200 / 2000 [ 10%] (Warmup) #&gt; Chain 2: Iteration: 400 / 2000 [ 20%] (Warmup) #&gt; Chain 2: Iteration: 600 / 2000 [ 30%] (Warmup) #&gt; Chain 2: Iteration: 800 / 2000 [ 40%] (Warmup) #&gt; Chain 2: Iteration: 1000 / 2000 [ 50%] (Warmup) #&gt; Chain 2: Iteration: 1001 / 2000 [ 50%] (Sampling) #&gt; Chain 2: Iteration: 1200 / 2000 [ 60%] (Sampling) #&gt; Chain 2: Iteration: 1400 / 2000 [ 70%] (Sampling) #&gt; Chain 2: Iteration: 1600 / 2000 [ 80%] (Sampling) #&gt; Chain 2: Iteration: 1800 / 2000 [ 90%] (Sampling) #&gt; Chain 2: Iteration: 2000 / 2000 [100%] (Sampling) #&gt; Chain 2: #&gt; Chain 2: Elapsed Time: 0.036828 seconds (Warm-up) #&gt; Chain 2: 0.034224 seconds (Sampling) #&gt; Chain 2: 0.071052 seconds (Total) #&gt; Chain 2: #&gt; #&gt; SAMPLING FOR MODEL &#39;assignment06-bioassay&#39; NOW (CHAIN 3). #&gt; Chain 3: #&gt; Chain 3: Gradient evaluation took 1.3e-05 seconds #&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds. #&gt; Chain 3: Adjust your expectations accordingly! #&gt; Chain 3: #&gt; Chain 3: #&gt; Chain 3: Iteration: 1 / 2000 [ 0%] (Warmup) #&gt; Chain 3: Iteration: 200 / 2000 [ 10%] (Warmup) #&gt; Chain 3: Iteration: 400 / 2000 [ 20%] (Warmup) #&gt; Chain 3: Iteration: 600 / 2000 [ 30%] (Warmup) #&gt; Chain 3: Iteration: 800 / 2000 [ 40%] (Warmup) #&gt; Chain 3: Iteration: 1000 / 2000 [ 50%] (Warmup) #&gt; Chain 3: Iteration: 1001 / 2000 [ 50%] (Sampling) #&gt; Chain 3: Iteration: 1200 / 2000 [ 60%] (Sampling) #&gt; Chain 3: Iteration: 1400 / 2000 [ 70%] (Sampling) #&gt; Chain 3: Iteration: 1600 / 2000 [ 80%] (Sampling) #&gt; Chain 3: Iteration: 1800 / 2000 [ 90%] (Sampling) #&gt; Chain 3: Iteration: 2000 / 2000 [100%] (Sampling) #&gt; Chain 3: #&gt; Chain 3: Elapsed Time: 0.034739 seconds (Warm-up) #&gt; Chain 3: 0.027769 seconds (Sampling) #&gt; Chain 3: 0.062508 seconds (Total) #&gt; Chain 3: #&gt; #&gt; SAMPLING FOR MODEL &#39;assignment06-bioassay&#39; NOW (CHAIN 4). #&gt; Chain 4: #&gt; Chain 4: Gradient evaluation took 1.2e-05 seconds #&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds. #&gt; Chain 4: Adjust your expectations accordingly! #&gt; Chain 4: #&gt; Chain 4: #&gt; Chain 4: Iteration: 1 / 2000 [ 0%] (Warmup) #&gt; Chain 4: Iteration: 200 / 2000 [ 10%] (Warmup) #&gt; Chain 4: Iteration: 400 / 2000 [ 20%] (Warmup) #&gt; Chain 4: Iteration: 600 / 2000 [ 30%] (Warmup) #&gt; Chain 4: Iteration: 800 / 2000 [ 40%] (Warmup) #&gt; Chain 4: Iteration: 1000 / 2000 [ 50%] (Warmup) #&gt; Chain 4: Iteration: 1001 / 2000 [ 50%] (Sampling) #&gt; Chain 4: Iteration: 1200 / 2000 [ 60%] (Sampling) #&gt; Chain 4: Iteration: 1400 / 2000 [ 70%] (Sampling) #&gt; Chain 4: Iteration: 1600 / 2000 [ 80%] (Sampling) #&gt; Chain 4: Iteration: 1800 / 2000 [ 90%] (Sampling) #&gt; Chain 4: Iteration: 2000 / 2000 [100%] (Sampling) #&gt; Chain 4: #&gt; Chain 4: Elapsed Time: 0.033204 seconds (Warm-up) #&gt; Chain 4: 0.028264 seconds (Sampling) #&gt; Chain 4: 0.061468 seconds (Total) #&gt; Chain 4: 25.2.2 2. Use \\(\\widehat{R}\\) for convergence analysis. Report the \\(\\widehat{R}\\) values both for \\(\\alpha\\) and \\(\\beta\\) and discuss the convergence of the chains. Briefly explain in your own words how to interpret the obtained \\(\\widehat{R}\\) values. Bellow is a table summarizing the results of sampling from the model’s posterior. The \\(\\widehat{R}\\) is stated in the last column of the table. As the values are all around 1.0, this suggests that the chains mixed and converged. bioassay_mdl_posterior #&gt; Inference for Stan model: assignment06-bioassay. #&gt; 4 chains, each with iter=2000; warmup=1000; thin=1; #&gt; post-warmup draws per chain=1000, total post-warmup draws=4000. #&gt; #&gt; mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat #&gt; mdl_params[1] 0.96 0.02 0.89 -0.65 0.35 0.91 1.54 2.77 1353 1 #&gt; mdl_params[2] 10.64 0.13 4.64 3.48 7.13 10.03 13.65 20.83 1331 1 #&gt; theta[1] -8.19 0.09 3.52 -16.08 -10.35 -7.70 -5.50 -2.77 1509 1 #&gt; theta[2] -2.23 0.02 1.10 -4.67 -2.92 -2.11 -1.44 -0.40 2476 1 #&gt; theta[3] 0.43 0.02 0.77 -1.01 -0.10 0.41 0.92 2.01 1596 1 #&gt; theta[4] 8.73 0.11 4.00 2.34 5.74 8.19 11.37 17.39 1236 1 #&gt; lp__ -7.14 0.03 1.00 -9.88 -7.54 -6.83 -6.42 -6.14 1593 1 #&gt; #&gt; Samples were drawn using NUTS(diag_e) at Tue Feb 8 07:06:40 2022. #&gt; For each parameter, n_eff is a crude measure of effective sample size, #&gt; and Rhat is the potential scale reduction factor on split chains (at #&gt; convergence, Rhat=1). \\(\\widehat{R}\\) is a metric for how well the chains mixed and converged using the within- and between-chain variance. If the value is larger than 1, it indicates that the chains have likely not mixed, either due to model misspecification or not running the chains for long enough. It can also be thought of a scaling factor indicating how much greater the estimated variance in the posterior is compared to the real variance caused by the chains not converging. 25.2.3 3. Plot the draws for \\(\\alpha\\) and \\(\\beta\\) (scatter plot) and include this plot in your report post_df &lt;- bioassay_mdl_posterior %&gt;% spread_draws(mdl_params[param]) %&gt;% mutate(param = ifelse(param == 1, &quot;alpha&quot;, &quot;beta&quot;)) post_df %&gt;% ggplot(aes(y = fct_rev(param), x = mdl_params)) + stat_halfeye(.width = c(0.50, 0.89)) + labs(x = &quot;posterior value&quot;, y = &quot;model parameter&quot;) post_point_est &lt;- as_tibble( bayestestR::point_estimate(bioassay_mdl_posterior) ) %&gt;% select(param = Parameter, mean = Mean) %&gt;% filter(str_detect(param, &quot;mdl_params&quot;)) %&gt;% mutate(param = c(&quot;alpha&quot;, &quot;beta&quot;)) post_hdi &lt;- as_tibble(bayestestR::hdi(bioassay_mdl_posterior, ci = 0.89)) %&gt;% janitor::clean_names() %&gt;% select(param = parameter, ci, ci_low, ci_high) %&gt;% filter(str_detect(param, &quot;mdl_params&quot;)) %&gt;% mutate(param = c(&quot;alpha&quot;, &quot;beta&quot;)) parameter_post_description &lt;- inner_join(post_point_est, post_hdi, by = &quot;param&quot;) ALPHA_COL &lt;- &quot;#F90039&quot; BETA_COL &lt;- &quot;#4E477F&quot; post_df %&gt;% pivot_wider(names_from = param, values_from = mdl_params) %&gt;% ggplot(aes(x = alpha, y = beta)) + geom_density_2d(alpha = 0.5) + geom_point(size = 0.4, alpha = 0.5) + geom_rect( aes(xmin = ci_low, xmax = ci_high), data = parameter_post_description %&gt;% slice(1), ymin = -Inf, ymax = Inf, alpha = 0.1, fill = ALPHA_COL, inherit.aes = FALSE ) + geom_rect( aes(ymin = ci_low, ymax = ci_high), data = parameter_post_description %&gt;% slice(2), xmin = -Inf, xmax = Inf, alpha = 0.1, fill = BETA_COL, inherit.aes = FALSE ) + geom_vline( xintercept = parameter_post_description$mean[[1]], color = ALPHA_COL, linetype = 2 ) + geom_hline( yintercept = parameter_post_description$mean[[2]], color = BETA_COL, linetype = 2 ) + labs(x = &quot;alpha&quot;, y = &quot;beta&quot;, title = &quot;Bioassy model posterior&quot;) 25.2.4 4. To develop the course and provide feedback to Stan developers, we collect information on which Stan setup you used and whether you had any problems in setting it up or using it. Please report, Operating system (Linux, Mac, Windows) or jupyter.cs.aalto.fi? macOS Big Sur (v11.6) Programming environment used: R or Python? R Interface used: RStan, CmdStanR, PyStan, or CmdStanPy? RStan Did you have installation or compilation problems? No troubles. Did you try first installing locally, but switched to jupyter.cs.aalto.fi? No. In addition of these you can write what other things you found out difficult (or even frustrating) when making this assignment with Stan. No frustrations this time, but I have had some in the past, but the problem was with how I had installed R and not specific to Stan. sessionInfo() #&gt; R version 4.1.2 (2021-11-01) #&gt; Platform: x86_64-apple-darwin17.0 (64-bit) #&gt; Running under: macOS Big Sur 10.16 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices datasets utils methods base #&gt; #&gt; other attached packages: #&gt; [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.7 #&gt; [4] purrr_0.3.4 readr_2.0.1 tidyr_1.1.3 #&gt; [7] tibble_3.1.3 tidyverse_1.3.1 bayesplot_1.8.1 #&gt; [10] tidybayes_3.0.1 rstan_2.21.2 ggplot2_3.3.5 #&gt; [13] StanHeaders_2.21.0-7 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] matrixStats_0.61.0 fs_1.5.0 bit64_4.0.5 #&gt; [4] lubridate_1.7.10 insight_0.14.4 httr_1.4.2 #&gt; [7] rprojroot_2.0.2 tensorA_0.36.2 tools_4.1.2 #&gt; [10] backports_1.2.1 bslib_0.2.5.1 utf8_1.2.2 #&gt; [13] R6_2.5.0 DBI_1.1.1 colorspace_2.0-2 #&gt; [16] ggdist_3.0.0 withr_2.4.2 tidyselect_1.1.1 #&gt; [19] gridExtra_2.3 prettyunits_1.1.1 processx_3.5.2 #&gt; [22] bit_4.0.4 curl_4.3.2 compiler_4.1.2 #&gt; [25] rvest_1.0.1 cli_3.0.1 arrayhelpers_1.1-0 #&gt; [28] xml2_1.3.2 isoband_0.2.5 bayestestR_0.11.0 #&gt; [31] labeling_0.4.2 bookdown_0.24 posterior_1.1.0 #&gt; [34] sass_0.4.0 scales_1.1.1 checkmate_2.0.0 #&gt; [37] ggridges_0.5.3 callr_3.7.0 digest_0.6.27 #&gt; [40] rmarkdown_2.10 pkgconfig_2.0.3 htmltools_0.5.1.1 #&gt; [43] highr_0.9 dbplyr_2.1.1 rlang_0.4.11 #&gt; [46] readxl_1.3.1 rstudioapi_0.13 jquerylib_0.1.4 #&gt; [49] farver_2.1.0 generics_0.1.0 svUnit_1.0.6 #&gt; [52] jsonlite_1.7.2 vroom_1.5.4 distributional_0.2.2 #&gt; [55] inline_0.3.19 magrittr_2.0.1 loo_2.4.1 #&gt; [58] Rcpp_1.0.7 munsell_0.5.0 fansi_0.5.0 #&gt; [61] abind_1.4-5 lifecycle_1.0.0 stringi_1.7.3 #&gt; [64] yaml_2.2.1 snakecase_0.11.0 MASS_7.3-54 #&gt; [67] pkgbuild_1.2.0 plyr_1.8.6 grid_4.1.2 #&gt; [70] parallel_4.1.2 crayon_1.4.1 lattice_0.20-45 #&gt; [73] haven_2.4.3 hms_1.1.0 knitr_1.33 #&gt; [76] ps_1.6.0 pillar_1.6.2 codetools_0.2-18 #&gt; [79] clisymbols_1.2.0 stats4_4.1.2 reprex_2.0.1 #&gt; [82] glue_1.4.2 evaluate_0.14 V8_3.4.2 #&gt; [85] renv_0.14.0 RcppParallel_5.1.4 modelr_0.1.8 #&gt; [88] vctrs_0.3.8 tzdb_0.1.2 cellranger_1.1.0 #&gt; [91] gtable_0.3.0 datawizard_0.2.1 assertthat_0.2.1 #&gt; [94] xfun_0.25 janitor_2.1.0 broom_0.7.9 #&gt; [97] coda_0.19-4 ellipsis_0.3.2 here_1.0.1 "],["assignment-7.html", "26 Assignment 7 26.1 Setup 26.2 1. Linear model: drowning data with Stan 26.3 2. Hierarchical model: factory data with Stan", " 26 Assignment 7 2021-10-18 Assignment 7 26.1 Setup knitr::opts_chunk$set(echo = TRUE, comment = &quot;#&gt;&quot;, dpi = 300) for (f in list.files(here::here(&quot;src&quot;), pattern = &quot;R$&quot;, full.names = TRUE)) { source(f) } library(rstan) library(tidybayes) library(magrittr) library(tidyverse) theme_set(theme_classic() + theme(strip.background = element_blank())) options(mc.cores = 2) rstan_options(auto_write = TRUE) drowning &lt;- aaltobda::drowning factory &lt;- aaltobda::factory 26.2 1. Linear model: drowning data with Stan The provided data drowning in the ‘aaltobda’ package contains the number of people who died from drowning each year in Finland 1980–2019. A statistician is going to fit a linear model with Gaussian residual model to these data using time as the predictor and number of drownings as the target variable. She has two objective questions: What is the trend of the number of people drowning per year? (We would plot the histogram of the slope of the linear model.) What is the prediction for the year 2020? (We would plot the histogram of the posterior predictive distribution for the number of people drowning at \\(\\tilde{x} = 2020\\).) Corresponding Stan code is provided in Listing 1. However, it is not entirely correct for the problem. First, there are three mistakes. Second, there are no priors defined for the parameters. In Stan, this corresponds to using uniform priors. a) Find the three mistakes in the code and fix them. Report the original mistakes and your fixes clearly in your report. Include the full corrected Stan code in your report. Declaration of sigma on line 10 should be real&lt;lower=0&gt;. Missing semicolon at the end of line 16. On line 19, the prediction on new data does not use the new data in xpred. This has been changed to real ypred = normal_rng(alpha + beta*xpred, sigma);. Below is a copy of the final model. The full Stan file is at models/assignment07-drownings.stan. data { int&lt;lower=0&gt; N; // number of data points vector[N] x; // observation year vector[N] y; // observation number of drowned real xpred; // prediction year } parameters { real alpha; real beta; real&lt;lower=0&gt; sigma; // fix: &#39;upper&#39; should be &#39;lower&#39; } transformed parameters { vector[N] mu = alpha + beta*x; } model { y ~ normal(mu, sigma); // fix: missing semicolor } generated quantities { real ypred = normal_rng(alpha + beta*xpred, sigma); // fix: use `xpred` } b) Determine a suitable weakly-informative prior \\(\\text{Normal}(0,\\sigma_\\beta)\\) for the slope \\(\\beta\\). It is very unlikely that the mean number of drownings changes more than 50 % in one year. The approximate historical mean yearly number of drownings is 138. Hence, set \\(\\sigma_\\beta\\) so that the following holds for the prior probability for \\(\\beta\\): \\(Pr(−69 &lt; \\beta &lt; 69) = 0.99\\). Determine suitable value for \\(\\sigma_\\beta\\) and report the approximate numerical value for it. x &lt;- rnorm(1e5, 0, 26) print(mean(-69 &lt; x &amp; x &lt; 69)) #&gt; [1] 0.99212 plot_single_hist(x, alpha = 0.5, color = &quot;black&quot;) + geom_vline(xintercept = c(-69, 69)) + labs(x = &quot;beta&quot;) #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. c) Using the obtained σβ, add the desired prior in the Stan code. From some trial and error, it seems that a prior of \\(\\text{Normal}(0, 26)\\) should work. I have added this prior distribution to beta in the model at line 17. beta ~ normal(0, 26); // prior on `beta` d) In a similar way, add a weakly informative prior for the intercept alpha and explain how you chose the prior. To use the year directly as the values for \\(x\\) would lead to a massive value of \\(\\alpha\\) because the values for \\(x\\) range from 1980 to 2019. Thus, it would be advisable to first center the year, meaning at the prior distribution for \\(\\alpha\\) can be centered around the average of the number of drownings per year and a standard deviation near that of the actual number of drownings. head(drowning) #&gt; year drownings #&gt; 1 1980 149 #&gt; 2 1981 127 #&gt; 3 1982 139 #&gt; 4 1983 141 #&gt; 5 1984 122 #&gt; 6 1985 120 print(mean(drowning$drownings)) #&gt; [1] 134.35 print(sd(drowning$drownings)) #&gt; [1] 28.48441 Therefore, I add the prior \\(\\text{Normal}(135, 50)\\) to \\(\\alpha\\) on line 16. alpha ~ normal(135, 50); // prior on `alpha` data &lt;- list( N = nrow(drowning), x = drowning$year - mean(drowning$year), y = drowning$drownings, xpred = 2020 - mean(drowning$year) ) drowning_model &lt;- stan( here::here(&quot;models&quot;, &quot;assignment07-drownings.stan&quot;), data = data ) variable_post &lt;- spread_draws(drowning_model, alpha, beta) %&gt;% pivot_longer(c(alpha, beta), names_to = &quot;variable&quot;, values_to = &quot;value&quot;) head(variable_post) #&gt; # A tibble: 6 × 5 #&gt; .chain .iteration .draw variable value #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 1 1 alpha 135. #&gt; 2 1 1 1 beta -1.08 #&gt; 3 1 2 2 alpha 134. #&gt; 4 1 2 2 beta -0.918 #&gt; 5 1 3 3 alpha 135. #&gt; 6 1 3 3 beta -1.58 variable_post %&gt;% ggplot(aes(x = .iteration, y = value, color = factor(.chain))) + facet_grid(rows = vars(variable), scales = &quot;free_y&quot;) + geom_path(alpha = 0.5) + scale_x_continuous(expand = expansion(c(0, 0))) + scale_y_continuous(expand = expansion(c(0.02, 0.02))) + labs(x = &quot;iteration&quot;, y = &quot;value&quot;, color = &quot;chain&quot;) variable_post %&gt;% ggplot(aes(x = value)) + facet_grid(cols = vars(variable), scales = &quot;free_x&quot;) + geom_histogram(color = &quot;black&quot;, alpha = 0.3, bins = 30) + scale_x_continuous(expand = expansion(c(0.02, 0.02))) + scale_y_continuous(expand = expansion(c(0, 0.02))) spread_draws(drowning_model, ypred) %$% plot_single_hist(ypred, alpha = 0.3, color = &quot;black&quot;) + labs(x = &quot;predicted number of drownings in 2020&quot;) #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. red &lt;- &quot;#C34E51&quot; bayestestR::describe_posterior(drowning_model, ci = 0.89, test = c()) %&gt;% as_tibble() %&gt;% filter(str_detect(Parameter, &quot;mu&quot;)) %&gt;% select(Parameter, Median, CI_low, CI_high) %&gt;% janitor::clean_names() %&gt;% mutate(idx = row_number()) %&gt;% left_join(drowning %&gt;% mutate(idx = row_number()), by = &quot;idx&quot;) %&gt;% ggplot(aes(x = year)) + geom_point(aes(y = drownings), data = drowning, color = &quot;#4C71B0&quot;) + geom_line(aes(y = median), color = red, size = 1.2) + geom_smooth( aes(y = ci_low), method = &quot;loess&quot;, formula = &quot;y ~ x&quot;, linetype = 2, se = FALSE, color = red, size = 1 ) + geom_smooth( aes(y = ci_high), method = &quot;loess&quot;, formula = &quot;y ~ x&quot;, linetype = 2, se = FALSE, color = red, size = 1 ) + labs(x = &quot;year&quot;, y = &quot;number of drownings (mean ± 89% CI)&quot;) 26.3 2. Hierarchical model: factory data with Stan The factory data in the ‘aaltobda’ package contains quality control measurements from 6 machines in a factory (units of the measurements are irrelevant here). In the data file, each column contains the measurements for a single machine. Quality control measurements are expensive and time-consuming, so only 5 measurements were done for each machine. In addition to the existing machines, we are interested in the quality of another machine (the seventh machine). For this problem, you’ll use the following Gaussian models: a separate model, in which each machine has its own model a pooled model, in which all measurements are combined and there is no distinction between machines a hierarchical model, which has a hierarchical structure as described in BDA3 Section 11.6 As in the model described in the book, use the same measurement standard deviation \\(\\sigma\\) for all the groups in the hierarchical model. In the separate model, however, use separate measurement standard deviation \\(\\sigma_j\\) for each group \\(j\\). You should use weakly informative priors for all your models. Complete the following questions for each of the three models (separate, pooled, hierarchical). a) Describe the model with mathematical notation. Also describe in words the difference between the three models. Separate model: The separate model is described below where each machine has its own centrality \\(\\mu\\) and dispersion \\(\\sigma\\) parameters that do not influence the parameters of the other machines. \\[ y_{ij} \\sim N(\\mu_j, \\sigma_j) \\\\ \\mu_j \\sim N(0, 1) \\\\ \\sigma_j \\sim \\text{Inv-}\\chi^2(10) \\] Pooled model: The pool model is described below where there is no distinction between the models but instead a single set of parameters for all of the data. \\[ y_{i} \\sim N(\\mu, \\sigma) \\\\ \\mu \\sim N(0, 1) \\\\ \\sigma \\sim \\text{Inv-}\\chi^2(10) \\] Hierarchical model: The hierarchical model is described below where each machine has its own centrality \\(\\mu\\) parameter which are linked through a hyper-prior distribution from which they are drawn. The machines will all share a common dispersion paramete \\(\\sigma\\) \\[ y_{ij} \\sim N(\\mu_j, \\sigma_j) \\\\ \\mu_j \\sim N(\\alpha, \\tau) \\\\ \\alpha \\sim N(0, 1) \\\\ \\tau \\sim \\text{HalfNormal}(2.5) \\\\ \\sigma \\sim \\text{Inv-}\\chi^2(10) \\] The separate model is effectively building a different linear model for each machine where as the pooled model treats all the measurements as coming from the same model. The hierarchical model is treating the machines as having come from a single, shared distribution. b) Implement the model in Stan and include the code in the report. Use weakly informative priors for all your models. print_model_code &lt;- function(path) { for (l in readLines(path)) { cat(l, &quot;\\n&quot;) } } Separate model separate_model_code &lt;- here::here( &quot;models&quot;, &quot;assignment07_factories_separate.stan&quot; ) print_model_code(separate_model_code) #&gt; data { #&gt; int&lt;lower=0&gt; N; // number of data points per machine #&gt; int&lt;lower=0&gt; J; // number of machines #&gt; vector[J] y[N]; // quality control data points #&gt; } #&gt; #&gt; parameters { #&gt; vector[J] mu; #&gt; vector&lt;lower=0&gt;[J] sigma; #&gt; } #&gt; #&gt; model { #&gt; // priors #&gt; for (j in 1:J) { #&gt; mu[j] ~ normal(100, 10); #&gt; sigma[j] ~ inv_chi_square(5); #&gt; } #&gt; #&gt; // likelihood #&gt; for (j in 1:J){ #&gt; y[,j] ~ normal(mu[j], sigma[j]); #&gt; } #&gt; } #&gt; #&gt; generated quantities { #&gt; // Compute the predictive distribution for the sixth machine. #&gt; real y6pred; #&gt; vector[J] log_lik[N]; #&gt; #&gt; y6pred = normal_rng(mu[6], sigma[6]); #&gt; #&gt; for (j in 1:J) { #&gt; for (n in 1:N) { #&gt; log_lik[n,j] = normal_lpdf(y[n,j] | mu[j], sigma[j]); #&gt; } #&gt; } #&gt; } separate_model_data &lt;- list( y = factory, N = nrow(factory), J = ncol(factory) ) separate_model &lt;- rstan::stan( separate_model_code, data = separate_model_data, verbose = FALSE, refresh = 0 ) knitr::kable( bayestestR::describe_posterior(separate_model, ci = 0.89, test = NULL), digits = 3 ) Parameter Median CI CI_low CI_high ESS Rhat 31 mu[1] 85.111 0.89 74.306 96.601 2713.665 1.000 32 mu[2] 105.263 0.89 98.325 111.841 3975.737 0.999 33 mu[3] 90.187 0.89 82.651 97.276 3363.204 1.000 34 mu[4] 110.726 0.89 106.159 115.729 3507.330 1.001 35 mu[5] 91.315 0.89 84.852 97.457 3387.003 1.000 36 mu[6] 90.724 0.89 81.465 100.714 3947.610 1.000 37 y6pred 90.870 0.89 62.936 121.718 4077.420 1.001 1 log_lik[1,1] -3.847 0.89 -4.405 -3.393 2050.755 1.000 7 log_lik[2,1] -3.979 0.89 -4.431 -3.576 4879.696 1.000 13 log_lik[3,1] -3.979 0.89 -4.431 -3.576 4429.343 0.999 19 log_lik[4,1] -6.266 0.89 -8.130 -4.896 5557.199 1.001 25 log_lik[5,1] -4.386 0.89 -5.030 -3.759 5096.882 1.000 2 log_lik[1,2] -4.006 0.89 -4.863 -3.250 6597.596 0.999 8 log_lik[2,2] -3.348 0.89 -3.909 -2.880 2587.751 0.999 14 log_lik[3,2] -3.688 0.89 -4.358 -3.117 2452.719 1.000 20 log_lik[4,2] -3.281 0.89 -3.774 -2.801 3074.626 1.001 26 log_lik[5,2] -4.972 0.89 -6.871 -3.669 5487.854 0.999 3 log_lik[1,3] -3.901 0.89 -4.723 -3.337 3825.434 1.000 9 log_lik[2,3] -3.423 0.89 -3.880 -2.959 3092.288 1.000 15 log_lik[3,3] -3.394 0.89 -3.868 -2.943 2587.751 0.999 21 log_lik[4,3] -3.437 0.89 -4.010 -2.947 3505.274 1.000 27 log_lik[5,3] -5.626 0.89 -7.689 -4.092 2961.958 1.001 4 log_lik[1,4] -3.277 0.89 -3.979 -2.647 3786.606 1.000 10 log_lik[2,4] -3.696 0.89 -4.675 -2.832 4896.409 1.000 16 log_lik[3,4] -3.199 0.89 -3.900 -2.614 4317.514 1.000 22 log_lik[4,4] -3.775 0.89 -5.014 -2.892 6923.344 0.999 28 log_lik[5,4] -3.199 0.89 -3.900 -2.614 2505.018 1.000 5 log_lik[1,5] -4.127 0.89 -5.201 -3.309 2777.028 1.001 11 log_lik[2,5] -3.410 0.89 -3.964 -2.926 5870.349 1.000 17 log_lik[3,5] -4.020 0.89 -5.144 -3.216 5096.882 1.000 23 log_lik[4,5] -4.127 0.89 -5.201 -3.309 3577.546 1.000 29 log_lik[5,5] -3.190 0.89 -3.677 -2.722 3005.680 1.000 6 log_lik[1,6] -5.888 0.89 -7.758 -4.540 5509.757 0.999 12 log_lik[2,6] -3.771 0.89 -4.234 -3.314 6725.445 1.000 18 log_lik[3,6] -4.147 0.89 -4.723 -3.642 3786.606 1.000 24 log_lik[4,6] -4.139 0.89 -4.700 -3.565 2685.671 1.001 30 log_lik[5,6] -3.978 0.89 -4.411 -3.486 3718.073 1.000 Pooled model pooled_model_code &lt;- here::here(&quot;models&quot;, &quot;assignment07_factories_pooled.stan&quot;) print_model_code(pooled_model_code) #&gt; data { #&gt; int&lt;lower=0&gt; N; // number of data points #&gt; vector[N] y; // machine quality control data #&gt; } #&gt; #&gt; parameters { #&gt; real mu; #&gt; real&lt;lower=0&gt; sigma; #&gt; } #&gt; #&gt; model { #&gt; // priors #&gt; mu ~ normal(100, 10); #&gt; sigma ~ inv_chi_square(5); #&gt; #&gt; // likelihood #&gt; y ~ normal(mu, sigma); #&gt; } #&gt; #&gt; generated quantities { #&gt; real ypred; #&gt; vector[N] log_lik; #&gt; #&gt; ypred = normal_rng(mu, sigma); #&gt; #&gt; for (i in 1:N) #&gt; log_lik[i] = normal_lpdf(y[i] | mu, sigma); #&gt; #&gt; } pooled_model_data &lt;- list( y = unname(unlist(factory)), N = length(unlist(factory)) ) pooled_model &lt;- rstan::stan( pooled_model_code, data = pooled_model_data, verbose = FALSE, refresh = 0 ) knitr::kable( bayestestR::describe_posterior(pooled_model, ci = 0.89, test = NULL), digits = 3 ) Parameter Median CI CI_low CI_high ESS Rhat 31 mu 93.516 0.89 88.619 98.538 2792.680 1.000 32 ypred 93.338 0.89 63.567 121.323 4090.508 1.000 1 log_lik[1] -3.978 0.89 -4.190 -3.753 2834.900 1.000 12 log_lik[2] -3.796 0.89 -3.990 -3.586 2552.985 1.002 23 log_lik[3] -3.796 0.89 -3.990 -3.586 2552.985 1.002 25 log_lik[4] -7.500 0.89 -8.975 -6.111 3175.958 1.002 26 log_lik[5] -4.947 0.89 -5.454 -4.497 3189.124 1.001 27 log_lik[6] -4.694 0.89 -5.126 -4.305 2997.643 1.000 28 log_lik[7] -4.190 0.89 -4.444 -3.942 2833.338 1.001 29 log_lik[8] -4.482 0.89 -4.830 -4.161 2951.303 1.000 30 log_lik[9] -3.977 0.89 -4.195 -3.776 2707.695 1.003 2 log_lik[10] -3.863 0.89 -4.075 -3.662 2664.152 1.001 3 log_lik[11] -3.888 0.89 -4.075 -3.680 2665.731 1.004 4 log_lik[12] -3.793 0.89 -3.992 -3.586 2549.054 1.003 5 log_lik[13] -3.796 0.89 -3.990 -3.586 2552.985 1.002 6 log_lik[14] -3.887 0.89 -4.102 -3.681 2710.840 1.001 7 log_lik[15] -4.947 0.89 -5.454 -4.497 3189.124 1.001 8 log_lik[16] -4.013 0.89 -4.226 -3.798 2728.733 1.003 9 log_lik[17] -4.853 0.89 -5.367 -4.429 3019.529 1.000 10 log_lik[18] -4.621 0.89 -5.016 -4.248 2984.177 1.000 11 log_lik[19] -3.914 0.89 -4.119 -3.717 2676.073 1.003 13 log_lik[20] -4.621 0.89 -5.016 -4.248 2984.177 1.000 14 log_lik[21] -4.142 0.89 -4.399 -3.910 2963.757 1.000 15 log_lik[22] -3.814 0.89 -4.013 -3.618 2539.292 1.003 16 log_lik[23] -3.944 0.89 -4.156 -3.746 2690.057 1.003 17 log_lik[24] -4.142 0.89 -4.399 -3.910 2963.757 1.000 18 log_lik[25] -3.796 0.89 -3.990 -3.586 2552.985 1.002 19 log_lik[26] -5.986 0.89 -6.897 -5.180 3193.539 1.002 20 log_lik[27] -3.796 0.89 -3.990 -3.586 2552.985 1.002 21 log_lik[28] -3.977 0.89 -4.195 -3.776 2707.695 1.003 22 log_lik[29] -4.242 0.89 -4.517 -3.984 3028.028 1.000 24 log_lik[30] -3.864 0.89 -4.049 -3.654 2628.695 1.004 Hierarchical model hierarchical_model_code &lt;- here::here( &quot;models&quot;, &quot;assignment07_factories_hierarchical.stan&quot; ) print_model_code(hierarchical_model_code) #&gt; data { #&gt; int&lt;lower=0&gt; N; // number of data points per machine #&gt; int&lt;lower=0&gt; J; // number of machines #&gt; vector[J] y[N]; // quality control data points #&gt; } #&gt; #&gt; parameters { #&gt; vector[J] mu; #&gt; real&lt;lower=0&gt; sigma; #&gt; real alpha; #&gt; real&lt;lower=0&gt; tau; #&gt; } #&gt; #&gt; model { #&gt; // hyper-priors #&gt; alpha ~ normal(100, 10); #&gt; tau ~ normal(0, 10); #&gt; #&gt; // priors #&gt; mu ~ normal(alpha, tau); #&gt; sigma ~ inv_chi_square(5); #&gt; #&gt; // likelihood #&gt; for (j in 1:J){ #&gt; y[,j] ~ normal(mu[j], sigma); #&gt; } #&gt; } #&gt; #&gt; generated quantities { #&gt; // Compute the predictive distribution for the sixth machine. #&gt; real y6pred; // Leave for compatibility with earlier assignments. #&gt; vector[J] ypred; #&gt; real mu7pred; #&gt; real y7pred; #&gt; vector[J] log_lik[N]; #&gt; #&gt; y6pred = normal_rng(mu[6], sigma); #&gt; for (j in 1:J) { #&gt; ypred[j] = normal_rng(mu[j], sigma); #&gt; } #&gt; #&gt; mu7pred = normal_rng(alpha, tau); #&gt; y7pred = normal_rng(mu7pred, sigma); #&gt; #&gt; for (j in 1:J) { #&gt; for (n in 1:N) { #&gt; log_lik[n,j] = normal_lpdf(y[n,j] | mu[j], sigma); #&gt; } #&gt; } #&gt; } hierarchical_model_data &lt;- list( y = factory, N = nrow(factory), J = ncol(factory) ) hierarchical_model &lt;- rstan::stan( hierarchical_model_code, data = hierarchical_model_data, verbose = FALSE, refresh = 0 ) #&gt; Warning: There were 32 divergent transitions after warmup. See #&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #&gt; to find out why this is a problem and how to eliminate them. #&gt; Warning: Examine the pairs() plot to diagnose sampling problems knitr::kable( bayestestR::describe_posterior(hierarchical_model, ci = 0.89, test = NULL), digits = 3 ) Parameter Median CI CI_low CI_high ESS Rhat 32 mu[1] 81.502 0.89 71.656 91.170 2666.504 1.002 33 mu[2] 102.520 0.89 92.735 111.327 3058.328 1.001 34 mu[3] 89.846 0.89 81.341 98.753 3882.504 1.001 35 mu[4] 106.568 0.89 96.595 116.746 2209.765 1.001 36 mu[5] 91.266 0.89 82.593 99.788 3592.183 0.999 37 mu[6] 88.523 0.89 79.551 97.316 4059.488 0.999 1 alpha 94.256 0.89 87.420 102.841 3417.937 0.999 39 tau 10.574 0.89 4.933 17.387 1643.252 1.003 40 y6pred 88.177 0.89 63.554 112.444 4098.415 1.000 42 ypred[1] 81.369 0.89 56.341 105.538 3544.553 1.001 43 ypred[2] 103.058 0.89 77.523 127.228 3675.682 1.000 44 ypred[3] 89.805 0.89 64.398 112.847 4492.295 1.000 45 ypred[4] 106.496 0.89 82.866 131.399 3414.140 1.000 46 ypred[5] 91.079 0.89 66.153 115.148 4135.596 1.000 47 ypred[6] 88.358 0.89 63.394 113.503 4218.295 0.999 38 mu7pred 94.467 0.89 74.222 113.732 3826.575 1.001 41 y7pred 94.836 0.89 65.364 125.617 3463.076 1.000 2 log_lik[1,1] -3.649 0.89 -3.937 -3.369 2271.617 1.001 8 log_lik[2,1] -3.879 0.89 -4.447 -3.464 3246.640 1.001 14 log_lik[3,1] -3.879 0.89 -4.447 -3.464 4042.348 1.000 20 log_lik[4,1] -6.710 0.89 -8.676 -5.034 1622.617 1.001 26 log_lik[5,1] -4.113 0.89 -4.811 -3.528 3865.045 0.999 3 log_lik[1,2] -4.112 0.89 -4.769 -3.490 4840.755 1.000 9 log_lik[2,2] -3.711 0.89 -4.161 -3.400 3519.330 1.002 15 log_lik[3,2] -3.916 0.89 -4.482 -3.416 2107.559 1.002 21 log_lik[4,2] -3.642 0.89 -3.931 -3.364 2807.278 1.000 27 log_lik[5,2] -4.194 0.89 -5.003 -3.598 2275.083 1.001 4 log_lik[1,3] -3.918 0.89 -4.455 -3.471 2627.950 1.001 10 log_lik[2,3] -3.655 0.89 -3.939 -3.382 2405.063 1.001 16 log_lik[3,3] -3.643 0.89 -3.934 -3.389 3519.330 1.002 22 log_lik[4,3] -3.658 0.89 -3.962 -3.376 2765.118 1.001 28 log_lik[5,3] -4.873 0.89 -5.868 -3.895 2634.266 1.001 5 log_lik[1,4] -3.647 0.89 -3.939 -3.367 1987.050 1.001 11 log_lik[2,4] -3.977 0.89 -4.646 -3.435 3317.433 1.000 17 log_lik[3,4] -3.821 0.89 -4.410 -3.408 3859.162 1.000 23 log_lik[4,4] -3.691 0.89 -4.031 -3.401 4217.883 1.000 29 log_lik[5,4] -3.821 0.89 -4.410 -3.408 1814.465 1.002 6 log_lik[1,5] -3.970 0.89 -4.519 -3.481 2446.320 1.003 12 log_lik[2,5] -3.702 0.89 -4.060 -3.402 2201.263 1.001 18 log_lik[3,5] -3.942 0.89 -4.500 -3.494 3865.045 0.999 24 log_lik[4,5] -3.970 0.89 -4.519 -3.481 3729.297 0.999 30 log_lik[5,5] -3.630 0.89 -3.906 -3.377 2944.595 1.000 7 log_lik[1,6] -6.046 0.89 -7.683 -4.598 4021.581 1.000 13 log_lik[2,6] -3.665 0.89 -3.944 -3.379 4637.809 1.000 19 log_lik[3,6] -4.186 0.89 -4.998 -3.612 1987.050 1.001 25 log_lik[4,6] -3.930 0.89 -4.470 -3.453 2039.388 1.001 31 log_lik[5,6] -3.930 0.89 -4.524 -3.496 3890.526 1.000 c) Using the model (with weakly informative priors) report, comment on and, if applicable, plot histograms for the following distributions: the posterior distribution of the mean of the quality measurements of the sixth machine. the predictive distribution for another quality measurement of the sixth machine. the posterior distribution of the mean of the quality measurements of the seventh machine. plot_hist_mean_of_sixth &lt;- function(vals) { plot_single_hist(vals, bins = 30, color = &quot;black&quot;, alpha = 0.3) + labs(x = &quot;mean of 6th machine&quot;, y = &quot;posterior density&quot;) } plot_hist_sixth_predictions &lt;- function(vals) { plot_single_hist(vals, bins = 30, color = &quot;black&quot;, alpha = 0.3) + labs(x = &quot;posterior predictions for 6th machine&quot;, y = &quot;posterior density&quot;) } plot_hist_mean_of_seventh &lt;- function(vals) { plot_single_hist(vals, bins = 30, color = &quot;black&quot;, alpha = 0.3) + labs(x = &quot;mean of 7thth machine&quot;, y = &quot;posterior density&quot;) } Separate model plot_hist_mean_of_sixth(rstan::extract(separate_model)$mu[, 6]) plot_hist_sixth_predictions(rstan::extract(separate_model)$y6pred) It is not possible to estimate the posterior for the mean of some new 7th machine because all machines are treated separately. Pooled model plot_hist_mean_of_sixth(rstan::extract(pooled_model)$mu) plot_hist_sixth_predictions(rstan::extract(pooled_model)$ypred) The predicted mean for a new machine is the same as the pooled mean \\(mu\\). plot_hist_mean_of_seventh(rstan::extract(pooled_model)$mu) Hierarchical model plot_hist_mean_of_sixth(rstan::extract(hierarchical_model)$mu[, 6]) plot_hist_sixth_predictions(rstan::extract(hierarchical_model)$y6pred) plot_hist_mean_of_seventh(rstan::extract(hierarchical_model)$mu7pred) d) Report the posterior expectation for \\(\\mu_1\\) with a 90% credible interval but using a \\(\\text{Normal}(0,10)\\) prior for the \\(\\mu\\) parameter(s) and a \\(\\text{Gamma}(1,1)\\) prior for the \\(\\sigma\\) parameter(s). For the hierarchical model, use the \\(\\text{Normal}(0, 10)\\) and \\(\\text{Gamma}(1, 1)\\) as hyper-priors. (I’m going to skip this one, but come back to it if it is needed for future assignments.) sessionInfo() #&gt; R version 4.1.2 (2021-11-01) #&gt; Platform: x86_64-apple-darwin17.0 (64-bit) #&gt; Running under: macOS Big Sur 10.16 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices datasets utils methods base #&gt; #&gt; other attached packages: #&gt; [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.7 #&gt; [4] purrr_0.3.4 readr_2.0.1 tidyr_1.1.3 #&gt; [7] tibble_3.1.3 tidyverse_1.3.1 magrittr_2.0.1 #&gt; [10] tidybayes_3.0.1 rstan_2.21.2 ggplot2_3.3.5 #&gt; [13] StanHeaders_2.21.0-7 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-153 matrixStats_0.61.0 fs_1.5.0 #&gt; [4] lubridate_1.7.10 insight_0.14.4 httr_1.4.2 #&gt; [7] rprojroot_2.0.2 tensorA_0.36.2 tools_4.1.2 #&gt; [10] backports_1.2.1 bslib_0.2.5.1 utf8_1.2.2 #&gt; [13] R6_2.5.0 mgcv_1.8-38 DBI_1.1.1 #&gt; [16] colorspace_2.0-2 ggdist_3.0.0 withr_2.4.2 #&gt; [19] tidyselect_1.1.1 gridExtra_2.3 prettyunits_1.1.1 #&gt; [22] processx_3.5.2 curl_4.3.2 compiler_4.1.2 #&gt; [25] cli_3.0.1 rvest_1.0.1 arrayhelpers_1.1-0 #&gt; [28] xml2_1.3.2 bayestestR_0.11.0 labeling_0.4.2 #&gt; [31] bookdown_0.24 posterior_1.1.0 sass_0.4.0 #&gt; [34] scales_1.1.1 checkmate_2.0.0 aaltobda_0.3.1 #&gt; [37] callr_3.7.0 digest_0.6.27 rmarkdown_2.10 #&gt; [40] pkgconfig_2.0.3 htmltools_0.5.1.1 highr_0.9 #&gt; [43] dbplyr_2.1.1 rlang_0.4.11 readxl_1.3.1 #&gt; [46] rstudioapi_0.13 jquerylib_0.1.4 farver_2.1.0 #&gt; [49] generics_0.1.0 svUnit_1.0.6 jsonlite_1.7.2 #&gt; [52] distributional_0.2.2 inline_0.3.19 loo_2.4.1 #&gt; [55] Matrix_1.3-4 Rcpp_1.0.7 munsell_0.5.0 #&gt; [58] fansi_0.5.0 abind_1.4-5 lifecycle_1.0.0 #&gt; [61] stringi_1.7.3 yaml_2.2.1 snakecase_0.11.0 #&gt; [64] pkgbuild_1.2.0 grid_4.1.2 parallel_4.1.2 #&gt; [67] crayon_1.4.1 lattice_0.20-45 splines_4.1.2 #&gt; [70] haven_2.4.3 hms_1.1.0 knitr_1.33 #&gt; [73] ps_1.6.0 pillar_1.6.2 codetools_0.2-18 #&gt; [76] clisymbols_1.2.0 stats4_4.1.2 reprex_2.0.1 #&gt; [79] glue_1.4.2 evaluate_0.14 V8_3.4.2 #&gt; [82] renv_0.14.0 RcppParallel_5.1.4 modelr_0.1.8 #&gt; [85] vctrs_0.3.8 tzdb_0.1.2 cellranger_1.1.0 #&gt; [88] gtable_0.3.0 datawizard_0.2.1 assertthat_0.2.1 #&gt; [91] xfun_0.25 janitor_2.1.0 broom_0.7.9 #&gt; [94] coda_0.19-4 ellipsis_0.3.2 here_1.0.1 "],["assignment-8.html", "27 Assignment 8 27.1 Setup 27.2 Exercise 1. Model assessment: LOO-CV for factory data with Stan", " 27 Assignment 8 2021-11-12 Assignment 8 27.1 Setup knitr::opts_chunk$set(echo = TRUE, comment = &quot;#&gt;&quot;, dpi = 300) for (f in list.files(here::here(&quot;src&quot;), pattern = &quot;R$&quot;, full.names = TRUE)) { source(f) } library(rstan) library(bayestestR) library(loo) library(tidybayes) library(tidyverse) rstan_options(auto_write = TRUE) options(mc.cores = 2) theme_set(theme_classic() + theme(strip.background = element_blank())) factory &lt;- aaltobda::factory set.seed(678) 27.2 Exercise 1. Model assessment: LOO-CV for factory data with Stan Use leave-one-out cross-validation (LOO-CV) to assess the predictive performance of the pooled, separate and hierarchical Gaussian models for the factory dataset (see the second exercise in Assignment 7). a) Fit the models with Stan as instructed in Assignment 7. To use the loo or psisloo functions, you need to compute the log-likelihood values of each observation for every posterior draw (i.e. an \\(S\\)-by-\\(N\\) matrix, where \\(S\\) is the number of posterior draws and \\(N = 30\\) is the total number of observations). This can be done in the generated quantities block in the Stan code; for a demonstration, see the Gaussian linear model lin.stan in the R Stan examples that can be found here. Separate model separate_model_code &lt;- here::here( &quot;models&quot;, &quot;assignment07_factories_separate.stan&quot; ) separate_model_data &lt;- list( y = factory, N = nrow(factory), J = ncol(factory) ) separate_model &lt;- rstan::stan( separate_model_code, data = separate_model_data, verbose = FALSE, refresh = 0 ) print(separate_model, pars = c(&quot;mu&quot;, &quot;sigma&quot;)) #&gt; Inference for Stan model: assignment07_factories_separate. #&gt; 4 chains, each with iter=2000; warmup=1000; thin=1; #&gt; post-warmup draws per chain=1000, total post-warmup draws=4000. #&gt; #&gt; mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat #&gt; mu[1] 85.74 0.13 7.30 72.77 80.60 85.40 90.50 101.41 2985 1 #&gt; mu[2] 105.07 0.07 4.40 96.26 102.25 105.16 107.86 113.48 3528 1 #&gt; mu[3] 90.40 0.08 4.62 81.81 87.40 90.12 93.23 100.44 3546 1 #&gt; mu[4] 110.56 0.06 3.12 104.01 108.86 110.67 112.45 116.16 2523 1 #&gt; mu[5] 91.46 0.06 3.90 84.00 89.00 91.29 93.83 99.79 3928 1 #&gt; mu[6] 91.25 0.11 6.31 79.88 87.09 90.80 94.99 104.94 3392 1 #&gt; sigma[1] 19.28 0.14 6.92 10.51 14.54 17.85 22.36 36.47 2495 1 #&gt; sigma[2] 10.41 0.06 3.32 6.14 8.14 9.78 11.92 18.78 2971 1 #&gt; sigma[3] 11.42 0.07 3.76 6.62 8.86 10.57 13.13 20.71 2825 1 #&gt; sigma[4] 6.85 0.06 2.47 3.90 5.26 6.37 7.82 12.71 1640 1 #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 2 rows ] #&gt; #&gt; Samples were drawn using NUTS(diag_e) at Tue Feb 8 07:07:25 2022. #&gt; For each parameter, n_eff is a crude measure of effective sample size, #&gt; and Rhat is the potential scale reduction factor on split chains (at #&gt; convergence, Rhat=1). Pooled model pooled_model_code &lt;- here::here(&quot;models&quot;, &quot;assignment07_factories_pooled.stan&quot;) pooled_model_data &lt;- list( y = unname(unlist(factory)), N = length(unlist(factory)) ) pooled_model &lt;- rstan::stan( pooled_model_code, data = pooled_model_data, verbose = FALSE, refresh = 0 ) print(pooled_model, pars = c(&quot;mu&quot;, &quot;sigma&quot;)) #&gt; Inference for Stan model: assignment07_factories_pooled. #&gt; 4 chains, each with iter=2000; warmup=1000; thin=1; #&gt; post-warmup draws per chain=1000, total post-warmup draws=4000. #&gt; #&gt; mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat #&gt; mu 93.64 0.06 3.15 87.50 91.56 93.62 95.67 99.94 2906 1 #&gt; sigma 17.74 0.04 2.33 13.92 16.06 17.47 19.16 22.88 2707 1 #&gt; #&gt; Samples were drawn using NUTS(diag_e) at Tue Feb 8 07:07:28 2022. #&gt; For each parameter, n_eff is a crude measure of effective sample size, #&gt; and Rhat is the potential scale reduction factor on split chains (at #&gt; convergence, Rhat=1). Hierarchical model hierarchical_model_code &lt;- here::here( &quot;models&quot;, &quot;assignment07_factories_hierarchical.stan&quot; ) hierarchical_model_data &lt;- list( y = factory, N = nrow(factory), J = ncol(factory) ) hierarchical_model &lt;- rstan::stan( hierarchical_model_code, data = hierarchical_model_data, verbose = FALSE, refresh = 0 ) #&gt; Warning: There were 29 divergent transitions after warmup. See #&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #&gt; to find out why this is a problem and how to eliminate them. #&gt; Warning: Examine the pairs() plot to diagnose sampling problems print(hierarchical_model, pars = c(&quot;alpha&quot;, &quot;tau&quot;, &quot;mu&quot;, &quot;sigma&quot;)) #&gt; Inference for Stan model: assignment07_factories_hierarchical. #&gt; 4 chains, each with iter=2000; warmup=1000; thin=1; #&gt; post-warmup draws per chain=1000, total post-warmup draws=4000. #&gt; #&gt; mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat #&gt; alpha 94.49 0.08 4.59 85.49 91.41 94.51 97.42 103.75 3438 1.00 #&gt; tau 10.94 0.12 4.10 3.65 8.07 10.58 13.41 19.85 1222 1.01 #&gt; mu[1] 81.63 0.17 6.34 69.57 77.30 81.40 85.80 94.85 1382 1.00 #&gt; mu[2] 102.56 0.12 5.77 91.48 98.58 102.49 106.34 114.27 2445 1.00 #&gt; mu[3] 89.79 0.10 5.57 78.62 86.16 89.88 93.51 100.59 3159 1.00 #&gt; mu[4] 106.30 0.14 6.32 93.89 102.01 106.47 110.66 118.44 2004 1.00 #&gt; mu[5] 91.32 0.09 5.38 80.68 87.73 91.38 94.88 101.74 3999 1.00 #&gt; mu[6] 88.65 0.12 5.69 77.27 84.95 88.75 92.59 99.52 2244 1.00 #&gt; sigma 14.34 0.05 2.19 10.78 12.78 14.07 15.58 19.52 1980 1.00 #&gt; #&gt; Samples were drawn using NUTS(diag_e) at Tue Feb 8 07:07:30 2022. #&gt; For each parameter, n_eff is a crude measure of effective sample size, #&gt; and Rhat is the potential scale reduction factor on split chains (at #&gt; convergence, Rhat=1). b) Compute the PSIS-LOO elpd values and the \\(\\hat{k}\\)-values for each of the three models. Hint! It will be convenient to visualize the \\(\\hat{k}\\)-values for each model so that you can easily see how many of these values fall in the range \\(\\hat{k} &gt; 0.7\\) to assess the reliability of the PSIS-LOO estimate for each model. You can read more about the theoretical guarantees for the accuracy of the estimate depending on \\(\\hat{k}\\) from the original article (see here or here), but regarding this assignment, it suffices to understand that if all the \\(\\hat{k}\\)-values are \\(\\hat{k} \\le 0.7\\), the PSIS-LOO estimate can be considered to be reliable, otherwise there is a concern that it may be biased (too optimistic, overestimating the predictive accuracy of the model). calc_loo &lt;- function(mdl) { log_lik &lt;- loo::extract_log_lik(mdl, merge_chains = FALSE) r_eff &lt;- loo::relative_eff(exp(log_lik)) loo_res &lt;- loo::loo(log_lik, r_eff = r_eff) return(loo_res) } Separate model separate_loo &lt;- calc_loo(separate_model) #&gt; Warning: Some Pareto k diagnostic values are too high. See help(&#39;pareto-k-diagnostic&#39;) for details. print(separate_loo) #&gt; #&gt; Computed from 4000 by 30 log-likelihood matrix #&gt; #&gt; Estimate SE #&gt; elpd_loo -131.7 7.1 #&gt; p_loo 13.6 3.5 #&gt; looic 263.5 14.2 #&gt; ------ #&gt; Monte Carlo SE of elpd_loo is NA. #&gt; #&gt; Pareto k diagnostic values: #&gt; Count Pct. Min. n_eff #&gt; (-Inf, 0.5] (good) 19 63.3% 1810 #&gt; (0.5, 0.7] (ok) 6 20.0% 572 #&gt; (0.7, 1] (bad) 4 13.3% 32 #&gt; (1, Inf) (very bad) 1 3.3% 12 #&gt; See help(&#39;pareto-k-diagnostic&#39;) for details. Pooled model pooled_loo &lt;- calc_loo(pooled_model) print(pooled_loo) #&gt; #&gt; Computed from 4000 by 30 log-likelihood matrix #&gt; #&gt; Estimate SE #&gt; elpd_loo -130.9 4.9 #&gt; p_loo 2.1 0.9 #&gt; looic 261.9 9.7 #&gt; ------ #&gt; Monte Carlo SE of elpd_loo is 0.0. #&gt; #&gt; All Pareto k estimates are good (k &lt; 0.5). #&gt; See help(&#39;pareto-k-diagnostic&#39;) for details. Hierarchical model hierarchical_loo &lt;- calc_loo(hierarchical_model) #&gt; Warning: Some Pareto k diagnostic values are slightly high. See help(&#39;pareto-k-diagnostic&#39;) for details. print(hierarchical_loo) #&gt; #&gt; Computed from 4000 by 30 log-likelihood matrix #&gt; #&gt; Estimate SE #&gt; elpd_loo -127.0 5.1 #&gt; p_loo 6.1 1.8 #&gt; looic 254.0 10.1 #&gt; ------ #&gt; Monte Carlo SE of elpd_loo is 0.1. #&gt; #&gt; Pareto k diagnostic values: #&gt; Count Pct. Min. n_eff #&gt; (-Inf, 0.5] (good) 28 93.3% 1358 #&gt; (0.5, 0.7] (ok) 2 6.7% 250 #&gt; (0.7, 1] (bad) 0 0.0% &lt;NA&gt; #&gt; (1, Inf) (very bad) 0 0.0% &lt;NA&gt; #&gt; #&gt; All Pareto k estimates are ok (k &lt; 0.7). #&gt; See help(&#39;pareto-k-diagnostic&#39;) for details. c) Compute the effective number of parameters $p_ for each of the three models. Hint! The estimated effective number of parameters in the model can be computed from equation (7.15) in the book, where elpdloo-cv is the PSIS-LOO value (sum of the LOO log densities) and lpd is given by equation (7.5) in the book. extract_p_eff &lt;- function(loo_res) { loo_res$estimates[2, ] } bind_rows( extract_p_eff(separate_loo), extract_p_eff(pooled_loo), extract_p_eff(hierarchical_loo) ) %&gt;% add_column(model = c(&quot;separate&quot;, &quot;pooled&quot;, &quot;hierarchical&quot;)) #&gt; # A tibble: 3 × 3 #&gt; Estimate SE model #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 13.6 3.47 separate #&gt; 2 2.13 0.892 pooled #&gt; 3 6.07 1.76 hierarchical d) Assess how reliable the PSIS-LOO estimates are for the three models based on the \\(\\hat{k}\\)-values. plot_khat &lt;- function(loo_res, factory_data) { khat &lt;- as.data.frame(loo_res$pointwise)$influence_pareto_k factory_data %&gt;% mutate(idx = row_number()) %&gt;% pivot_longer(-idx, names_to = &quot;factory&quot;, values_to = &quot;measure&quot;) %&gt;% arrange(factory) %&gt;% mutate( khat = !!khat, factory = str_replace(factory, &quot;V&quot;, &quot;factory &quot;) ) %&gt;% ggplot(aes(x = factor(idx), y = khat)) + facet_wrap(vars(factory), nrow = 1, scales = &quot;free_x&quot;) + geom_hline(yintercept = c(0, 0.5, 0.7, 1.0), linetype = 2, color = &quot;grey50&quot;) + geom_point(shape = 3, color = &quot;#6497B1&quot;) + theme(axis.ticks = element_blank(), panel.grid.major.y = element_line()) + labs(x = &quot;measurement&quot;, y = &quot;Pareto shape k&quot;) } plot_khat(separate_loo, factory) + labs(title = &quot;Separate model&quot;) plot_khat(pooled_loo, factory) + labs(title = &quot;Pooled model&quot;) plot_khat(hierarchical_loo, factory) + labs(title = &quot;Hierarchical model&quot;) e) An assessment of whether there are differences between the models with regard to the elpdloo-cv, and if so, which model should be selected according to PSIS-LOO. extract_elpd &lt;- function(loo_res) { loo_res$estimates[1, ] } bind_rows( extract_elpd(separate_loo), extract_elpd(pooled_loo), extract_elpd(hierarchical_loo) ) %&gt;% add_column(model = c(&quot;separate&quot;, &quot;pooled&quot;, &quot;hierarchical&quot;)) #&gt; # A tibble: 3 × 3 #&gt; Estimate SE model #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 -132. 7.08 separate #&gt; 2 -131. 4.86 pooled #&gt; 3 -127. 5.05 hierarchical From the ELPD and \\(\\hat{k}\\) values, the hierarchical model is superior to the seaprate and pooled models. f) Both the Stan and R code should be included in your report. All of the R code is included in this file. All of the models are described in Assignment 7. Below is a list of the Stan code for all of the models (available in the models/ directory): separate models pooled model hierarchical model sessionInfo() #&gt; R version 4.1.2 (2021-11-01) #&gt; Platform: x86_64-apple-darwin17.0 (64-bit) #&gt; Running under: macOS Big Sur 10.16 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices datasets utils methods base #&gt; #&gt; other attached packages: #&gt; [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.7 #&gt; [4] purrr_0.3.4 readr_2.0.1 tidyr_1.1.3 #&gt; [7] tibble_3.1.3 tidyverse_1.3.1 tidybayes_3.0.1 #&gt; [10] loo_2.4.1 bayestestR_0.11.0 rstan_2.21.2 #&gt; [13] ggplot2_3.3.5 StanHeaders_2.21.0-7 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] fs_1.5.0 matrixStats_0.61.0 lubridate_1.7.10 #&gt; [4] insight_0.14.4 httr_1.4.2 rprojroot_2.0.2 #&gt; [7] tensorA_0.36.2 tools_4.1.2 backports_1.2.1 #&gt; [10] bslib_0.2.5.1 utf8_1.2.2 R6_2.5.0 #&gt; [13] DBI_1.1.1 colorspace_2.0-2 ggdist_3.0.0 #&gt; [16] withr_2.4.2 tidyselect_1.1.1 gridExtra_2.3 #&gt; [19] prettyunits_1.1.1 processx_3.5.2 curl_4.3.2 #&gt; [22] compiler_4.1.2 rvest_1.0.1 cli_3.0.1 #&gt; [25] arrayhelpers_1.1-0 xml2_1.3.2 labeling_0.4.2 #&gt; [28] bookdown_0.24 posterior_1.1.0 sass_0.4.0 #&gt; [31] scales_1.1.1 checkmate_2.0.0 aaltobda_0.3.1 #&gt; [34] callr_3.7.0 digest_0.6.27 rmarkdown_2.10 #&gt; [37] pkgconfig_2.0.3 htmltools_0.5.1.1 highr_0.9 #&gt; [40] dbplyr_2.1.1 rlang_0.4.11 readxl_1.3.1 #&gt; [43] rstudioapi_0.13 jquerylib_0.1.4 farver_2.1.0 #&gt; [46] generics_0.1.0 svUnit_1.0.6 jsonlite_1.7.2 #&gt; [49] distributional_0.2.2 inline_0.3.19 magrittr_2.0.1 #&gt; [52] Rcpp_1.0.7 munsell_0.5.0 fansi_0.5.0 #&gt; [55] abind_1.4-5 lifecycle_1.0.0 stringi_1.7.3 #&gt; [58] yaml_2.2.1 pkgbuild_1.2.0 grid_4.1.2 #&gt; [61] parallel_4.1.2 crayon_1.4.1 lattice_0.20-45 #&gt; [64] haven_2.4.3 hms_1.1.0 knitr_1.33 #&gt; [67] ps_1.6.0 pillar_1.6.2 codetools_0.2-18 #&gt; [70] clisymbols_1.2.0 stats4_4.1.2 reprex_2.0.1 #&gt; [73] glue_1.4.2 evaluate_0.14 V8_3.4.2 #&gt; [76] renv_0.14.0 RcppParallel_5.1.4 modelr_0.1.8 #&gt; [79] vctrs_0.3.8 tzdb_0.1.2 cellranger_1.1.0 #&gt; [82] gtable_0.3.0 assertthat_0.2.1 datawizard_0.2.1 #&gt; [85] xfun_0.25 broom_0.7.9 coda_0.19-4 #&gt; [88] ellipsis_0.3.2 here_1.0.1 "],["assignment-9.html", "28 Assignment 9 28.1 Setup 28.2 Exercise 1. Decision analysis for the factory data", " 28 Assignment 9 2021-11-18 Assignment 9 28.1 Setup knitr::opts_chunk$set(echo = TRUE, comment = &quot;#&gt;&quot;, dpi = 300) library(glue) library(rstan) ## Loading required package: StanHeaders ## Loading required package: ggplot2 ## rstan (Version 2.21.2, GitRev: 2e1f913d3ca3) ## For execution on a local, multicore CPU with excess RAM we recommend calling ## options(mc.cores = parallel::detectCores()). ## To avoid recompilation of unchanged Stan programs, we recommend calling ## rstan_options(auto_write = TRUE) library(tidybayes) library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ tibble 3.1.3 ✔ dplyr 1.0.7 ## ✔ tidyr 1.1.3 ✔ stringr 1.4.0 ## ✔ readr 2.0.1 ✔ forcats 0.5.1 ## ✔ purrr 0.3.4 ## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::collapse() masks glue::collapse() ## ✖ tidyr::extract() masks rstan::extract() ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() for (f in list.files(here::here(&quot;src&quot;), pattern = &quot;R$&quot;, full.names = TRUE)) { source(f) } rstan_options(auto_write = TRUE) options(mc.cores = 2) theme_set(theme_classic() + theme(strip.background = element_blank())) factory &lt;- aaltobda::factory set.seed(678) 28.2 Exercise 1. Decision analysis for the factory data Your task is to decide whether or not to buy a new (7th) machine for the company. The decision should be based on our best knowledge about the machines. The following is known about the production process: The given data contains quality measurements of single products from the six machines that are ordered from the same seller. (columns: different machines, rows: measurements) Customers pay 200 euros for each product. – If the quality of the product is below 85, the product cannot be sold – All the products that have sufficient quality are sold. Raw-materials, the salary of the machine user and the usage cost of the machine for each product cost 106 euros in total. – Usage cost of the machine also involves all investment and repair costs divided by the number of products a machine can create. So there is no need to take the investment cost into account as a separate factor. The only thing the company owner cares about is money. Thus, as a utility function, use the profit of a new product from a machine. a) For each of the six machines, compute and report the expected utility of one product of that machine. PURCHASE_RPICE &lt;- 200 MIN_QUALITY_TO_SELL &lt;- 85 COST_TO_PRODUCE &lt;- 106 utility &lt;- function(draws) { purchased &lt;- PURCHASE_RPICE * sum(draws &gt;= MIN_QUALITY_TO_SELL) cost_to_produce &lt;- -1 * COST_TO_PRODUCE * length(draws) u &lt;- (purchased + cost_to_produce) / length(draws) return(u) } # Test case given in the assignment. test_y_pred &lt;- c(123.80, 85.23, 70.16, 80.57, 84.91) test_res &lt;- utility(draws = test_y_pred) stop_if_not_close_to(test_res, -26) Fit the hierarchical model and gather posterior predictions from each machine. hierarchical_model_code &lt;- here::here( &quot;models&quot;, &quot;assignment07_factories_hierarchical.stan&quot; ) hierarchical_model_data &lt;- list( y = factory, N = nrow(factory), J = ncol(factory) ) hierarchical_model &lt;- rstan::stan( hierarchical_model_code, data = hierarchical_model_data, verbose = FALSE, refresh = 0 ) #&gt; Warning: There were 20 divergent transitions after warmup. See #&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #&gt; to find out why this is a problem and how to eliminate them. #&gt; Warning: Examine the pairs() plot to diagnose sampling problems print(hierarchical_model, pars = c(&quot;alpha&quot;, &quot;tau&quot;, &quot;mu&quot;, &quot;sigma&quot;)) #&gt; Inference for Stan model: assignment07_factories_hierarchical. #&gt; 4 chains, each with iter=2000; warmup=1000; thin=1; #&gt; post-warmup draws per chain=1000, total post-warmup draws=4000. #&gt; #&gt; mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat #&gt; alpha 94.55 0.08 4.83 85.43 91.32 94.37 97.72 104.49 3501 1 #&gt; tau 11.10 0.12 4.16 4.08 8.23 10.66 13.54 20.47 1212 1 #&gt; mu[1] 81.53 0.16 6.34 69.02 77.32 81.42 85.70 94.91 1618 1 #&gt; mu[2] 102.52 0.11 5.86 91.11 98.64 102.57 106.40 113.99 3076 1 #&gt; mu[3] 89.82 0.09 5.55 79.06 86.07 89.76 93.49 100.91 4114 1 #&gt; mu[4] 106.41 0.13 6.13 93.57 102.51 106.57 110.50 118.39 2285 1 #&gt; mu[5] 91.29 0.08 5.37 80.40 87.93 91.28 94.86 102.05 4113 1 #&gt; mu[6] 88.51 0.10 5.47 78.00 84.76 88.50 92.29 99.23 3143 1 #&gt; sigma 14.27 0.04 2.08 10.87 12.79 14.02 15.50 18.81 2940 1 #&gt; #&gt; Samples were drawn using NUTS(diag_e) at Tue Feb 8 07:07:43 2022. #&gt; For each parameter, n_eff is a crude measure of effective sample size, #&gt; and Rhat is the potential scale reduction factor on split chains (at #&gt; convergence, Rhat=1). Extract the posterior predictions for each machine and compare them to the observations. factory_ypred &lt;- rstan::extract(hierarchical_model, pars = &quot;ypred&quot;)$ypred tidy_factory_measure_matrix &lt;- function(factory_mat) { as.data.frame(factory_mat) %&gt;% set_names(glue(&quot;machine {seq(ncol(factory_mat))}&quot;)) %&gt;% pivot_longer(-c(), names_to = &quot;machine&quot;, values_to = &quot;quality_measurement&quot;) } factory_long &lt;- tidy_factory_measure_matrix(factory) tidy_factory_measure_matrix(factory_ypred) %&gt;% ggplot(aes(x = quality_measurement)) + facet_wrap(vars(machine), nrow = 2, scales = &quot;free&quot;) + geom_density(fill = &quot;black&quot;, alpha = 0.1) + geom_rug(data = factory_long, color = &quot;blue&quot;) + scale_x_continuous(expand = expansion(c(0, 0))) + scale_y_continuous(expand = expansion(c(0, 0.02))) + labs( x = &quot;quality measurements&quot;, y = &quot;density&quot;, title = &quot;Posterior predictions on current machines&quot; ) Calculate the expected utility for each current machine. machine_utilities &lt;- apply(factory_ypred, 2, utility) tibble( machine = glue(&quot;machine {seq(length(machine_utilities))}&quot;), expected_utility = machine_utilities ) %&gt;% kableExtra::kbl() machine expected_utility machine 1 -26.15 machine 2 70.15 machine 3 17.50 machine 4 76.45 machine 5 27.45 machine 6 11.05 b) Rank the machines based on the expected utilities. In other words order the machines from worst to best. Also briefly explain what the utility values tell about the quality of these machines. E.g. Tell which machines are profitable and which are not (if any). Based on their expected utility, the rankings of the machines from worst to best is: 1, 6, 3, 5, 2, 4. Machine 1 has a negative utility, indicating that it is expected to be unprofitable. c) Compute and report the expected utility of the products of a new (7th) machine. machine7_pred &lt;- rstan::extract(hierarchical_model, pars = &quot;y7pred&quot;)$y7pred ggplot(tibble(x = unlist(machine7_pred)), aes(x = x)) + geom_density(fill = &quot;black&quot;, alpha = 0.1) + scale_x_continuous(expand = expansion(c(0, 0))) + scale_y_continuous(expand = expansion(c(0, 0.02))) + labs( x = &quot;quality measurements&quot;, y = &quot;density&quot;, title = &quot;Posterior predictions on hypothetical machine 7&quot; ) # Expected utility from machine 7. utility(machine7_pred) #&gt; [1] 30.7 The expected utility of hypothetical machine 7 is 30.7. d) Based on your analysis, discuss briefly whether the company owner should buy a new (7th) machine. Based on this analysis, purchasing another machine would be expected to be profitable. It might be worth replacing machine 1 with this new machine. e) As usual, remember to include the source code for both Stan and R (or Python). The model is available here “assignment07_factories_hierarchical.stan”. The only changes were made in the generated quantities block: ... generated quantities { // Compute the predictive distribution for the sixth machine. real y6pred; // Leave for compatibility with earlier assignments. vector[J] ypred; real mu7pred; real y7pred; vector[J] log_lik[N]; y6pred = normal_rng(mu[6], sigma); for (j in 1:J) { ypred[j] = normal_rng(mu[j], sigma); } mu7pred = normal_rng(alpha, tau); y7pred = normal_rng(mu7pred, sigma); for (j in 1:J) { for (n in 1:N) { log_lik[n,j] = normal_lpdf(y[n,j] | mu[j], sigma); } } } sessionInfo() #&gt; R version 4.1.2 (2021-11-01) #&gt; Platform: x86_64-apple-darwin17.0 (64-bit) #&gt; Running under: macOS Big Sur 10.16 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices datasets utils methods base #&gt; #&gt; other attached packages: #&gt; [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.7 #&gt; [4] purrr_0.3.4 readr_2.0.1 tidyr_1.1.3 #&gt; [7] tibble_3.1.3 tidyverse_1.3.1 tidybayes_3.0.1 #&gt; [10] rstan_2.21.2 ggplot2_3.3.5 StanHeaders_2.21.0-7 #&gt; [13] glue_1.4.2 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] matrixStats_0.61.0 fs_1.5.0 lubridate_1.7.10 #&gt; [4] webshot_0.5.2 httr_1.4.2 rprojroot_2.0.2 #&gt; [7] tensorA_0.36.2 tools_4.1.2 backports_1.2.1 #&gt; [10] bslib_0.2.5.1 utf8_1.2.2 R6_2.5.0 #&gt; [13] DBI_1.1.1 colorspace_2.0-2 ggdist_3.0.0 #&gt; [16] withr_2.4.2 tidyselect_1.1.1 gridExtra_2.3 #&gt; [19] prettyunits_1.1.1 processx_3.5.2 curl_4.3.2 #&gt; [22] compiler_4.1.2 cli_3.0.1 rvest_1.0.1 #&gt; [25] arrayhelpers_1.1-0 xml2_1.3.2 labeling_0.4.2 #&gt; [28] bookdown_0.24 posterior_1.1.0 sass_0.4.0 #&gt; [31] scales_1.1.1 checkmate_2.0.0 aaltobda_0.3.1 #&gt; [34] callr_3.7.0 systemfonts_1.0.3 digest_0.6.27 #&gt; [37] svglite_2.0.0 rmarkdown_2.10 pkgconfig_2.0.3 #&gt; [40] htmltools_0.5.1.1 highr_0.9 dbplyr_2.1.1 #&gt; [43] rlang_0.4.11 readxl_1.3.1 rstudioapi_0.13 #&gt; [46] jquerylib_0.1.4 farver_2.1.0 generics_0.1.0 #&gt; [49] svUnit_1.0.6 jsonlite_1.7.2 distributional_0.2.2 #&gt; [52] inline_0.3.19 magrittr_2.0.1 kableExtra_1.3.4 #&gt; [55] loo_2.4.1 Rcpp_1.0.7 munsell_0.5.0 #&gt; [58] fansi_0.5.0 abind_1.4-5 lifecycle_1.0.0 #&gt; [61] stringi_1.7.3 yaml_2.2.1 pkgbuild_1.2.0 #&gt; [64] grid_4.1.2 parallel_4.1.2 crayon_1.4.1 #&gt; [67] lattice_0.20-45 haven_2.4.3 hms_1.1.0 #&gt; [70] knitr_1.33 ps_1.6.0 pillar_1.6.2 #&gt; [73] codetools_0.2-18 clisymbols_1.2.0 stats4_4.1.2 #&gt; [76] reprex_2.0.1 evaluate_0.14 V8_3.4.2 #&gt; [79] renv_0.14.0 RcppParallel_5.1.4 modelr_0.1.8 #&gt; [82] vctrs_0.3.8 tzdb_0.1.2 cellranger_1.1.0 #&gt; [85] gtable_0.3.0 assertthat_0.2.1 xfun_0.25 #&gt; [88] broom_0.7.9 coda_0.19-4 viridisLite_0.4.0 #&gt; [91] ellipsis_0.3.2 here_1.0.1 "],["exercises-intro.html", "Introduction", " Introduction For a few chapters, I worked through some of the exercises provided at the end. My answers are provided in the notebooks in this section. "],["chapter-1-exercises.html", "29 Chapter 1 Exercises 29.1 Question 1 29.2 Question 2 29.3 Question 6 29.4 Question 8", " 29 Chapter 1 Exercises 2021-08-19 Complete questions 1-4 and 6-8. 29.1 Question 1 When \\(\\theta = 1\\), then \\(y = N(\\mu = 1, \\sigma)\\) and when \\(\\theta = 2\\), then \\(y = N(\\mu=2, \\sigma)\\). \\(\\Pr(\\theta=1)= \\Pr(\\theta=2) = 0.5\\). a) If \\(\\sigma=2\\) what is the marginal probability density for \\(y\\)? \\[ \\begin{aligned} &amp;= \\Sigma_{\\theta=1}^{\\Theta} \\Pr(\\theta) N(y | \\mu_\\theta, \\sigma) \\\\ &amp;= \\frac{1}{2} N(y|1,2) + \\frac{1}{2} N(y|2,2) \\end{aligned} \\] y &lt;- seq(-6, 10, 0.1) d &lt;- 0.5 * dnorm(y, 1, 2) + 0.5 * dnorm(y, 2, 2) plot( y, d, type = &quot;l&quot;, frame = FALSE, xlab = &quot;y&quot;, ylab = &quot;probability density&quot;, main = &quot;Joint probability density of y&quot; ) b) What is \\(\\Pr(\\theta=1 | y=1)\\) with \\(\\sigma=2\\). Solve using Baye’s rule: \\[ \\begin{aligned} \\Pr(\\theta | y) &amp;= \\frac{\\Pr(\\theta) \\Pr(y | \\theta)}{\\Pr(y)} \\\\ \\Pr(\\theta=1 | y=1) &amp;= \\frac{\\Pr(\\theta=1) \\Pr(y=1 | \\theta=1)}{\\Pr(y=1)} \\\\ \\end{aligned} \\] where \\[ \\Pr(\\theta = 1) = 0.5 \\\\ \\Pr(y=1 | \\theta=1) = N(y=1|1,2) \\\\ \\Pr(y=1) = \\frac{1}{2} N(y=1|1,2) + \\frac{1}{2} N(y=1|2,2) \\] thus \\[ \\begin{aligned} \\Pr(\\theta=1 | y=1) &amp;= \\frac{\\Pr(\\theta=1) \\Pr(y=1 | \\theta=1)}{\\Pr(y=1)} \\\\ &amp;= \\frac{\\frac{1}{2} N(y=1|1,2)}{\\frac{1}{2} N(y=1|1,2) + \\frac{1}{2} N(y=1|2,2)} \\\\ \\end{aligned} \\] (0.5 * dnorm(1, 1, 2)) / (0.5 * dnorm(1, 1, 2) + 0.5 * dnorm(1, 2, 2)) #&gt; [1] 0.5312094 c) Describe the posterior density of \\(\\theta\\) as \\(\\sigma\\) increases or decreases. As \\(\\sigma \\to \\infty\\), the probabilities \\(\\Pr(y|\\theta)\\) and \\(\\Pr(y)\\) become increasingly wide, resulting in the prior probability \\(\\Pr(\\theta)\\) consuming the equation resulting in \\(\\Pr(\\theta=1|y=1) = \\frac{1}{2}\\). This situation would be analogous to having no data. As \\(\\sigma \\to 0\\), the opposite occurs and the prior is overwhelmed by the probability \\(\\Pr(y=1|\\theta=1)\\). Thus \\(\\Pr(\\theta=1|y=1) = 1\\); complete certainty in the value of \\(\\theta\\). This situation would be analogous to collecting a lot of highly homogeneous data. 29.2 Question 2 Conditional means and variances: show that equations 1.8 and 1.9 hold if \\(u\\) is a vector. Equation 1.8: \\(\\text{E}(u) = \\text{E}(\\text{E}(u|v))\\) For a vector \\(u\\), Equation 1.8 would be computed componentwise: \\(\\text{E}(u_i) = \\text{E}(\\text{E}(u_i|v))\\). Equation 1.9: \\(\\text{var}(u) = \\text{E}(\\text{var}(u|v)) + \\text{var}(\\text{E}(u|v))\\) For a vecotr \\(u\\), the diagnoals for Euqation 1.9 would be computed componentwise: \\(\\text{var}(u_i) = \\text{E}(\\text{var}(u_i|v)) + \\text{var}(\\text{E}(u_i|v))\\). For off-diagonals, the result is the covariance between the indeices of \\(u\\): \\(\\text{cov}(u_i, u_j)\\). 29.3 Question 6 Approximately 1/125 of all births are fraternal twins and 1/300 are identical twins. Elvis had a twin brother. What is the probability that Elivs was an identical twin? \\[ \\Pr(\\text{identical twin} | \\text{twin and brother}) = \\frac{\\Pr(\\text{identical twin}) \\Pr(\\text{twin and brother} | \\text{identical twin})}{\\Pr(\\text{twin and brother})} \\\\ \\] \\[ \\begin{aligned} \\Pr(\\text{identical twin}) = \\frac{1}{300} \\\\ \\Pr(\\text{twin and brother} | \\text{identical twin}) = 1 \\\\ \\Pr(\\text{twin and brother}) &amp;= \\Pr(\\text{identical twin}) \\Pr(\\text{boy} | \\text{identical twin}) + \\Pr(\\text{fraternal twin}) \\Pr(\\text{boy} | \\text{fraternal twin}) \\\\ &amp;=\\frac{1}{300} \\times 1 + \\frac{1}{125} \\times \\frac{1}{2} \\end{aligned} \\] \\[ \\begin{aligned} \\Pr(\\text{identical twin} | \\text{twin and brother}) &amp;= \\frac{\\frac{1}{300} \\times 1}{\\frac{1}{300} \\times 1 + \\frac{1}{125} \\times \\frac{1}{2}} \\\\ &amp;= \\frac{\\frac{1}{300}}{\\frac{11}{1500}} \\\\ &amp;= \\frac{5}{11} \\end{aligned} \\] 29.4 Question 8 Subjective probability: discuss the following statement. ‘The probability of event \\(E\\) is considered “subjective” if two rational persons \\(A\\) and \\(B\\) can assign unequal probabilities to \\(E\\), \\(P_A(E)\\) and \\(P_B(E)\\). These probabilities can also be interpreted as “conditional”: \\(P_A(E)\\) = \\(P(E|I_A)\\) and \\(P_B(E) = P(E|I_B)\\), where \\(I_A\\) and \\(I_B\\) represent the knowledge available to persons \\(A\\) and \\(B\\), respectively.’ Apply this idea to the following examples. (a) The probability that a ‘6’ appears when a fair die is rolled, where \\(A\\) observes the outcome of the die roll and \\(B\\) does not. In this case, the statement “the probability of event \\(E\\) is considered”subjective” if two rational persons \\(A\\) and \\(B\\) can assign unequal probabilities to \\(E\\)” does not hold because \\(A\\) knows the value of the die whereas \\(B\\) must guess at random. Thus the probability of the event is not subjective, the two people have different amounts of data. (b) The probability that Brazil wins the next World Cup, where \\(A\\) is ignorant of soccer and \\(B\\) is a knowledgeable sports fan. As the event has yet to occur, the probability of the event is subjective and \\(B\\) has a stronger prior belief than does \\(A\\). "],["chapter-2-exercises.html", "30 Chapter 2 Exercises 30.1 Setup 30.2 Question 1 30.3 Question 2 30.4 Question 3 30.5 Question 4", " 30 Chapter 2 Exercises 2021-08-19 30.1 Setup knitr::opts_chunk$set(echo = TRUE, comment = &quot;#&gt;&quot;, dpi = 300) rfiles &lt;- list.files(here::here(&quot;src&quot;), full.names = TRUE, pattern = &quot;R$&quot;) for (rfile in rfiles) { source(rfile) } library(glue) library(tidyverse) Complete questions 2.1-2.5, 2.8, 2.9, 2.14, 2.17, and 2.22. 30.2 Question 1 Posterior inference: suppose you have a \\(\\text{Beta}(4,4)\\) prior distribution on the probability \\(\\theta\\) that a count will yield a ‘head’ when spun. The coin is spun 10 times and ‘heads’ appear fewer than 3 times. Calculate the exact posterior density for \\(\\theta\\) and sketch it. prior: \\(\\text{Beta}(4,4)\\) data: \\(y = 0 \\text{ or } 1 \\text{ or } 2\\) if \\(y=2\\): \\(p(\\theta | y=2) = \\text{Beta}(4+2, 4+8)\\) if \\(y=1\\): \\(p(\\theta | y=1) = \\text{Beta}(4+1, 4+9)\\) if \\(y=0\\): \\(p(\\theta | y=0) = \\text{Beta}(4+0, 4+10)\\) \\(p(\\theta|y) = \\frac{1}{3} \\text{Beta}(6, 12) + \\frac{1}{3} \\text{Beta}(5, 13) + \\frac{1}{3} \\text{Beta}4, 14)\\) theta &lt;- seq(0, 1, 0.01) prob_density &lt;- (dbeta(theta, 6, 12) + dbeta(theta, 5, 13) + dbeta(theta, 4, 14)) / 3 plot_dist(theta, prob_density, xlab = &quot;theta&quot;, ylab = &quot;probability&quot;) 30.3 Question 2 Predictive distributions: consider two coins \\(C_1\\) and \\(C_2\\) with the following characteristics: \\(\\Pr(\\text{heads} | C_1) = 0.6\\) and \\(\\Pr(\\text{heads} | C_2) = 0.4\\). Choose one of the coins at random and spin it. Given that the first two spins are tails, what is the expectation of the number of additional spins until a heads? Find the probability of each coin given the data and use those as “weights” for the expected number of spins to get heads. \\[ p(C_1|y) = \\frac{p(C_1) p(y|C_1)}{p(y)} \\\\ p(C_1) = \\frac{1}{2} \\\\ p(y|C_1) = (1-0.6)^2 = 0.4^2 = \\frac{16}{100} \\\\ p(y) = \\frac{1}{2} \\frac{16}{100} + \\frac{1}{2} \\frac{36}{100} \\\\ p(C_1|y) = \\frac{\\frac{1}{2} \\frac{16}{100}}{\\frac{1}{2} \\frac{16}{100} + \\frac{1}{2} \\frac{36}{100}} = \\frac{8}{26} \\] Same cacuation for \\(p(C_2|y)\\) resulting in \\(p(C_2|y) = \\frac{18}{26}\\). Expected number \\(n\\) of coin spins until get heads given the probability of getting heads \\(\\theta\\): \\[ \\text{E}(n|\\theta) = 1 \\theta + 2(1-\\theta)\\theta + 3(1 - \\theta)^2 \\theta + \\dots = \\frac{1}{\\theta} \\] Thus \\[ \\begin{aligned} \\text{E}(n|y) &amp;= p(C_1|y) \\text{E}(n|C_1,y) + p(C_2|y) \\text{E}(n|C_2,y) \\\\ &amp;= \\frac{8}{26} \\frac{1}{0.6} + \\frac{18}{26} \\frac{1}{0.4} \\\\ &amp;= 2.24 \\end{aligned} \\] 30.4 Question 3 Predictive distributions: let \\(y\\) be the number of 6’s in 1000 rolls of a fair die. a) Sketch the approximate distribution of \\(y\\) based on the normal approximation. mean: \\(\\text{E}(y) = \\frac{1}{6} 1000 = \\frac{500}{3}\\) std. dev: \\(\\text{sd}(y) = \\sqrt{\\frac{1}{6} \\frac{5}{6} 1000}\\) mu &lt;- 500 / 3 sigma &lt;- sqrt(1000 * 5 / (6 * 6)) y &lt;- seq(100, 250, 1) likelihood &lt;- dnorm(y, mu, sigma) plot_dist(y, likelihood, xlab = &quot;y&quot;, ylab = &quot;likelihood&quot;) b) Using the normal distribution table, give approximate 5%, 25%, 50%, 75%, and 95% points for the distribution of \\(y\\). percentile z formula value 5% -1.65 \\(\\text{E}(y) - 1.65 \\times \\text{sd}(y)\\) 147.2 25% -0.67 \\(\\text{E}(y) - 1.65 \\times \\text{sd}(y)\\) 158.8 50% 0 \\(\\text{E}(y)\\) 166.7 75% 0.67 \\(\\text{E}(y) + 1.65 \\times \\text{sd}(y)\\) 174.6 95% 1.65 \\(\\text{E}(y) + 1.65 \\times \\text{sd}(y)\\) 186.1 p &lt;- map_chr(c(5, 25, 50, 75, 95), ~ glue(&quot;{.x}%&quot;)) q &lt;- c(147.2, 158.8, 166.7, 174.6, 186.1) pqs &lt;- tibble(p = p, q = q) d &lt;- tibble(y = y, likelihood = likelihood) ggplot(d, aes(x = y, y = likelihood)) + geom_line() + geom_vline(aes(xintercept = q, color = p), data = pqs, show.legend = FALSE) + geom_text(aes(x = q, label = p), data = pqs, y = 0.036, show.legend = FALSE) + scale_x_continuous(expand = expansion()) + scale_y_continuous(expand = expansion(mult = c(0, 0.1))) + theme_bw() 30.5 Question 4 Predictive distributions: let \\(y\\) be the number of 6’s in 1000 rolls of a die that may not be fair. Let \\(\\theta\\) be the probability that the die lands on 6 with the following priors for different values of \\(\\theta\\): \\[ \\begin{aligned} \\Pr(\\theta = \\frac{1}{12} &amp;= 0.25) \\\\ \\Pr(\\theta = \\frac{1}{6} &amp;= 0.5) \\\\ \\Pr(\\theta = \\frac{1}{4} &amp;= 0.25) \\\\ \\end{aligned} \\] a) Using the normal approximation for the conditional distributions \\(p(y|\\theta)\\), sketch the prior predictive for \\(y\\). prior predictive: \\(p(\\tilde{y}|M) = \\int p(\\tilde{y}|\\theta, n, M) p(\\theta|M)\\) for this exercise: \\[ \\begin{aligned} p(\\tilde{y}|M) &amp;= p(\\tilde{y} | \\theta=\\frac{1}{12}, n=1000, M) p(\\theta=\\frac{1}{12}) + \\dots \\\\ &amp;= N(\\frac{1}{12} 1000, \\sqrt{1000 \\frac{1}{12} (1 - \\frac{1}{12})}) \\times \\frac{1}{4} + \\dots \\\\ \\end{aligned} \\] six_likelihood &lt;- function(y, theta, n = 1000, prior) { mu &lt;- n * theta sigma &lt;- sqrt(n * theta * (1 - theta)) dnorm(y, mu, sigma) * prior } y &lt;- seq(30, 310) separate_likelihoods &lt;- map2( c(1 / 12, 1 / 6, 1 / 4), c(0.25, 0.5, 0.25), ~ six_likelihood(y, .x, n = 1000, prior = .y) ) combined_likelihood &lt;- accumulate(separate_likelihoods, ~ .x + .y)[[3]] plot_dist(y, combined_likelihood, &quot;y&quot;, &quot;likelihood&quot;) "],["chapter-5-exercises.html", "31 Chapter 5 Exercises 31.1 Question 1", " 31 Chapter 5 Exercises 2021-10-31 Complete question 5.1. 31.1 Question 1 Exchangeability with known model parameters: For each of the following three examples, answer: (i) Are observations \\(y_1\\) and \\(y_2\\) exchangeable? (ii) Are observations \\(y_1\\) and \\(y_2\\) independent? (iii) Can we act as if the two observations are independent? a) A box has one black ball and one white ball. We pick a ball \\(y_1\\) at random, put it back, and pick another ball \\(y_2\\) at random. The observations are exchangeable, independent, and we can act as if they are independent. b) A box has one black ball and one white ball. We pick a ball \\(y_1\\) at random, we do not put it back, then we pick ball \\(y_2\\). The observations are exchangeable because we don’t have information about which ball is most likely to be picked first, but they are not independent because with \\(y_1\\), we know the result for \\(y_2\\). I don’t think we can treat the observations as independent c) A box has a million black balls and a million white balls. We pick a ball \\(y_1\\) at random, we do not put it back, then we pick ball \\(y_2\\) at random. The observations are exchangeable for the same reason as in the answer to (b). The observations are not independent because we will know that, after \\(y_1\\), the other color is slightly more likely to be picked. Since there are so many balls, we can likely treat the observations are independent. "],["chapter-19-exercises---reproducing-the-the-serial-dilution-assay.html", "32 Chapter 19 Exercises - Reproducing the the ‘serial dilution assay’ 32.1 Setup 32.2 Modeling 32.3 Session info", " 32 Chapter 19 Exercises - Reproducing the the ‘serial dilution assay’ 2021-12-10 I turned this exercise into a blog post on my webiste. In chapter 17 “Parametric nonlinear models” of Bayesian Data Analysis by Gelman et al. (Gelman et al. 2013), the authors present an example of fitting a curve to a serial dilution standard curve and using it to estimate unknown concentrations. Below, I build the model with Stan and fit it using MCMC. Unfortunately, I was unable to find the original data in Gelman’s original publication of the model (Gelman, Chew, and Shnaidman 2004). The best I could do was copy the data for the standard curve from a table in the book and build the model to fit that data. The source code for this post is in a repository of my work for Aki Vehtari’s Bayesian Data Analysis course. 32.1 Setup library(rstan) library(tidybayes) library(patchwork) library(tidyverse) options(mc.cores = parallel::detectCores()) rstan_options(auto_write = TRUE) theme_set( theme_classic() + theme( panel.grid.major = element_line(), strip.background = element_blank(), plot.title = element_text(hjust = 0.5) ) ) SNS_BLUE &lt;- &quot;#1F77B4&quot; STAN_RED &lt;- &quot;#B2171D&quot; As mentioned above, I couldn’t find the original data, so I copied it from the book’s figure 19.3 on page 473. dilution_standards_data &lt;- tibble::tribble( ~conc, ~dilution, ~y, 0.64, 1, c(101.8, 121.4), 0.32, 1 / 2, c(105.2, 114.1), 0.16, 1 / 4, c(92.7, 93.3), 0.08, 1 / 8, c(72.4, 61.1), 0.04, 1 / 16, c(57.6, 50.0), 0.02, 1 / 32, c(38.5, 35.1), 0.01, 1 / 64, c(26.6, 25.0), 0, 0, c(14.7, 14.2), ) %&gt;% mutate(rep = purrr::map(conc, ~ c(&quot;a&quot;, &quot;b&quot;))) %&gt;% unnest(c(y, rep)) knitr::kable(dilution_standards_data) conc dilution y rep 0.64 1.000000 101.8 a 0.64 1.000000 121.4 b 0.32 0.500000 105.2 a 0.32 0.500000 114.1 b 0.16 0.250000 92.7 a 0.16 0.250000 93.3 b 0.08 0.125000 72.4 a 0.08 0.125000 61.1 b 0.04 0.062500 57.6 a 0.04 0.062500 50.0 b 0.02 0.031250 38.5 a 0.02 0.031250 35.1 b 0.01 0.015625 26.6 a 0.01 0.015625 25.0 b 0.00 0.000000 14.7 a 0.00 0.000000 14.2 b The following plot shows the two standard dilution curves. They are quite similar. data_plot &lt;- dilution_standards_data %&gt;% ggplot(aes(x = conc, y = y, color = rep)) + geom_line(alpha = 0.5, linetype = 2) + geom_point(alpha = 0.8) + scale_x_continuous(expand = expansion(c(0, 0.02)), limits = c(0, NA)) + scale_y_continuous(expand = expansion(c(0, 0.02)), limits = c(0, NA)) + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set1&quot;) + theme( legend.position = c(0.8, 0.2), legend.background = element_blank() ) + labs( x = &quot;concentration&quot;, y = &quot;y&quot;, title = &quot;Serial dilution standard curve&quot;, color = &quot;replicate&quot; ) data_plot 32.2 Modeling 32.2.1 Model specification The model uses a normal likelihood to describe the posterior distribution \\(p(y|x)\\). The mean of the likelihood is defined for a given concentration \\(x\\) using the standard equation used in the field: \\[ \\text{E}[y | x, \\beta] = g(x, \\beta) = \\beta_1 + \\frac{\\beta_2}{1 + (x/\\beta_3)^{-\\beta_4}} \\\\ \\] The model is a scaled and shifted logistic curve. This structure results in the following interpretations for \\(\\beta\\), all of which are restricted to positive values: \\(\\beta_1\\): color intensity when the concentration is 0 \\(\\beta_2\\): increase to saturation \\(\\beta_3\\): the inflection point of the curve \\(\\beta_4\\): rate of saturation Below are the prior distributions for \\(\\beta\\). Note that they are are drastically different scales - this is critical to help the model fit the data. \\[ \\beta_1 \\sim N(10, 2.5) \\\\ \\beta_2 \\sim N(100, 5) \\\\ \\beta_3 \\sim N(0, 1) \\\\ \\beta_4 \\sim N(0, 2.5) \\] The measurement error of the model, representing the variance in the model’s likelihood is defined as follows: \\[ \\tau(\\alpha, \\sigma_y, g(x, \\beta), A) = \\lgroup \\frac{g(x,\\beta)}{A} \\rgroup^{2\\alpha} \\sigma^2_y \\] Here, \\(\\alpha\\), restricted to lie between 0 and 1, allows the variance to be higher for larger measurement values. \\(A\\) is a constant (set to 30 by the authors) that allows \\(\\sigma_y\\) to be more easily interpreted as the variance from “typical” measurements. Below are the priors for the new variables in the model. \\[ \\alpha \\sim \\text{Beta}(1, 1) \\qquad \\sigma \\sim |N(0, 2.5)| \\] 32.2.2 In Stan Below is the Stan code for the model. It looks very similar to the mathematical description of the model, a nice feature of the Stan probabilistic programming language. The centrality and variance of the likelihood are calculated separately as g and tau so they can be used in the model and generated quantities block without duplicating the code. The log_lik is calculated so that PSIS-LOO cross validation can be estimated. I also included the ability to provide new data to make predictions over as xnew. dilution_model_file &lt;- here::here(&quot;models&quot;, &quot;serial-dilution.stan&quot;) writeLines(readLines(dilution_model_file)) #&gt; data { #&gt; int&lt;lower=0&gt; N; // number of data points #&gt; int&lt;lower=0&gt; A; // constant used in model of measurement error #&gt; vector&lt;lower=0&gt;[N] x; // concentration values #&gt; vector&lt;lower=0&gt;[N] y; // observed color intensity #&gt; int&lt;lower=0&gt; M; // number of new x values #&gt; vector&lt;lower=0&gt;[M] xnew; // new x values #&gt; } #&gt; #&gt; parameters { #&gt; vector&lt;lower=0&gt;[4] beta; #&gt; real&lt;lower=0,upper=1&gt; alpha; #&gt; real&lt;lower=0&gt; sigma; #&gt; } #&gt; #&gt; transformed parameters { #&gt; vector&lt;lower=0&gt;[N] g; #&gt; vector&lt;lower=0&gt;[N] tau; #&gt; #&gt; for (i in 1:N) { #&gt; g[i] = beta[1] + beta[2] / (1 + (x[i] / beta[3]) ^ (-beta[4])); #&gt; tau[i] = ((g[i] / A) ^ (2.0 * alpha)) * (sigma ^ 2.0); #&gt; } #&gt; } #&gt; #&gt; model { #&gt; // Priors #&gt; alpha ~ beta(1, 1); #&gt; beta[1] ~ normal(10, 2.5); #&gt; beta[2] ~ normal(100, 5); #&gt; beta[3] ~ normal(0, 1); #&gt; beta[4] ~ normal(0, 2.5); #&gt; sigma ~ normal(0, 2.5); #&gt; #&gt; // Likelihood #&gt; for (i in 1:N) { #&gt; y[i] ~ normal(g[i], tau[i]); #&gt; } #&gt; } #&gt; #&gt; generated quantities { #&gt; vector[N] ypred; #&gt; vector[N] log_lik; #&gt; #&gt; vector[M] g_hat; #&gt; vector[M] tau_hat; #&gt; vector[M] ynew; #&gt; #&gt; for (i in 1:N) { #&gt; ypred[i] = normal_rng(g[i], tau[i]); #&gt; log_lik[i] = normal_lpdf(y[i] | g[i], tau[i]); #&gt; } #&gt; #&gt; for (i in 1:M) { #&gt; g_hat[i] = beta[1] + beta[2] / (1 + (xnew[i] / beta[3]) ^ (-beta[4])); #&gt; tau_hat[i] = ((g_hat[i] / A) ^ (2.0 * alpha)) * (sigma ^ 2.0); #&gt; ynew[i] = normal_rng(g_hat[i], tau_hat[i]); #&gt; } #&gt; } 32.2.3 Sampling As mentioned above, specifically defining the prior distributions for each \\(\\beta\\) is necessary for MCMC to accurately sample from the posterior. With those helping restrict the range of their values, the model fit very well. xnew &lt;- seq(0, max(dilution_standards_data$conc), 0.001) model_data &lt;- list( N = nrow(dilution_standards_data), A = 30, x = dilution_standards_data$conc, y = dilution_standards_data$y, M = length(xnew), xnew = xnew ) dilution_model &lt;- stan( dilution_model_file, model_name = &quot;serial-dilution&quot;, data = model_data, refresh = 1000 ) 32.2.4 Posterior distributions The next step is to analyze the posterior draws of the model. We can check the success of MCMC by visualizing the traces of the chains, looking for good mixing (“fuzzy caterpillars”) and checking diagnostic values such as \\(\\widehat{R}\\) and \\(n_\\text{eff}\\). The trace plots are shown below followed by a table of the posteriors with the diagnostic values. Everything looks good suggesting MCMC was successful. model_pars &lt;- c(&quot;beta&quot;, &quot;alpha&quot;, &quot;sigma&quot;) rstan::stan_trace(dilution_model, pars = model_pars, ncol = 2, alpha = 0.7) + scale_x_continuous(expand = expansion(c(0, 0))) + scale_y_continuous(expand = expansion(c(0.02, 0.02))) + theme(legend.position = &quot;bottom&quot;) print(dilution_model, pars = model_pars) #&gt; Inference for Stan model: serial-dilution. #&gt; 4 chains, each with iter=2000; warmup=1000; thin=1; #&gt; post-warmup draws per chain=1000, total post-warmup draws=4000. #&gt; #&gt; mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat #&gt; beta[1] 14.33 0.02 0.55 13.12 14.08 14.36 14.61 15.33 1074 1 #&gt; beta[2] 102.70 0.10 4.30 94.48 99.67 102.61 105.60 111.32 1755 1 #&gt; beta[3] 0.06 0.00 0.01 0.05 0.06 0.06 0.07 0.08 1633 1 #&gt; beta[4] 1.13 0.00 0.08 0.97 1.07 1.12 1.18 1.29 1870 1 #&gt; alpha 0.72 0.01 0.17 0.33 0.61 0.74 0.85 0.98 1074 1 #&gt; sigma 1.33 0.01 0.24 0.98 1.16 1.30 1.45 1.92 893 1 #&gt; #&gt; Samples were drawn using NUTS(diag_e) at Tue Feb 8 07:08:13 2022. #&gt; For each parameter, n_eff is a crude measure of effective sample size, #&gt; and Rhat is the potential scale reduction factor on split chains (at #&gt; convergence, Rhat=1). The following density plots show the posterior distributions of the model parameters \\(\\beta\\), \\(\\alpha\\), and \\(\\sigma\\). rstan::stan_dens( dilution_model, pars = model_pars, separate_chains = FALSE, alpha = 0.6 ) + scale_x_continuous(expand = expansion(c(0, 0))) + scale_y_continuous(expand = expansion(c(0, 0.02))) 32.2.5 Posterior predictive check Below is a plot of the posterior predictive distributions of the model on the original data. 1,000 individual simulations are plotted in blue and the mean in black. The simulated curves visually appear to correspond well with the observed data indicating the model has good fit. dilution_post_pred &lt;- rstan::extract(dilution_model, &quot;ypred&quot;)$ypred %&gt;% as.data.frame() %&gt;% as_tibble() %&gt;% set_names(seq(1, ncol(.))) %&gt;% mutate(draw = 1:n()) %&gt;% pivot_longer(-c(draw), names_to = &quot;idx&quot;) %&gt;% left_join( dilution_standards_data %&gt;% mutate(idx = as.character(1:n())), by = &quot;idx&quot; ) plt_n_draws &lt;- 1000 plt_draws &lt;- sample(1:max(dilution_post_pred$draw), plt_n_draws) ppc_mean &lt;- dilution_post_pred %&gt;% group_by(conc) %&gt;% summarize(value = mean(value)) %&gt;% ungroup() dilution_post_pred %&gt;% filter(draw %in% !!plt_draws) %&gt;% mutate(grp = glue::glue(&quot;{draw}-{rep}&quot;)) %&gt;% ggplot(aes(x = conc, y = value)) + geom_line(aes(group = grp), alpha = 0.05, color = SNS_BLUE) + geom_line(group = &quot;a&quot;, data = ppc_mean, color = &quot;black&quot;) + geom_point(data = ppc_mean, color = &quot;black&quot;) + geom_line( aes(y = y, group = rep), data = dilution_standards_data, color = STAN_RED ) + geom_point(aes(y = y), data = dilution_standards_data, color = STAN_RED) + scale_x_continuous(expand = expansion(c(0, 0))) + scale_y_continuous(expand = expansion(c(0.02, 0.02))) + labs( x = &quot;concentration&quot;, y = &quot;y&quot;, title = &quot;Posterior predictive distribution&quot; ) I also had the model make posterior predictions on concentrations across the observed range at smaller step-sizes. The mean and 89% HDI are shown in blue below along with the observed data in red. The inset plot is a zoomed-in view of the posterior predictive distribution at the lower concentrations. ynew_mean &lt;- apply(rstan::extract(dilution_model, pars = &quot;ynew&quot;)$ynew, 2, mean) ynew_hdi &lt;- apply( rstan::extract(dilution_model, pars = &quot;ynew&quot;)$ynew, 2, bayestestR::hdi, ci = 0.89 ) ynew_ppc &lt;- tibble( conc = xnew, ynew_mean = ynew_mean, ynew_hdi_low = purrr::map_dbl(ynew_hdi, ~ unlist(.x)[[2]]), ynew_hdi_hi = purrr::map_dbl(ynew_hdi, ~ unlist(.x)[[3]]) ) plot_posterior_pred &lt;- function(ppc_df, obs_df, pt_size = 1.5) { ppc_df %&gt;% ggplot(aes(x = conc, y = ynew_mean)) + geom_ribbon( aes(ymin = ynew_hdi_low, ymax = ynew_hdi_hi), fill = SNS_BLUE, alpha = 0.5 ) + geom_line(group = &quot;a&quot;) + geom_line( aes(y = y, group = rep), data = obs_df, color = STAN_RED ) + geom_point(aes(y = y), data = obs_df, size = pt_size, color = STAN_RED) + scale_x_continuous(expand = expansion(c(0, 0))) + scale_y_continuous(expand = expansion(c(0.02, 0.02))) } ppc_plot &lt;- plot_posterior_pred(ynew_ppc, dilution_standards_data) + labs( x = &quot;concentration&quot;, y = &quot;y&quot;, title = &quot;Posterior predictive distribution&quot; ) sub_max &lt;- 0.04 sub_ppc_plot &lt;- plot_posterior_pred( ynew_ppc %&gt;% filter(conc &lt;= sub_max), dilution_standards_data %&gt;% filter(conc &lt;= sub_max), pt_size = 0.6 ) + theme(axis.title = element_blank()) ppc_plot + inset_element(sub_ppc_plot, left = 0.5, bottom = 0.05, right = 0.9, top = 0.5) 32.3 Session info sessionInfo() #&gt; R version 4.1.2 (2021-11-01) #&gt; Platform: x86_64-apple-darwin17.0 (64-bit) #&gt; Running under: macOS Big Sur 10.16 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices datasets utils methods base #&gt; #&gt; other attached packages: #&gt; [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.7 #&gt; [4] purrr_0.3.4 readr_2.0.1 tidyr_1.1.3 #&gt; [7] tibble_3.1.3 tidyverse_1.3.1 patchwork_1.1.1 #&gt; [10] tidybayes_3.0.1 rstan_2.21.2 ggplot2_3.3.5 #&gt; [13] StanHeaders_2.21.0-7 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] matrixStats_0.61.0 fs_1.5.0 lubridate_1.7.10 #&gt; [4] insight_0.14.4 RColorBrewer_1.1-2 httr_1.4.2 #&gt; [7] rprojroot_2.0.2 tensorA_0.36.2 tools_4.1.2 #&gt; [10] backports_1.2.1 bslib_0.2.5.1 utf8_1.2.2 #&gt; [13] R6_2.5.0 DBI_1.1.1 colorspace_2.0-2 #&gt; [16] ggdist_3.0.0 withr_2.4.2 tidyselect_1.1.1 #&gt; [19] gridExtra_2.3 prettyunits_1.1.1 processx_3.5.2 #&gt; [22] curl_4.3.2 compiler_4.1.2 cli_3.0.1 #&gt; [25] rvest_1.0.1 arrayhelpers_1.1-0 xml2_1.3.2 #&gt; [28] bayestestR_0.11.0 labeling_0.4.2 bookdown_0.24 #&gt; [31] posterior_1.1.0 sass_0.4.0 scales_1.1.1 #&gt; [34] checkmate_2.0.0 callr_3.7.0 digest_0.6.27 #&gt; [37] rmarkdown_2.10 pkgconfig_2.0.3 htmltools_0.5.1.1 #&gt; [40] highr_0.9 dbplyr_2.1.1 rlang_0.4.11 #&gt; [43] readxl_1.3.1 rstudioapi_0.13 jquerylib_0.1.4 #&gt; [46] farver_2.1.0 generics_0.1.0 svUnit_1.0.6 #&gt; [49] jsonlite_1.7.2 distributional_0.2.2 inline_0.3.19 #&gt; [52] magrittr_2.0.1 loo_2.4.1 Rcpp_1.0.7 #&gt; [55] munsell_0.5.0 fansi_0.5.0 abind_1.4-5 #&gt; [58] lifecycle_1.0.0 stringi_1.7.3 yaml_2.2.1 #&gt; [61] pkgbuild_1.2.0 grid_4.1.2 parallel_4.1.2 #&gt; [64] crayon_1.4.1 lattice_0.20-45 haven_2.4.3 #&gt; [67] hms_1.1.0 knitr_1.33 ps_1.6.0 #&gt; [70] pillar_1.6.2 codetools_0.2-18 clisymbols_1.2.0 #&gt; [73] stats4_4.1.2 reprex_2.0.1 glue_1.4.2 #&gt; [76] evaluate_0.14 V8_3.4.2 renv_0.14.0 #&gt; [79] RcppParallel_5.1.4 modelr_0.1.8 vctrs_0.3.8 #&gt; [82] tzdb_0.1.2 cellranger_1.1.0 gtable_0.3.0 #&gt; [85] datawizard_0.2.1 assertthat_0.2.1 xfun_0.25 #&gt; [88] broom_0.7.9 coda_0.19-4 ellipsis_0.3.2 #&gt; [91] here_1.0.1 References "],["stan-models-1.html", "33 Stan models 33.1 Model: 8-schools.stan 33.2 Model: assignment06-bioassay.stan 33.3 Model: assignment07_factories_hierarchical.stan 33.4 Model: assignment07_factories_pooled.stan 33.5 Model: assignment07_factories_separate.stan 33.6 Model: assignment07-drownings.stan 33.7 Model: serial-dilution.stan", " 33 Stan models Below are the Stan models built as a part of this course. The original files are available in the GitHub repo in the “models” directory. 33.1 Model: 8-schools.stan // 8 schools model from &#39;rstan&#39; documentation. // https://mc-stan.org/rstan/articles/rstan.html data { int&lt;lower=0&gt; J; // number of schools real y[J]; // estimated treatment effects real&lt;lower=0&gt; sigma[J]; // s.e. of effect estimates } parameters { real mu; real&lt;lower=0&gt; tau; vector[J] eta; } transformed parameters { vector[J] theta; theta = mu + tau * eta; } model { target += normal_lpdf(eta | 0, 1); target += normal_lpdf(y | theta, sigma); } 33.2 Model: assignment06-bioassay.stan data { int&lt;lower=0&gt; N; // number of data points vector[N] x; // dose int&lt;lower=0&gt; n[N]; // number of animals int&lt;lower=0&gt; y[N]; // number of deaths vector[2] mu; // prior on mean of theta matrix&lt;lower=0&gt;[2, 2] sigma; // prior on covariance matrix of theta } parameters { vector[2] mdl_params; } transformed parameters { vector[N] theta; theta = mdl_params[1] + mdl_params[2] * x; } model { mdl_params ~ multi_normal(mu, sigma); y ~ binomial_logit(n, theta); } 33.3 Model: assignment07_factories_hierarchical.stan data { int&lt;lower=0&gt; N; // number of data points per machine int&lt;lower=0&gt; J; // number of machines vector[J] y[N]; // quality control data points } parameters { vector[J] mu; real&lt;lower=0&gt; sigma; real alpha; real&lt;lower=0&gt; tau; } model { // hyper-priors alpha ~ normal(100, 10); tau ~ normal(0, 10); // priors mu ~ normal(alpha, tau); sigma ~ inv_chi_square(5); // likelihood for (j in 1:J){ y[,j] ~ normal(mu[j], sigma); } } generated quantities { // Compute the predictive distribution for the sixth machine. real y6pred; // Leave for compatibility with earlier assignments. vector[J] ypred; real mu7pred; real y7pred; vector[J] log_lik[N]; y6pred = normal_rng(mu[6], sigma); for (j in 1:J) { ypred[j] = normal_rng(mu[j], sigma); } mu7pred = normal_rng(alpha, tau); y7pred = normal_rng(mu7pred, sigma); for (j in 1:J) { for (n in 1:N) { log_lik[n,j] = normal_lpdf(y[n,j] | mu[j], sigma); } } } 33.4 Model: assignment07_factories_pooled.stan data { int&lt;lower=0&gt; N; // number of data points vector[N] y; // machine quality control data } parameters { real mu; real&lt;lower=0&gt; sigma; } model { // priors mu ~ normal(100, 10); sigma ~ inv_chi_square(5); // likelihood y ~ normal(mu, sigma); } generated quantities { real ypred; vector[N] log_lik; ypred = normal_rng(mu, sigma); for (i in 1:N) log_lik[i] = normal_lpdf(y[i] | mu, sigma); } 33.5 Model: assignment07_factories_separate.stan data { int&lt;lower=0&gt; N; // number of data points per machine int&lt;lower=0&gt; J; // number of machines vector[J] y[N]; // quality control data points } parameters { vector[J] mu; vector&lt;lower=0&gt;[J] sigma; } model { // priors for (j in 1:J) { mu[j] ~ normal(100, 10); sigma[j] ~ inv_chi_square(5); } // likelihood for (j in 1:J){ y[,j] ~ normal(mu[j], sigma[j]); } } generated quantities { // Compute the predictive distribution for the sixth machine. real y6pred; vector[J] log_lik[N]; y6pred = normal_rng(mu[6], sigma[6]); for (j in 1:J) { for (n in 1:N) { log_lik[n,j] = normal_lpdf(y[n,j] | mu[j], sigma[j]); } } } 33.6 Model: assignment07-drownings.stan data { int&lt;lower=0&gt; N; // number of data points vector[N] x; // observation year vector[N] y; // observation number of drowned real xpred; // prediction year } parameters { real alpha; real beta; real&lt;lower=0&gt; sigma; // fix: &#39;upper&#39; should be &#39;lower&#39; } transformed parameters { vector[N] mu = alpha + beta*x; } model { alpha ~ normal(135, 50); // prior on `alpha` beta ~ normal(0, 26); // prior on `beta` y ~ normal(mu, sigma); // fix: missing semicolor } generated quantities { real ypred = normal_rng(alpha + beta*xpred, sigma); // fix: use `xpred` } 33.7 Model: serial-dilution.stan data { int&lt;lower=0&gt; N; // number of data points int&lt;lower=0&gt; A; // constant used in model of measurement error vector&lt;lower=0&gt;[N] x; // concentration values vector&lt;lower=0&gt;[N] y; // observed color intensity int&lt;lower=0&gt; M; // number of new x values vector&lt;lower=0&gt;[M] xnew; // new x values } parameters { vector&lt;lower=0&gt;[4] beta; real&lt;lower=0,upper=1&gt; alpha; real&lt;lower=0&gt; sigma; } transformed parameters { vector&lt;lower=0&gt;[N] g; vector&lt;lower=0&gt;[N] tau; for (i in 1:N) { g[i] = beta[1] + beta[2] / (1 + (x[i] / beta[3]) ^ (-beta[4])); tau[i] = ((g[i] / A) ^ (2.0 * alpha)) * (sigma ^ 2.0); } } model { // Priors alpha ~ beta(1, 1); beta[1] ~ normal(10, 2.5); beta[2] ~ normal(100, 5); beta[3] ~ normal(0, 1); beta[4] ~ normal(0, 2.5); sigma ~ normal(0, 2.5); // Likelihood for (i in 1:N) { y[i] ~ normal(g[i], tau[i]); } } generated quantities { vector[N] ypred; vector[N] log_lik; vector[M] g_hat; vector[M] tau_hat; vector[M] ynew; for (i in 1:N) { ypred[i] = normal_rng(g[i], tau[i]); log_lik[i] = normal_lpdf(y[i] | g[i], tau[i]); } for (i in 1:M) { g_hat[i] = beta[1] + beta[2] / (1 + (xnew[i] / beta[3]) ^ (-beta[4])); tau_hat[i] = ((g_hat[i] / A) ^ (2.0 * alpha)) * (sigma ^ 2.0); ynew[i] = normal_rng(g_hat[i], tau_hat[i]); } } "],["about.html", "About 33.8 The website 33.9 About me", " About 33.8 The website The purpose of this website is to serve as a resource for using my notes and work for this course in the future. Originally, I built it using ‘distill’ and deployed it as a simple static website on GitHub. This worked well and was quick to build because the notebooks did not need to be re-run each time. Though it is a very flexible platform, it had some limitations and I didn’t like the styling of the notebooks in HTML. I’m sure this could have been endlessly adjusted in CSS, but I realized firs that the ‘bookdown’ format may be more appropriate for my needs. I transformed this site into a ‘bookdown’ book after completing the course. It took a bit of rearrangement, but I think the product is more logical and easier to use. It has replaced the ‘distill’ website completely and is deployed on GitHub. 33.9 About me My name is Joshua Cook and I am (at the time of taking this course and writing this About page) a graduate student at Harvard Medical School. My research is on cancer genetics and I have a specific love of Bayesian modelling. You can peruse more of my projects and other work on my GitHub profile at jhrcook or my website. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
